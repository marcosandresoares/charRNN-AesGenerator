DO-FIX: CREATING DEEPER RELATIONSHIPS BETWEEN USERS AND
PRODUCTS THROUGH VISIBLE REPAIR by NAZLI GÖKÇE TERZİOĞLU

Chapter 1: Introduction

A multitude of sociological and psychological motivators urge people to consume significant quantities of products continuously. The contemporary manufacturing system has worked against the environment throughout the twentieth century and into the twenty-first, with the availability of cheap, mass-produced goods, planned obsolescence, repairs which are more expensive than buying a new item and technological developments that quickly outdate products (Brook, 2012; Gill & Lopes, 2011; König, 2013). Since products have become cheaper and globally available, it has become normative consumer behaviour to dispose of products which are less than perfect, even if the problem is easy to fix (Middleton, 2012). As a growing body of work emphasises, it should be considered essential to manufacture longlasting and purposeful products if global rates of consumption are to be lowered (McDonough & Braungart, 2002; Fletcher, 2008). Over two and a half billion tonnes of waste are generated annually in the EU, according to Eurostat Data (Eurostat, 2016). According to the European Union’s Road Map, it would take the equivalent of more than two planets to sustain humanity by 2050 if we continue to consume resources at the current pace. It is a complicated task to determine the countries responsible for climate change today, because there are various factors affecting this, such as historical emissions, current emissions per capita or in absolute figures, and the carbon footprint of consumption, including imported products (Clark, 2011). Besides, deforestation and extraction of fossil fuels can also be counted, as they have significant implications for the environment. Although each measure gives a different insight, we cannot determine those who are responsible and those who are innocent, because environmental destruction is now happening at a global level. For example, China has the highest amount of CO2 emissions, with 9697 million tonnes (MT) or 28.6 per cent, followed by the US and India, but these results are misleading considering the sizes and populations of the nations (Clark, 2011). The data on emissions per person shows that Qatar has the highest figure, followed by the US and Australia (Clark, 2011). Governmental organisations and business representatives offer multiple scenarios with a range of technological and behavioural options that aim to decrease consumption rates (IPCC, 2014; WBCSD, 2016). The European Commission presented an EU action plan for what is termed a circular economy (see Section 2.3) on 2 December 2015. The plan contains a series of actions: four proposed new pieces of legislation on waste, targeting reuse, recycling and landfill, to be achieved by 2030. The UK Government’s Department for Environment, Food and Rural Affairs, DEFRA, proposed a new approach towards waste policy, highlighting the advantages of increasing product lifetimes and offering repair and reuse before replacing products, and also encouraging businesses to produce products that are long lasting, repairable and easy to disassemble (DEFRA, 2011). The Waste and Resources Action Programme (WRAP) is a UK government-funded institution that studies product lifetimes. It has developed a series of programmes, including reuse, repair and refurbishment strategies for users and businesses such as an online product life optimisation tool (WRAP, 2009). WRAP argues that one of the most effective strategies to increase resource efficiency is to extend product lifetimes. Despite all these efforts the amount of waste generated in the EU does not seem to be declining. According to the Eurostat data, the total amount of waste per year was 2,547,590,000 tonnes in 2004, but this had increased to 2,598,140,000 tonnes per year in 2014 (Eurostat, 2016). Most consumer goods are nevertheless still considered as throwaway items. It is essential to understand and change our wasteful attitude and our insufficient engagement with products to overcome these problems (Chapman, 2005; Lockton, Harrison and Stanton, 2008). The ‘circular economy’ (see Section 2.3) is a system-based approach to the industrial economy which offers an opportunity to help reduce our global sustainability pressures (European Commission, 2015; Ellen MacArthur Foundation, 2013). Strategies such as ‘closing the loop’ with reuse, repair, recycling and remanufacturing can enable zero-waste circular manufacturing systems (Stahel, 2010; Bocken, de Pauw, Bakker, & van der Grinten, 2016). Resource consumption can be mitigated by prolonging the utilisation period of products (Bocken et al., 2016). The transformation to a circular economy will require huge shifts in terms of regulations, inputs, product design and consumer behaviour. Solutions offered should be in accord with the needs and wants of consumers to make the transition possible and sustainable. Repair is a highly effective strategy for extending the lifespan of products. However, the decision whether or not to repair something is affected by complex factors, and is dependent upon users’ motivations, perceptions and choices. Consequently, this research aims to explore different ways of encouraging people to repair products more often, as well as exploring the complex factors that influence repair behaviour. 

Design Background and Motivation

I have grown up in a small town. When I was a child, shopping malls, global companies and their strategies had not invaded my hometown yet. I have met with the consumerist society when I moved to Ankara to study industrial design at Middle East Technical University (2006 - 2011). In my second year, I saw that our deep fryer was left next to the bin. I asked my father why he did not repair it as always or take it to a technician. His answer raised some questions in my head: ‘The products are low quality and cannot be repaired anymore. It is very cheap to buy a new one for the sake of my budget and our country’s economy.’ I felt guilty leaving the deep fryer back next to the bin because this idea was against my values. I began to get interested in sustainable design and my interest helped to form my research proposal for the Master of Science in Industrial Design (2011-2013). I conducted a research with twenty repair technicians about the breakdown reasons of small kitchen appliances. This research helped me to improve my knowledge about sustainable design and form my research proposal to study PhD at RCA. My dream was to design sustainable, long lasting and modular small kitchen appliances that users can repair by themselves. In my first year, I collaborated with Jon Kuster who was a Master of Arts student in design products at RCA. We designed the CE Kettle, a repairable, long-lasting kettle for the circular economy. After reviewing the literature and conducting some pilot studies in my first years, I realised that the challenge for designers is not designing circular products, which was already achieved. The challenge is connecting people with products again and overcoming their problematic relationship. We are in a world in which objects are valued for their symbolic meaning based on what dominant social and economic system says. Design practice needs to enable people to extend their understanding of products’ real value. My design practice has rapidly evolved in the first two years of my PhD and I decided to explore how repair might enrich our relationship with products and connect us with their materiality. I attempt to provide an open account of my role in this research throughout the thesis. I have included this biographical explanation of the path that led me to this research to enhance the transparency of the research process and allow the reader to assess the trustworthiness of this study. As I explained above, throwaway mentality is against my values. I acknowledge my biased position of being an environmentalist and conducting this research from this standpoint. My interest in environmentalism, sustainable design and circular economy helped me form and complete this research.

Aims of the Research

- To design a product or service that encourages people to repair products more often 
- To create a new aesthetic language around repair in order to enable a different way of looking at damaged/broken products and product repair 
- To develop design considerations by exploring the complex factors which influence user behaviour in order to motivate people towards repairing products

Research Questions

- How can we encourage people to repair products in order to experience deeper relationships with things and create greater engagement with environmental problems? 
- What are the motivations and barriers that people experience in relation to product repair?

Structure of the Thesis

Figure 1 outlines the structure of the thesis and methodology diagram (Figure 2) shows main research studies, the results and the iterations between these studies. This thesis is organised into seven chapters, which are briefly described below. Chapter 1 constitutes a brief introduction and the aims and objectives of the study, and presents the research questions. Chapter 2 includes the literature review. The aim of this chapter is to provide an overview to the background of the research topic and establish the focus of the research. The chapter starts by exploring the concepts of planned obsolescence and the circular economy. Existing product examples and case studies are included in this part. It continues with a review of the literature on product repair. This chapter concludes with the identification of a gap in the knowledge. Chapter 3 presents the systematic structure of the research and the methodology conducted to answer the research questions. The chapter first presents the explanation of my epistemological stance and the theoretical perspectives applied in this thesis. Then the links between the textual and practical components of this research are explained, as well as the ‘PhD by practice’ approach employed in this thesis. After describing participant selection methods the chapter presents the research phases, including data collection and analysis methods. The chapter concludes with an explanation of the validity and reliability of the research. Chapter 4 reports on the research processes and findings. It starts with the cultural probes study, and it explains the design studies where various repair techniques were explored using a design-led methodology. Then the workshops are presented before the chapter concludes with the overall findings and conclusions from the primary research. Chapter 5 introduces the design projects, namely the Do-Fix repair kits, which are the main outcomes of this PhD, answering the research questions, and the aims and results of the participants’ involvement in this research, The kits include four different variants, namely a kintsugi kit, 3D-printed patches, plaster patches and textile patches. The design projects and their development process are explained thoroughly in this chapter. Chapter 6 brings together all the previous chapters, which constitute the PhD thesis. This is achieved by outlining how the research questions have been answered and summarising the overall conclusions. The chapter concludes by describing recommendations for further research. Chapter 7 presents the original contributions to knowledge and discusses their relevance to wider fields, including product design discourse and practice and the circular economy. 

Chapter 2 : Literature Review

Introduction
The Earth, which is widely considered to be limitless and generous does not now work as it used to. Climate change, ozone depletion, an increased incidence of cancer and toxins, found even in the bodies of new-born babies, are all clues directing us towards serious problems (UNEP, 2011). Nature tries to inform us, and we should not ignore it, because migrating to the edge of another river is not an option. Human beings meet their all needs, both the basic ones of food, water, clothing, and shelter and the more recently emerging ones of shopping and consuming, by drawing on the materials of the earth. We are hastily consuming the only place we have to live in. Unfortunately, these issues are not new to us; experts have been aware of the human effect on the environment from the early stages of industrialisation (Stahel, 1994). In 1962, Rachel Carson brought significant environmental issues to light by documenting the detrimental effects of using pesticides on the environment in her book Silent Spring. Similarly, Donella Meadows, lead author of the influential book The Limits to Growth, predicted the current stituation and questioned the Earth’s capacity to support economic growth. Since then, the environment has been the academic focus of a wide range of disciplines, and within design it has led to notions such as eco design, green design, environmentally friendly design and sustainable design. A wider concept, known as the circular economy, has emerged, which proposes optimising systems rather than components by taking insights from living beings. Day by day, the circular economy is becoming a part of a new business agenda for companies worldwide. Rather than selling significant numbers of low-cost products, innovative business models focus on ‘closing the loop’, by reusing and repairing products, selling services instead of items, and proving to us that it is possible to generate financial profit while respecting both the environment and society. The literature review diagram (Figure 3), outlines the subject areas related to this research. I started by reading about consumption strategies with the aim of gaining a deep understanding of how the system of production and consumption evolved into its current state. I then reviewed the literature related to the circular economy and repair studies. Finally, I focused on research related to motivation and behaviour change.

Consumption Strategies and their Effects on the User-Product Relationship
In the Oxford English Dictionary, planned obsolescence is defined as the policy of producing consumer goods that rapidly become obsolete by virtue of a change in their design, and thus need to be replaced by the use of inferior materials, without the supply of spare parts (Planned obsolescence, 2006). The term first appeared in the United States in the late 1920s (Slade, 2006). Planned obsolescence is arguably the basis of many current environmental and socioeconomic problems. How has the strategy of planned obsolescence worked so well and become one of the building blocks of our current economic system? 
Technological obsolescence is the earliest version of product obsolescence: it was first seen when cars with self-starting engines were produced, replacing the hand-cranked versions, in 1923 (Kline & Pinch, 1996). After this manufacturers realised that obsolescence worked very well for their commercial aims, and they found other ways of utilising it, such as psychological obsolescence and deliberate obsolescence. People are always willing to pay for fashion and style, as they think these enable them to present themselves as superior to others (Slade, 2006). At this point General Motors, in the United States, took the rapidly growing fashion and textiles industry as a model and identified and implemented psychological obsolescence (Packard, 1960). Their success again proved that obsolescence sells. 
The least ethical version of obsolescence, namely deliberate obsolescence, prevailed during the Great Depression (Slade, 2006). Bernard London published three essays offering planned obsolescence as an effective solution for ending the Depression in 1932. During this time manufacturers were looking for different ways of selling commercial goods, as warehouses were overstocked with products (Slade, 2006). They used inferior materials and mimicked failure to shorten the product lifespan. Other consumer strategies followed deliberate obsolescence, including advertising, packaging and branding methods, when the manufacturers realised that it was successful in creating repetitive consumption of their brands. 
In August 1927, advertising expert Earnest Elmo Calkins, founder of the Calkins and Holden agency, wrote the following in his article 'Beauty, the new business tool' for The Atlantic magazine: “ People buy a new car, not because the old one is worn out, but because it is no longer modern. It does not satisfy their pride. They refurbish the house, not because the old furniture is unable to perform its duties as furniture, but because it is out of date, out of style, no longer the thing. You cannot produce this state of mind by mere efficiency. You cannot make people substitute a new car that runs well for an old car that runs well unless it has some added quality. The new quality must be borrowed from the realms of good taste—smarter lines, newer design, better colour, more luxurious upholstery, more art, or at least more taste. (p.153)” 
Here the advertiser argues that it is not possible to sell a substitute car, even if it is more efficient than the one the user owns. This quote shows that style is the selling point for consumers because they are willing to pay for a new car just because it is modern, even if their old one works fine. Since then, people have followed the manipulations and consumption strategies which are current at any time. 
Vance Packard (1960) and Victor Papanek (1971) realised this manipulation and wrote about consumption strategies and how they affect people psychologically. In a hierarchical society in which everyone assesses and compares themselves with others, this system created a state of anxiety where old things are not valued and are regarded as embarrassing (Slade, 2006). Papanek (1971) discusses repetitive consumption and its environmental, social, economical effects and asserts, in his book Design for the Real World: Human Ecology and Social Change: “There are professions more harmful than industrial design, but only a very few of them. And possibly only one profession is phonier. Advertising design, in persuading people to buy things they don`t need, with money they don’t have, to impress others who don’t care, is probably the phoniest field in existence today. (p.9)” 
Similarly, John Thackara says, in the documentary film Pyramids of waste directed by Dannoritz (2010), ‘Our role in life seems to be just to consume things with credit, to borrow money to buy things we don’t need. That makes no real sense to me at all.’ (23:39) 
So is it possible to imagine an economy without planned obsolescence? During the nineteenth century most engineers and manufacturers designed and created products to last (Slade, 2006). The world’s longest-burning lightbulb is one of the great examples of this period (Ubeda, Barrat, & Cosima, 2010). This was produced in 1895 and is still alight in Livermore, California. Similarly, DuPont nylon stockings were sturdy and ladder-free when they were first produced (Rivera & Lallmahomed, 2016). Manufacturers tried to make nylon weaker so that they would not last as long. Today’s equivalent tights do not generally last for more than about three uses. 
Some people may argue that without planned obsolescence we would not have access to contemporary prosperity: there would be no designers, architects, cleaners, or shopping malls and none of these jobs would be required. 
The economic system that is based on planned obsolescence produces a constant stream of waste. Waste has been hidden during the industrial age, but we can no longer avoid it. The waste economy is, perhaps, reaching its last stage. John Thackara fights against planned obsolescence and shows us examples of existing alternative systems, citing Lagos kiosk traders, Indian jugaad tinkerers, Central American cooperative farmers, Danish bike-sharers and others (Thackara, 2015). He states that the notion of throwing away a product just because it breaks is completely unheard of and unthinkable in India, and he explains the jugaad tradition in India, which refers to fixing everything regardless of its complexity (Thackara, 2015). 
This historical overview is very important in order to understand that planned obsolescence is man made, and to realise how it became a part of our lives. People have no control over this problem and its detrimental effects; actually, the majority is inured to it. The throwaway mentality affects the way we experience and think about objects, the environment and ourselves, in a negative way, of course. Unfortunately, the trajectory of consumption has resulted in ‘other forms of cultural obsolescence including languages, cultural practices, traditions, vernacular knowledge and skills, farmed and wild genetic diversity and so on.’ (Maycroft, 2016, p.4).
Planned obsolescence has become more and more complicated since the industrial era, and now it encompasses numerous applications, such as programming electronics to stop functioning and the intentional design of many objects so that they cannot be repaired or adapted for alternative uses; many products now require and promote the subsequent consumption of extra goods and services (Maycroft, 2016). As opposed to dominant consumerist system various design approaches have developed supporting an environmentalist perspective. One of the newest approaches is circular economy which has drawn a growing attention over the last decade as a way to overcome current economic and environmental problems (Ghisellini, Cialani, & Ulgiati, 2016). The next section explains its origins, grounding principles, advantages and disadvantages.
Circular Economy
The circular economy is an industrial system that is based on ‘closing material loops in an economically attractive way to decouple wealth from resource usage.’(van den Berg & Bakker, 2015, p.365). It changes the understanding of the end of life of products, employs renewable energy and eliminates the use of toxic chemicals (Webster, 2013; Ellen MacArthur Foundation, 2012). The circular economy is receiving increasing attention in the last few years. As Prendeville et al. (2016) argue ‘Its integration in international policies from China, through its 11th and 12th ‘Five Year Plans’ (Su et al., 2013), to Europe through its Circular Economy Roadmap (European Commission, 2015) reflect the increasing importance of CE globally.’ (p. 278). Many circular economy studies including scientific reports, case studies, reports of government organisations and business representatives, etc. have been published (DEFRA, 2011; Ellen MacArthur Foundation, 2012; Su et al., 2013; IPCC, 2014; European Commission, 2015; Prendeville et al., 2014; WRAP, 2015; WBCSD, 2016). 
Closed loop system refers to a manufacturing model which does not produce waste and involves reverse flow of materials back to the system (e.g. repair, reuse, remanufacture, recycling) as well as forward flows of materials for production (Schenkel et al., 2015; Prendeville et al., 2016). With the aim of creating effective material and energy flows, two types of material flows are defined in the circular economy, including biological nutrients and technical nutrients (Bocken et al., 2016). Biological nutrients are organic materials, so they can be disposed of safely in the environment. Technical nutrients, however, are inorganic materials and cannot biodegrade. They are produced with high-quality materials and designed to have long lifespans, reused many times in the system with no loss of quality. 

Origins of Circular Economy
The circular economy is a synthesis of environmentalist approaches, including William McDonough and Michael Braungart’s ‘cradle-to-cradle’; Amory B Lovins’ ‘natural capitalism’; Janine Benyus’s ‘biomimicry’, Walter Stahel’s ‘performance/sharing economy’, and ‘industrial ecology’. These approaches are briefly explained in this section.

Cradle to Cradle
Cradle-to-cradle is a practical design framework for developing products and systems that aim for maximal economic value with zero adverse ecological impact (Braungart, McDonough & Bollinger, 2007). In this approach, all material inputs and outputs are seen as technical or biological nutrients. Each nutrient group has its own closed-loop cycles in an industrial or natural system. The avoidance of toxic materials and intelligent material pooling enables the elimination of waste by utilising it as a resource for production (McDonough & Braungart, 2002). Technical nutrients are recycled or reused with no decrease in quality, and biological nutrients return to the biosphere and are composted.

Natural Capitalism
Natural capitalism focuses on the changes which have occurred in natural resources, the pattern of scarcity we face today and the ever-decreasing natural capital. It offers a business model which involves four major shifts in business practices (Hawken, A. B. Lovins & L. H. Lovins, 2013). ‘Radically increasing the productivity of natural resources’ refers to savings in operational costs, capital investment, and time by changing companies’ production, design and technology. ‘The shift to biologically inspired production models and materials’ means eliminating the very concept of waste in closed-loop production systems inspired by nature. The outputs return to the ecosystem or are reused as a resource for manufacturing processes. ‘Moving to a ‘service-and-flow’ business model’ refers to delivering value as a service instead of selling products. Finally, ‘reinvesting in natural capital’ means making the most of natural capital by restoring, sustaining and expanding it.

Biomimicry
Biomimicry is an innovative approach towards considering nature as model, measure and mentor to provide innovative and sustainable solutions for industry and research development.
Imitating the systems and ‘designs’ found in nature, or taking inspiration from them, aims to solve identified problems (Benyus, 1997). The idea behind this approach is that nature has evolved highly efficient systems and processes that can inform solutions to many of the waste, resource efficiency and management problems that we encounter today. There are nine basic laws underpinning the concept of biomimicry: 1. Nature runs on sunlight; 2. Nature uses only the energy it needs; 3. Nature fits form to function; 4. Nature recycles everything; 5. Nature rewards cooperation; 6. Nature banks on diversity; 7. Nature demands local expertise; 8. Nature curbs excesses from within; 9. Nature taps the power of limits (Benyus, 1997).

Performance / Sharing Economy
The performance economy refers to an economy where the majority of the value is provided by services, and majority of jobs are in service activities (Stahel, 1997). The success of the present economy is measured by throughput and profit, whereas the performance economy is based on optimising the use of products and services and management of existing wealth (Stahel, 1997). Unlike the throughput economy, this system enables reduced resource consumption without waste, externalisation of costs and risk (Stahel, 2008). Greater competitiveness can be achieved through a functional service economy in which users pay per unit of service they receive and service providers reduce the resource flows and this, of course, will increase their profits by decreasing their material and energy costs (Stahel, 2008).

Industrial Ecology
Industrial ecology is a system-based multidisciplinary framework that serves to identify and implement strategies to reduce the environmental impacts of products and processes (Thomas, 1997). It studies material and energy flows in an industrial system, changing its linear nature to a closed-loop approach, and tries to eliminate by-products and waste. This framework provides an understanding of the global impacts of industrial systems by measuring and analysing the physical, chemical, and biological interactions and interrelationships within industrial systems (Graedel, Allenby, & Linhart, 1993). The production processes designed and organised by industrial ecology mimics living systems, with the ultimate goal of sustainable development.

Limits of Linear Consumption
The linear ‘take, make and dispose’ system depends on large quantities of resource and energy use that cannot be sustained with the planet’s finite resources (Figure 4). Many companies have recently been aware of the risks and damage that the current economic model is causing to both them and the environment. Cisco and Philips can be highlighted as examples of these businesses that have generated circular economy teams. One of the major problems for manufacturers is the acquisition of raw materials, because of gradually decreasing resources (Dobbs et al., 2011; Ongondo et al., 2011, Ellen MacArthur Foundation, 2012). According to an Ellen MacArthur Foundation report, the price volatility of metal, food and non-food agricultural outputs was higher in the first decade of the twenty-first century than any decade in the twentieth century (2012). More and more businesses face unpredictable prices in resources markets and high competition in the market. Therefore, business leaders are in search of better industrial models and more efficient raw material usage (De los Rios, & Charnley, 2016; Ellen MacArthur Foundation, 2012). These facts imply that action should be taken to fulfil the needs of business, and particularly to overcome the ever-growing environmental problems. 
The linear type of economy has been dominant in the world since the beginning of industrialisation, but according to circular economy experts it is reaching its end (Ellen MacArthur Foundation, 2012). Unlike the circular economy, the value the linear economic model creates is neither long lasting nor sustainable, either in terms of users or manufacturers.

Grounding Principles of the Circular Economy
Design out waste 
There is no such a thing as waste, according to this principle. According to this principle, products are designed and produced for disassembly and reuse through the ‘product cycle’ and the ‘component cycle’ (Ellen MacArthur Foundation, 2012). This feature is different from disposal and recycling in many aspects because both disposal and recycling rely on a significant amount of labour and energy usage. 
Consumable and Durable Components 
The circular economy differentiates products or their components as consumables or durables. Consumable products are made of biological ingredients or nutrients, while durables are produced with technical nutrients like metals and plastics (Ellen MacArthur Foundation, 2012). Biological nutrients are non-toxic and can safely dissolve in the biosphere. Technical nutrients, on the other hand, are detrimental for the biosphere and they are designed to be reused from the beginning of their life. 
In the current economic model, companies do not admit much responsibility after selling their products. The circular economy offers a different relationship between customers and business for technical nutrients. Durable products can be leased, rented or shared when possible (Ellen MacArthur Foundation, 2012). If they are sold, the company makes a contract with the user that ensures the return of the product to the manufacturer at the end of its primary use. This principle replaces the term ‘consumer’ with ‘user’ and enables the reuse of the products. 

Advantages for Users and Companies
Besides its significant environmental benefits, the circular economy model offers value not only for companies but also for users. The circular economy’s advantages for users include reducing the costs associated with planned obsolescence, increased choice and convenience (Winkler, 2011; Ellen MacArthur Foundation, 2012; Schenkel et al., 2015). Premature obsolescence costs disappear when products are designed for durability and a long lifespan. Planned obsolescence means that users pay for low-quality, short-lifespan goods repeatedly. Total ownership reduces the cost for users, as companies retain the ownership of products. Additionally, high-quality, non-toxic, circular products will improve customers’ quality of life. For example, MUD Jeans, a denim company based in the Netherlands, offers a leasing option to customers for their jeans, aiming to increase the circularity of jeans production. First, customers benefit from the use of high-quality, durable and ethically produced products. Second, customers do not need to worry about the costs of premature obsolescence, such as paying the whole price for a pair of jeans and then finding the product becomes obsolete, gets damaged and they can no longer wear it. Here customers only pay for the period during which they wear the jeans. Thirdly, the company offers a free repair service if the product gets damaged, and a recycling service at the end of its use phase (MUD Jeans, n.d.). The circular economy changes the ‘style’ of buying. Unlike the current purchasing system, there are diverse choices for users, which are presented and sold with contracts. As users decide how long they use the products and how they use them, choice and convenience increase. Users can choose the product parts and functions that they need from a range of diverse solutions. In the case of MUD Jeans, the user signs a contract with the company before leasing the jeans. According to this contract, the customer can swap their jeans for a new pair, continue using the same jeans without paying for them or return the jeans to the company. The company makes a profit by leasing the jeans: they lease the newly produced jeans as well as the returned ones that are in good condition and recycle the rest (MUD Jeans, n.d.). Recycling lowers the material costs, mitigates the effects of price fluctuations and at the same time decreases the environmental impacts of cotton production. 
Companies are currently facing many challenges, such as increasing bills for materials, the price volatility and the growing waste problem, and these problems are expected to increase in the near future (Schenkel et al., 2015). Additionally, the ethical issues, including conflict minerals (see Section 2.12.2), human rights abuses, labour rights and many others, cause a real risk of complicity in these abuses on the part of multinational companies who come into contact with these problems (Ellen MacArthur Foundation, 2013). The most important benefit of the circular economy for companies is mitigating the challenges they face today. These benefits include reduced materials bills and warranty risks, improved customer interaction and loyalty, less product complexity and more manageable lifecycles (Ellen MacArthur Foundation, 2013). Of course, producing durable and long-lasting products affects warranty costs positively. A decrease in material costs is also an expected result, with the help of the reuse of products and technical materials.

Challenges of Circular Economy
The challenges or barriers to achieve the circular economy have been largely discussed in the literature (Geng & Doberstein, 2008; Preston, 2012; Prendeville et al., 2014). The majority of the scholars mainly focus on practical issues of implementation (Grant & Banomyong, 2010; Kuo, 2011; Kuik et al., 2012; Souza, 2012). I discuss these challenges according to four groups: high up-front costs, complex supply chain, a completely closed loop system and behaviour change issues. 
High up-front costs: The circular economy would offer higher profits for the businesses in the long-term, however, the up-front investment costs and risks are inevitable and high (Preston, 2012, Prendeville et al., 2014). These costs include purchasing new machinery, building new distribution arrangements, transforming a company’s business model etc. 
Complex supply chain: Another significant challenge is the supply chain management. Manufacturing operations and consumption take place in different countries in the current global system (Preston, 2012). The entire network of resources, manufacturers and customers may have to be reorganised in a circular economy. 
A completely closed loop system: The aspects that influence the recycling and remanufacturing activities are complicated ranging from economic to technical factors. Therefore, some experts argue that it is difficult and expensive to achieve a completely closed loop circular economy (Hopewell et al., 2009). 
Behaviour change issues: The circular economy requires a different and more active relationship between users and products as well as users and producers (Shah, 2014). Users need to understand and value the circular system and products to be able to participate in it (Preston, 2012, Prendeville et al., 2014). This research draws attention to the complex nature of this relationship and presents examples which can be compared with current products and systems, exploring values different from those currently espoused. Products will only last longer when people consider them as worthy objects, see their material value and realise their immaterial aspects, and understand opportunities for products to age in a dignified way. More research, strong policy frameworks and incentives are needed to encourage users to change their behaviour as well as businesses to invest in a circular system and take the risks (Preston, 2012).

The Transition to a Circular Economy
It is not possible for companies to transform their business into a circular model overnight. For both companies and users the transition will take time and effort, and we are at the beginning of this process (Dobbs et al., 2011; Ellen MacArthur Foundation, 2013; De los Rios, & Charnley, 2016). There are two different scenarios observed in this transformation period offered by the Ellen MacArthur Foundation (2013). First, in a transition scenario, companies utilise existing technologies and services in order to transform the product design into a circular model. In this scenario, companies aim to increase recycling, refurbishing and remanufacturing activities. The second, more advanced, scenario is different from the first, as it requires a radical transformation. This scenario is radically disruptive because, like the Industrial Revolution, it transforms the way we currently produce and consume and allows the new solutions to supersede the established system. Developing infrastructure, creating cross-sector collaboration and legal frameworks are essential conditions of the advanced scenario (Ellen MacArthur Foundation, 2013). With the help of a structural shift, this scenario provides net material cost savings for the company.

The Role of Repair in the Transition Stage
The verb ‘to repair’ is defined as: ‘To restore (a damaged, worn, or faulty object or structure) to good or proper condition by replacing or fixing parts; to mend, fix.’(Repair, 2009) in the Oxford English Dictionary. This research studies self-repair which refers to user’s repairing a product by himself/herself according to instructions or his/her skills and knowledge. Again in the Oxford English Dictionary, the noun maintenance is defined as: ‘The action of keeping something in working order, in repair, etc.; by providing means for equipment, etc.; the state or fact of being so kept up; means or provision for upkeep.’ (Maintenance, 2000). The main difference between maintenance and repair is the ‘breakdown’ which can be defined as the disruption of perceived function of the product or its value in the context of this research. As damaged products may not always perceived as broken, two types of damages can be identified the ones that reduce the appeal of the product and the ones that enhance it. One of the most common examples for these types of damages is ripped jeans. Ripped parts might enhance the appeal of the jeans if they are in the knees. However, it might reduce the appeal if the jeans rip in the inner thigh. Repair comes after the breakdown. It refers to developing a solution for restoring the product back to its perceived functionality and value. Sewing holes in the socks, glueing broken parts of a plate and changing spare parts are examples of repair. Maintenance refers to all activity for keeping something in working order. Cleaning, lubricating and polishing are examples of maintenance acts. 
The transition stage has just begun, and the world is now full of low-quality and short-life span products that are not designed for repair, disassembly and recycling. These products cannot just be discarded because they are not suitable for the circular system. The most environmentally friendly product is the one you already own, because it does not require raw materials extracted from the earth and energy for manufacturing. As I illustrated in the transition stage diagram (Figure 5), the aim should be to lower the rate of production and make the most of existing products during the transition stage. 
One of the main principles of the circular economy is ‘zero waste’, which means that the waste from one system is the food of another. This principle is most effectively achieved by repair and reuse, where no virgin materials are used. However, two fundamental aspects are required here: product design requirements and active users (Shah, 2014; Ghisellini et. al., 2016). First, the products must be designed in accordance with the basic principles of the circular economy, also considering the users’ needs and wants. Second, awareness should be created among users in order to enable their participation in closing the loops by repairing products, returning the products back to the producer and creating a demand for circular products. The first condition has already been achieved: designers are capable of designing high-quality, long-lasting, circular products that can be repaired and disassembled easily. The challenge for product designers is to connect people with products again and overcome the problematic relationship between humans and objects. 
The relationship between people and products has completely changed with the throughput economy and the linear system, and it has become a continuously problematic relationship. The conditions of the current system have created a society of ‘passive consumers’, expected to become ‘active users’ in the circular economy. The circular economy offers a rethinking of ownership in which a need for a shared responsibility among all stakeholders exists, including consumers, in order enable the return of products for reuse, repair and remanufacturing, as well as collection of waste for recycling (Ghisellini et al., 2016). This transition requires a change in user behaviour, attitudes and understanding. However, most people perhaps do not even realise the value of products or their materials any more. Additionally, they are not aware of the methods of getting the most value from their products. 
As can be seen from the Ellen MacArthur Foundation’s system diagram (Figure 6), repair (‘maintain’, in the diagram’s terminology) is the inner circle of the circular system. It may be easier for users to relate to this complex economic system through the inner circle. The inner circle is where consumer thinking and behaviour can be changed, as it is easy to communicate this issue with people around the topic of repair. 
One of the goals of the circular economy is to keep products in circulation for longer and use tighter inner loops. This means maximising the time spent in each cycle by prolonging the use life and enabling maintenance, repair and reuse, rather than recycling. Maintenance and repair preserve the embedded energy and value in the product (Ellen MacArthur Foundation, 2015a). Thus, recycling and remanufacturing can be a source of value creation if repair is no longer feasible. When the cycles are lengthened, the material, energy and labour needed to manufacture a new product are avoided (Ellen MacArthur Foundation, 2015a).

Innovative Business Models
The circular economy offers a systematic solution to many environmental problems, covering in particular the economic dimension of sustainability, including planned obsolescence. It presents different business models that transform the relationship between customers and business (Bocken et al., 2016). 
Alternative business models that develop environmental benefits while fulfilling economic constraints have begun to claim the attention of business leaders. These alternative models are beneficial in many aspects, including extending product life and preventing resources and materials from becoming waste (WRAP, 2014; De los Rios & Charnley, 2016). Companies can launch a new business model that they have never considered before, or they can transform an existing business model into a circular one according to its requirements. These business models are also beneficial and effective for experimenting with the embedding of sustainability into the underlying structure of commercial businesses. Philips’ Pay Per Lux project is an example relating to this statement; it is explained in a case study in Section 2.10.1.2. The innovative business model map in Figure 7 shows the diversity of business models available.

Product Service Systems
Quite different from the selling of physical products, Product Service Systems (PSS) is a business model that focuses on providing a system of products and services that respond to the needs and demands of the client (Manzini & Vezzoli, 2002). The transition from physical products to PSS means developing a new way of interacting with users. Companies that implement this business model provide additional services in order to ensure utility and endurance. These additional services may include maintenance, repair or upgrading for a specified period and are applied according to the service contract signed between the company and the client. The system of products and services can be designed to offer long life or short life options for the products, depending on the requirements. They can be designed for disassembly, remanufacture and reuse, as companies take the products back at the end of the contract to reuse or recycle them.

Case Study: Philips Pay Per Lux Solution
Philips is a Dutch technology firm that consists of three main divisions: Philips Consumer Lifestyle, Philips Healthcare, and Philips Lighting. It has a diverse product range that includes electronics and electrical products (smartphones, televisions, small domestic appliances, etc.); healthcare products (MRI scanners, ultrasound equipment, CT scanners, etc.); and lighting products (indoor and outdoor luminaires, automotive lighting, etc.). Philips values sustainability and focuses on reducing the environmental impact of its operations. The firm sees the transition from the linear economy to the circular economy as one of the most important conditions for a sustainable world (Philips, 2014). Philips have been exploring circular innovation within their company, aiming to pioneer the circular economy in the areas of healthcare, consumer lifestyle and lighting. 
RAU Architects is an architectural firm in Amsterdam that has been working for sixteen years in both the public and private sectors (RAU Architects, n.d.). The studio adopts an environmental approach and values making a positive contribution to the world. Thomas Rau, founder of the RAU Architects, wanted to change the lighting at his agency and contacted Philips Lighting. He did not want an expensive lighting structure that needed maintenance and eventual replacement. He wanted to have light as a service that suited the building. Philips Lighting developed a new sustainable and cost-effective way of delivering light for RAU Architects. Through the project, called Pay per Lux, users get the exact amount of light they need in their workspaces and rooms and pay as they use it (Philips Lighting, 2012). 
The Solution 
Philips Lighting presented two lighting scenarios to RAU Architects. In the first design that Phillips proposed, the level of lighting was high and there were personally dimmable areas. However, Thomas Rau wanted to make more use of natural light, and accordingly reduce the amount of artificial light as much as possible in the office. After these negotiations, his requirements led the project in a different direction. Philips decided to develop a new kind of lighting plan focusing on the services provided. 
In the end, Philips created individual lighting modules floating over workplaces, which could illuminate the required areas while the rest of the office remained dim. LED light fittings for ceiling systems are hung in the high-roofed offices. Sensor and controller systems are utilised together to minimise the energy use. As the project team wanted to benefit from natural sunlight as much as possible, sensors were used to control the intensity of artificial lighting according to motion and the amount of available daylight (Figure 8). 
Moving away from the one-off sale to a performance-based model, the project provided a variety of benefits for both Philips Lighting and RAU Architects. The lighting system resulted in a thirty-five to fifty-five per cent reduction in total energy use following the installation (Philips Lighting, 2012). A further twenty per cent reduction in energy use was also observed after the optimisation carried out by Philips (Philips Lighting, 2012). Furthermore, maintenance, repair and the upgrade of the products are included in the Pay per Lux concept. Philips maintains ownership of the materials and is responsible for fixing broken parts and upgrading the existing system when the users need it. Philips reclaims the materials and products at the end of their use life and directs them to LightRec, Philips’ partner organisation responsible for the reuse and recycling of lighting components. 
The most important benefit of this collaboration for Philips is that they now have a new and sustainable model for lighting. Many architectural agencies and installers contacted them to learn more about the project and requested the installation of LED luminaires for projects of their own (Philips Lighting, 2012). After seeing the potential of a performance offering, Philips is now further developing the business that underpins this model and drawing up contracts that systemise the concept.

Hire and Learning
This is a usage-based business model where companies retain the ownership of the product and lease or share the usage of it. Companies keep the resources and the value of energy and labour embedded in the products. This model improves the longevity of products with services such as maintenance, repair, upgrading and the use of high-quality materials in manufacturing. According to the Innovative business model map (WRAP, 2014), long life, reuse and incentivised return circles encapsulate the two other business models (Figure 7). In order to extend the product lifespan, companies should design and produce them for maintenance, repair and upgrade. Incentivised return encourages users to return the products to manufacturers for a specified value (WRAP, 2014). Users benefit from gaining value from an unwanted product. Companies get the value of materials, energy, and labour embodied in the products back, and they refurbish these products and reuse them. 

Repair Business Models
Fixed Price Repair : Repair service is offered to customers at a fixed price independent of the nature of the damage. 
Repair Service Offered by Reuse Organisations : This business model is currently used for electrical and electronic items. Organisations collect second-hand, damaged or malfunctioning items. They then repair those items and prepare them for reuse, selling them online or in a shop. 
Exchange Repair Service : This business model suits high-volume and high-technology products. The company provides the same model or an equivalent of the product to the customer after receiving the faulty product. The damaged product is diagnosed and repaired as new. Finally, it is sent to another customer

Visible Repair of Ordinary Everyday Objects
This research does not focus on a single product category: rather, it focuses on physical damage. Physical damage refers to damage and defects which disturb or intervene with the usual ways a product is used. Broken, cracked or worn-out products, and also torn-apart, unstitched or frayed textiles are examples of physical damage. This categorisation does not include electrical or electronic problems; however, electronic and electrical products, of course, can be physically damaged: a mobile phone with a broken plastic housing, for instance. Although there is no single product category focus, this study mainly explores fast-moving consumer goods such as textiles, shoes and leather goods, and ceramic and medium-lifespan products such as glass products, small furniture, utensils and toys. Such objects are the ‘ordinary everyday objects’ referred to in the thesis.
This research is mainly focused on visible repair, which refers to the creative act of fixing an object with the aim of making something unique and beautiful out of it without hiding the damage, creating a new aesthetic language that honours the traces of the object’s life. Visible repair encourages thoughtful assessment as well as aesthetic appreciation of the act of repairing and the repaired object. The act of repair itself becomes an experience which goes beyond mere personalisation of products, enabling people to develop both skills and confidence (Spelman, 2003). Visible repair forms a challenge to our ways of thinking about things, giving us a much fuller knowledge about a product than buying a new one, since it involves engagement with its materiality. 
Examples of visible repair can be seen in art, design or everyday life. An example from art can be artist Charlotte Bailey’s (2016) method to repair broken ceramic products. Inspired by the Japanese traditional repair method kintsugi, she covers the broken parts with fabric pieces and patchworks them together with gold metallic thread (Figure 9). 
Woolfiller is a visible repair example from design. It is a darning kit to repair holes and cover stains in woollen clothes with special wool, a felting needle and a poke needle (Figure 10). The fibres of wool are pricked with a felt needle to create a patch on the damage. Heleen Klopper (n.d.) used woolfiller as a part of an exhibition about sustainability. She started to design it as a kit after so many visitors were interested in the method and wanted to use it.
Similarly, 5.5 designstudio from France uses the visible repair approach in their project called Reanim (Figure 11). This project is a collection of prosthetic seats and legs to repair damaged furniture (5.5 designstudio, 2004). The bright green colour and transparent product parts transform the damaged and old objects into an interesting hybrid suggesting a new aesthetics of imperfection and actively involving users in the repair process.
The examples in Figure 12 show how old the visible repair approach could be. Erik Kwakkel is a book historian who investigated book producers from medieval times and discovered how they turned damaged parts of parchment into art. As parchment is made out of thin membranes of animal skin, it would get damaged during the manufacturing process (Kwakkel, 2013). These examples show how book producers used embroidery with coloured threads to tie the holes together.
The approach related to visible repair used in this thesis can also be seen in similar examples in architecture. Materials that differ from those in the original in terms of texture and colour are used to differentiate the reconstructed parts, while the remaining elements of the heritage are consolidated in this type of restoration. David Chipperfield Architects’ (2005) Castello Sforzesco project in Milan is an example of this approach (Figure 13). The architects restored the medieval building in accordance with its historic form. The new additions were made out of brick and stone with no decoration, expressing the difference between old and new. 
The Astley Castle restoration project, shown in Figure 14, is another example, and this project won the Royal Institute of British Architects Stirling Prize for the greatest contribution to British architecture in 2013 (Wainwright, 2013). Astley Castle was converted into a holiday home, blending old and new, by the Landmark Trust in 2012 with the architect Witherford Watson Mann (Wainwright, 2013). In this approach, the remaining structure, with ruined parts and traces of previous restorations, reflects the history of the building. Differentiating the restoration in this way provides valuable information, such as the effect of, or the reason for, the damage, and the building becomes more meaningful with this historical background, like the traces of a product's life which can tell its story

Case Studies
Case Study: Patagonia
Patagonia is an American outdoor clothing company that produces high-quality, environmentally friendly garments that can be repaired and have a lifetime guarantee (Figure 15). It was founded in the 1970s, and was one of the first environmentally conscious companies in the clothing industry. They incorporated repair into their business system to save their sustainably made clothes from becoming waste, because even the most durable and well-made clothes can tear. Patagonia operates the largest garment repair facility in North America and carries out more than 40,000 individual repairs a year (Marcario, 2015). 
Patagonia offers more than forty ‘repair & care’ guides and repair tools on their website, besides the repair service they provide in their repair centre (Figure 16). For example, the Patagonia expedition sewing kit has been developed in collaboration with the iFixit company in order to encourage users to repair their clothes by themselves (Figure 17). The company also has a Worn Wear programme that presents stories about the repaired garments and provides an easy way to recycle them when they are beyond repair. 
The company launched a cross-country mobile repair tour in 2015 with a repair truck. They offered a repair service for any piece of clothing, regardless of the brand. The tour’s ultimate goal was not to achieve a certain number of repairs but to spread the ‘if it’s broken, fix it’ mantra.

Case Study: Fairphone
Fairphone is a social enterprise that aims to create a fairer economy and transform how we produce and use objects, starting with the mobile phone (Fairphone, 2014). Revealing the story behind the electronics supply chain, Fairphone focuses the world’s attention on the severe environmental and social problems in the industry (Figure 18).
Fairphone started as a campaign within the Amsterdam-based digital media cultural organisation Waag Society in 2010 to raise awareness among consumers and in the mobile phone industry about conflict minerals (Fairphone, 2014). It was established as an independent social enterprise in 2013 in order to take the campaign a step further and produce mobile phones responsibly with regard to the environment and society. The enterprise became successful. 25000 Fairphones were sold in 2013 and now a second batch of 35000 Fairphones is on sale. Crucial problems exist in the mining sector, where precious minerals such as tin, gold, tantalum and tungsten are extracted and transferred to the electronics industry. Illegal mining of these minerals perpetuate the conflicts and wars between various governmental and rebel armed groups in a number of African countries. Working conditions in the mines are harsh and dangerous, with problems such as child labour, neglected workers’ rights and pollution. The Fairphone team works closely with suppliers and manufacturers in order to improve the working conditions of miners and other workers and increase local wages (Fairphone, 2014). They strive to decrease the degradation caused by mining practices. Fairphone only uses tin which has been certified by the Conflict Free Tin Initiative in its production. Designing a smartphone with a longer lifespan is one of Fairphone’s main considerations. They aim to achieve this goal by making it easy to open, with replaceable product parts. Fairphone has been selling spare parts for the phones via their website since January 2014. Moreover, Fairphone has collaborated with iFixit to provide people with guidance for the repair process. Ten repair guides for different malfunctions of the Fairphone are available on the ifixit.com website.
Users can follow the step-by-step instructions and photographs to repair their phones (Figure 19). As well as complex operations like changing the display or the motherboard, easier replacements that require fewer steps, such as the replacement of the back cover, battery and SIM card are explained in detail. This website provides users with the opportunity to ask questions and open conversations. Questions are answered by Fairphone technicians, experts and other users who have encountered similar problems. 
The company designed the world’s first modular smartphone, the Fairphone 2, which will appear in stores in May 2017 (Figure 20). The company has focused on longevity and repairability. Fairphone 2 was designed in a way that encourages users to access the inside of the phone. This phone offers a different relationship to users from that of the other consumer electronics products on the market. It invites people to look inside and repair or upgrade the phone when necessary. Modular parts give the user more control over their phone, as it can be easily opened and no special tools are required (Oliver, 2015).

Case Study: Riva 1920
Riva 1920 is an Italian wooden furniture company characterised by reliable and long-lasting products. This company is included in this thesis because it provides maintenance sets with its products in order to prolong their use life. Moreover, the company offers maintenance and repair instructions on their website for dents and scratches, and videos with stain removal instruction.
The maintenance set that comes with Riva 1920’s Piano bookshelves is an example of users being encouraged to take care of their products. The bookshelves are designed in a way that allows easy replacement and upgrading of the components (Figure 21). With the aim of providing lifelong maintenance, the bookshelves are sold together with a maintenance kit that includes a set of small tools and materials such as oil-based paints and natural wax to finish surfaces, which can be used if the product is scratched or damaged (Figure 22).

Case Study: Droog Design
Droog Design is a Dutch design company founded in 1993 by product designer Gijs Bakker and design historian Renny Ramakers. This company critiques over-consumption and materialist culture through their design ideas that focus on recycling and reusing materials and found objects (Ramakers, 2002). Droog Design’s approach has been followed by prominent designers, artists and architects (Ramakers, 2002). Challenging the dominant culture, they value everyday mundane objects and celebrate the qualities of inferior things (Ramakers, 2002). As Ramakers has said: ‘They leave room for decay, for improvising, for chance, for familiar, the archetypical. Products are allowed to wear out and fade away’ (2002, p.6). 
The experiential dimension of products was emphasised in the Droog collection. Significantly, in the ‘Do create’ project the experience comes before the products (Ramakers, 2002). ‘Do create’ is a collaborative project that started in 2000 and features a range of design ideas from different designers that aims to make consumer products more active (Ramakers, 2002). Users are able to interact with the products and influence the design. The products are completed with the action of the users. These actions include shaping a chair with a sledgehammer, in the case of the ‘Do hit’ chair by van der Poll (Figure 23), breaking a vase in ‘Do break’ by Frank Tjepkema (Figure 24) and Peter van der Jagt and swinging on a lamp in the case of ‘Do swing’ by Thomas Bernstrand. The ‘Do create’ project is an example of enabling people to have relationships with objects that are different from those the dominant system allows. It encourages people to engage with the products in a creative way, and the results of this engagement are spontaneous, special and challenging.

Case Study: iFixit
Ifixit.com is the world’s first free repair manual, containing thousands of online repair instructions for various items, including consumer electronics and household appliances (Wiens, 2015). 
The company provides repair guides, product teardowns and a forum for users on the website. Effective knowledge and guidance are offered about product repair through tutorial videos, repair guides and product teardowns (Getto & Labriola, 2016). Teardowns are detailed, and the repair process is illustrated step by step, with related visuals. Repair guides target people at every skill level and inform users by providing a scale for the level of difficulty. Even instructions on how to use a screwdriver are included. A forum enables users to share their experience and discuss the difficulties they face during repair work. 
The company partners with a number of manufacturers such as Patagonia and Dell to make their products more repairable, develop repair guides for their products and provide tools and spare parts (http://ifixit.org/resources). They also work with other organisations, including Repair Cafes and the Ellen MacArthur Foundation. 
IFixit’s aim is to facilitate a future where people have the legal right to repair their stuff and the resources and the confidence to carry out the repairs (Wiens, 2015). The company empowers customers and creates awareness by encouraging self-repair (Scott & Weaver, 2014). IFixit emphasises the value in repair practices to business and customers, which is central to circular economy thinking. What this company is doing is crucial in terms of creating awareness and empowering people, and it represents a great example of a very successful business based on fixing objects in a world where local repair shops have closed and companies do not provide repair manuals and spare parts. 

The case studies presented here are six successful business examples from five different sectors: electrical and electronic products, textiles, consumer electronics, furniture and the service sector. The most important fact that these examples demonstrate is that the throughput-based, linear type of economy is not the only option for a successful business. There are only a small number of companies following this environmental and ethical path, because most manufacturers argue that it is not possible to make a profit if they produce and sell long-lasting, high-quality products. However, the linear economy is an ancient system that is detrimental to the environment, society and the economy. Since industrialisation, experts and researchers have developed various economic approaches, like the circular economy, which offers benefits for manufacturers as well as users and the environment. The approaches these companies employ can be scaled up to other product types, and other companies can also take these approaches as models. For example, a significant reduction in e-waste would be enabled if other consumer electronics companies sold spare parts on their website in the way that Fairphone does. Additionally, the sewing kits that Patagonia developed, and Riva 1920’s maintenance set, are great examples that encourage users to fix their products. Similarly, this research looks at different ways of encouraging people to repair their products.

Design Activism and Repair Platforms

Activism refers to taking actions to inculcate change for the purpose of generating social, cultural or political transformations (Fuad-Luke, 2009). Design activism similarly aims to change society, the economy or culture in a positive way and presents and supports possibilities other than those that already exist (Fuad-Luke, 2009). Design activism has the potential to bridge the gap between people’s behaviour and emotions and enable them to make the connection between ‘what they do’ and ‘what they feel about doing this’ (Markussen, 2013). As a result of this, an awareness of environmental and social problems can be created, and the current system can eventually be disrupted. 
A large number of design activist cases exist, with various applications. Thorpe argues that design lacks a theoretical framework for activism (2008). Then, based on sociological studies, she develops a framework and presents six different categories: design activism as a ‘demonstration artifact’, that provides alternative products superior to the existing ones; ‘info/communication’ category, that refers to making information visible; ‘conventional actions’, acts such as proposing legislation, conducting research and testifying at political meetings; ‘service artifacts’, which refers to providing humanitarian aid; the ‘events’ category includes conferences, exhibitions and talks; finally, ‘protest artifact’ is a confrontational object that critiques the morality of the status quo. 
Repair is already an act of activism, because it challenges the status quo or ‘normal behaviour’ as perceived by society. It suggests a different way of valuing artefacts and creating a different relationship with them. As an example of design activism, the Repair Cafes organisation (explained in a Case Study below) aims to raise awareness about environmental and social problems and empower people by teaching them how to repair. The Repair Cafes around the world organise events to bring together people who need a specialist repair service with repair technicians and enable people to give their products another chance. Restart Project is a platform similar to Repair Cafes that encourages people to repair their electronic products by organising repair events. Information and techniques for people who want to repair their own products are available across the internet. Websites such as ifixit.com, fixya.com, howstuffworks.com, fixperts.org, thingiverse.com and familyhandyman.com provide useful information about fixing various objects. Similarly, eSpares is a UK-based retailer which provides spare parts, consumables and accessories for electrical appliances. 
A considerable number of people contribute to this online repair movement. People repair broken products in various creative ways and post images of the process on websites. They also provide 3D computer-aided design (CAD) models of different products. Thingiverse is one of the websites on which users share digital design files for 3D printers, laser cutters and milling machines, etc. The broken handle of the joystick in Figure 25 is an example from this website. It is repaired by using a 3D printer. The tripod quick-release mount replacement in Figure 26 is repaired in the same way, by 3D-printing the broken product part. There are more than 25,000 digital things, ranging from a lens cap to a stove knob (Figure 27), available to download and make (Makerbot, 2012). From 2008 to 2012 digital files of things on Thingiverse had been downloaded more than 8.5 million times (Makerbot, 2012). 
It can be seen from online user platforms that there are people who want to fix their broken stuff. However, factors such as the design of products, unavailable spare parts and the high cost of repair prevent some of them from doing so. Chapter 4 includes a cultural probe study of people who want to fix their products and I explore their motivations: some of the factors mentioned here are considered as barriers that people experience around the activity of repair. 

Case Study : Repair Cafes
Repair Cafes are among the most influential new platforms and places emerging from a new wave of grassroots organisations (Charter & Keiller, 2014). They are meeting places in which people bring damaged products and fix them with the help of volunteer repair specialists (Figure 28). 
Five hundred Repair Cafes are active around the world. Visitors learn a range of details relating to repair and product use while working with repair specialists. According to a recent study, sustainability is one of the main drivers of participation in relation to the activities undertaken in Repair Cafes (Charter & Keiller, 2014). According to results of the study, more than eighty per cent of the volunteers in Repair Cafes are motivated by encouraging others to live sustainably and provide valuable services to the community to help product repairability and longevity (Charter & Keiller, 2014). 
Tools and materials are available in these meeting places to enable participants to carry out any repair they need, on clothes, furniture, electrical appliances, toys, etc. Participants not only get their objects repaired in Repair Cafes; they can also modify clothes, and electrical and electronic equipment and components are upcycled – in other words, reused for different purposes or transformed into new products in a creative way (Charter & Keiller, 2014). According to the responses which were given on a five-point Likert scale from always to never, the five categories of products that are most frequently brought to Repair Cafes for repair are small kitchen appliances, lighting, clothing, bicycles, and DVD/CD players (Charter & Keiller, 2014). 
Providing the means to repair products, Repair Cafes perform a very effective task in terms of environmental responsibility. They enable, encourage, and inspire people to look at objects differently and help to divert waste from landfill through repair and reuse.

Existing Research Related to Repair
Among several different areas of research that study product repair, two main areas stand out: sustainable design practices and studies that aim to inform Human-Computer Interaction (HCI). Product repair is frequently mentioned in the literature on sustainability and the circular economy as a way of extending product lifespan and ‘closing the loops’. However, few of them study repair in detail; in other words, the majority of these studies go no further than mentioning it as a strategy for product longevity. 
Researchers have mainly explored ways of decreasing the number of products in circulation by prolonging their use life through repair and reuse (Cooper, 2013; Fletcher, 2012, Mont, 2002). Repair is also included in the literature on the circular economy that looks at business models and strategies as a strategy for closing the loops (WRAP, 2014). With an approach similar to circular business model studies, Vezzoli and Manzini (2008) suggest after-sales services as a more eco-efficient way of marketing than providing more products. They look at the issue of product longevity and study it in correlation with services offering maintenance, repair and upgrading (2008). In this case, product services are offered and controlled by the producers; this rationalises the production of durable products for them, because they retain ownership of the products.
Repair is currently experiencing a revival, as a consequence of grassroots organisations and initiatives which seek to promote repair, reuse and other creative forms of waste prevention (Charter & Keiller, 2014; Middleton, 2012). Charter and Keiller conducted an online survey of the members of Repair Cafes and hackerspaces around the world to understand the importance of sustainability as a driver for participating in these organisations. They found that the strongest motivation for volunteers to take part in these organisations is the desire to do something for others. 
The literature on product repair is primarily focused on self-repair, and mainly addresses the context of the workplace (Orr, 1996; Suchman, 1987; Balka & Wagner, 2006) and the home (Maestri & Wakkary, 2011; Crabtree & Rodden, 2004; Taylor & Swan, 2005). Maestri and Wakkary’s research, for instance, explores how creativity plays a role in the repair and reuse of objects in the home (2011). This study aims to enable design technologies to extend product life through repair and further shows that design is an ongoing activity that includes the repair, appropriation and modification of objects. 
Apart from product design, repair has been studied within various disciplines such as textiles, clothing, architecture and others. (Cooper et al., 2013; Fletcher, 2012; Laitala, Boks, & Klepp, 2015). For example, Laitala et al. explore the possible extension of product lifespan to provide reasons to delay the disposal of clothing by improving its design. They discovered seventy reasons for disposal and developed design solutions for the most significant ones. Similarly, Middleton studied a technological system for smart wardrobes that extends the garment’s lifespan (2012). She states that the repair activity demonstrates the impact of things on humans because products make humans think they worth mending (2012). Similarly, Graham and Thrift say that repair represents the power of things, as the thing draws attention to itself and manifests itself existentially according to Heideggerian thinking (2007). Their paper focuses on modern cities and all the processes of repair and maintenance that keep cities going. The authors aim to give these repair and maintenance processes in cities the attention they deserve, as they are hidden from view and not currently acknowledged or known about (Graham & Thrift, 2007). 
A growing body of research in HCI has been studying repair to explore and understand the human-technology relationship further (Houston et al., 2016). One of the most influential studies is Suchman’s (1987) ethnographic research in which she demonstrated that breakdowns challenged the dominant understanding of human action in artificial intelligence and HCI work. Plans and goals were used to describe and design human-machine interaction at the time. However, Suchman has shown how human-machine interaction is extraordinarily complex and based on ‘situated actions’: it rarely goes according to the plan that the designers had assumed. Suchman’s work has influenced artificial intelligence, cognitive science and human-computer interaction, and its influence can also be seen in Julian Orr’s (1996) workplace studies on Xerox repair technicians. Similarly, Orr focused on the situatedness and contingent nature of repair and the challenging process of diagnosis. 
More recent work, in Rosner and Ames’s ethnographic study (2014), explores repair in social contexts. They conducted two pieces of fieldwork, including the One Laptop per Child project’s ‘XO’ laptops in Paraguay and repair platforms in California, for fifteen months. This paper shows how designers and engineers working remotely from the context of use may fail to understand the social context of breakage and repair, and it reveals the contingent nature of these processes. The XO laptop was designed and manufactured to be very difficult to break and to be so easy to repair that a child could do it. However, a number of unanticipated factors, such as the way children used laptops, the environment in which they were used and the manufacturing limitations, caused problems. For example, laptop screens often broke when they were dropped because of Paraguay’s hard cobblestone streets. The keyboards, AC adaptors and trackpads were too weak to withstand heavy use. Consequently, children were not able to repair such damage, and the spare parts were expensive, so it was not possible for children’s families to afford the repairs. At the end of the research, they conclude that breakdown and repair cannot be anticipated and scripted by designers beforehand, but emerge spontaneously in everyday practice. 
The book Invisible Users: Youth in the Internet Cafes of Urban Ghana is another example of ethnographic studies about repair (Burrell, 2012). Burrell looks at the e-waste scavengers in Ghana and provides a richly observed case of these ‘invisible users’ who are not considered in the design process (2012). He touches on the skills they developed to retrieve parts from electronic products such as mobile phones and computers and reuse these parts and precious metals. 
Similarly, Jackson, Pompe and Krieshok (2012) explore in their ethnographic fieldwork how information technology infrastructures are maintained and repaired in sub-Saharan Africa. Information technology devices and networks have spread from Europe and other developed countries to different parts of the world. The effect of this spread has created a local maintenance and repair culture in various parts of the world (Jackson et al., 2012). Jackson et al. developed a concept of ‘repair worlds’ in order to recognise, study and analyse this overlooked area, which offers valuable practical and theoretical knowledge (2012). 
Rosner, Jackson and their colleagues conducted the research project ‘Reclaiming repair’ (Rosner, Jackson, Hertz, Houston, & Rangaswamy, 2013). This is an ongoing three-year-long project which aims to advance the understanding of maintenance and repair practice by strengthening the connection between design and repair (Rosner et al., 2013). The project mainly studies the growing amateur repair movement in North America and Europe and repair knowledge in Bangladesh and sub-Saharan Africa to enhance the understanding of how repair and breakage relate to wider design practices. 
Jackson’s (2014) paper ‘Rethinking repair’ starts a discussion by asserting that breakage and repair are both part of technological systems: they are inevitable, and cannot be ignored. He critiques the dominant view that ignores the activities of maintenance and repair, which sustains technologies and practices in the world. Departing from Heidegger (1996), Jackson proposes a concept called ‘broken world thinking’, which puts maintenance and repair at the centre of thinking, rather than ‘innovation, development and design’, in media and technology studies. First, according to Jackson, broken world thinking enables us to have a wider perspective than the one offered by the current dominant binary structure of technology studies. Second, repair helps us change our production, with a new focus on sustainability and the meaning of objects. Third, it changes our thinking about the ‘timeliness’ of technology. And finally, repair transforms our relationship with technological artefacts and systems and makes it deeper and richer.
Influenced by Jackson’s ‘Rethinking repair’ paper, Houston et al. explored the transformation of values through repair and how new values are elicited. Valuation is a cognitive process involving an assessment of the significance of objects and the rendering of their importance. Values are not established and fixed at the point of design or purchase: but is a continuous process evolving throughout the object's lifespan (Houston et al., 2016). Houston et al. conducted ethnographic studies of mobile phone repair communities at four sites: in Uganda, Bangladesh and amateur fixers’ collectives in Brooklyn and Seattle in the US. They highlighted the centrality of values in repair and discussed a different way of understanding values from that found in HCI studies and design. They found out that the valuing of products is not static, in the way that it is studied in design and HCI. Conversely, it is an ongoing process. As a result of this, repair can help us transform how we think about values. Moreover, through repair alternative valuation processes can be embedded into products, changing the human relationship to technology in a way that strengthens the human relationship to technology by building attachment and meaning. This study provides significant information for this thesis, as one of the main arguments in the literature review is that repair enables a different way of thinking and understanding.

User-Product Relationship
Repair connects people to products. People engage with products on a material level through repair. In other words, they observe and better realise the materials, form and structure of a product because they consciously think about the product as they need to understand the damage before developing a solution for it. Accordingly, we can say that repair enables a deeper engagement with objects and bring a new consciousness to the user in terms of their relationship with products. 
I reviewed the existing research about the user-product relationship before exploring the ways that can be used to encourage people to repair products in order to experience deeper relationships with things. The literature in this subject area focuses on the user experience, which has mainly been studied by the human-computer interaction community (e.g. Desmet & Hekkert, 2007; Hassenzahl & Tractinsky, 2006; Forlizzi & Battarbee, 2004; Schifferstein & Hekkert, 2008). Understanding experience is a complex task (Forlizzi & Battarbee 2004), and many approaches exist in this subject area (Alben, 1996; Forlizzi & Ford, 2000; Kerne, 1998; Desmet & Hekkert, 2007). 
Product experience refers to the awareness of psychological effects elicited through interaction with a product (Schifferstein & Hekkert, 2008). It is a subjective process because experiences differ according to individuals and situations, and may vary over time (Hassenzahl, 2003). A product cannot be merely seen as a thing with functions and benefits, because it is a part of a complex system and network of relationships (Hassenzahl, 2003). According to Desmet and Hekkert, there are three different levels of product experience, including aesthetic experience, experience of meaning and emotional experience (2007). The aesthetic level is the user’s sensory perception of the object, while the experience of meaning refers to the process of assessing the personal or symbolic significance of products through many cognitive processes (Hekkert, 2006). Finally, the product experience also leads to emotional responses such as love, hate and frustration. 
Crilly, Moultrie and Clarkson (2004) explain the consumer response to the visual appearance of products in their article ‘Seeing things: consumer response to the visual domain in product design.’ They define cognitive response as ‘the judgements that the user or consumer has about the product based on the information perceived by the senses.’ (2004, p. 552). There are three cognitive response categories: aesthetic impression, semantic interpretation and symbolic association. Aesthetic impression refers to the sensation that is the outcome of the perceiving an object as attractive or unattractive (Crilly et al., 2004), whereas semantic interpretation refers to cognitive responses about product affordances. It can be defined as the practical aspects of a product and what it tells to the user about itself, its features and how it is used. Lastly, symbolic association refers to what a product symbolises to its owner or user and what it symbolises about its cultural context of use, such as status and power. Symbolic associations are culturally defined as the personal or social significance of products. For example, the experience of luxury is a social significance and it refers to a comfortable and sumptuous lifestyle, while the product attachment corresponds to the personal significance that occurs when products have profound emotional meaning for us. As an example of product attachment, Chapman (2009), indicated that products could be designed to sustain the attachment between users and products by providing the user with an evolving experience that allows the development of empathic relationships with objects.

Motivation
Many theories exist that aim to understand the concept of motivation. The main point in the majority of these theories is that people have limited energy that must be directed towards certain goals (Hirschman, 1983). According to educational psychologist Johnmarshall Reeve (2008), motivation refers to ‘the processes that give behaviour its energy and direction’ (p.8). Based on this definition of motivation, this thesis has explored the different ways that energise and direct people’s behaviour towards repairing products. In this context, energy concerns the strength of the behaviour, and direction implies that the behaviour has a purpose (Reeve, 2008).
Psychological factors that affect motivation and desire have been studied widely to understand consumer behaviour, and knowledge acquired from this research is widely used in the marketing sector. The insights gained are valuable for this field to identify the needs of consumers, as they are used to provide appealing products and advertising. Deep feelings, such as needs, passions and wants, are studied to understand consumer motivation. 
Early studies of motivation in the field of psychology were based on biological-psychological analysis (Reeve, 2008). These studies claimed that motivation was driven by instinct, and innate behaviour related to biological and learned needs (Solomon, Bamossy, Askegaard, & Hogg, 1999/2006). According to this theory, it is suggested that the consumer who purchases products because of his or her desire to attain a certain type of lifestyle has this urge as an instinct. This theory is no longer credited, as it is not possible to test the existence of instinct (Solomon et al., 1999/2006). 
The second theory to address motivation was known as the ‘drive theory’. It explains motivation as a result of biological needs that creates an unpleasant state (Solomon et al., 1999/2006). According to this theory, human behaviour is governed by the desire to reduce tension, eliminate this unpleasant state, and return to a balanced one. If a person’s consumption needs are not satisfied, he or she may be angry or sad and want to reduce these feelings. Drive theory has limited scope (Reeve, 2008), because people often do things that enhance the tension rather than reducing it. This theory cannot explain some human behaviour, such as when people act in a way which contradicts their biological needs (Solomon et al., 1999/2006). The field of psychology then adopted a new understanding of human beings in motivation studies as active agents, replacing the earlier, passive view of human nature (Reeve, 2008). Studies now focus on cognitive factors rather than biological needs to explain motivation: this is known as ‘expectancy theory’ (Solomon et al., 1999/2006).

Intrinsic and Extrinsic Motivation
Intrinsic and extrinsic motivation are two different types of motivation, first described by White (1959) and further developed by Ryan and Deci (2000). Intrinsic motivation is the tendency which occurs naturally, such as interest and curiosity (Ryan & Deci, 2000). Extrinsic motivation refers to behaviour that is driven by external factors, such as rewards or avoiding negative results (Ryan & Deci, 2000). ‘Self-determination theory’ is a framework that studies human motivation (Ryan & Deci, 2000). It also explores how social and cultural conditions affect human motivation. This theory argues that individuals have needs, including autonomy, competence and relatedness, to achieve intrinsic motivation. Autonomy concerns making a choice and acting according to one’s own decision (Ryan & Deci, 2008). Competence refers to the capability of achieving desired outcomes and relatedness is the need to establish reliance on others (Ryan & Deci, 2008). The social and cultural conditions supporting these needs foster internalisation and construct intrinsic motivation, whereas when any of these three psychological needs is thwarted there will be an opposite impact on human natural inclination (Ryan & Deci, 2008). For example, factors such as positive feedback, rewards and compliments enhance the feeling of competence and foster intrinsic motivation. However, an individual experience of only the feeling of competence cannot increase intrinsic motivation by itself. There should also be the feeling of autonomy and relatedness: Deci and Ryan (2008) demonstrated that these three needs should be fulfilled to achieve intrinsic motivation. 
In the case of this research, self-repair was encouraged, as it allows the feeling of autonomy. Competence is also a significant factor for this thesis, based on both self-determination theory and Fogg’s behaviour model (see Section 2.16.2). This study focused on starting with simple repairs – in other words, low skill-level repair work that aims to enhance the feeling of competence so that people can eventually improve their skills through practice. 
This thesis aims to explore different ways of encouraging people to repair products by using a design-led methodology. Associating design with human motivation, Bisset (2011a) explored the role of design in motivating and engaging human behaviour and the potential of intrinsically motivating design for changing human behaviour through the design of services and products. Bisset (2011b) sees motivation as a ‘dynamic and malleable entity’, and the role of the designer in the process of achieving intrinsic motivation, and he visualised this as like a sports coach or a film director supporting an athlete or an actor and controlling their performance ( p. 304). He developed six personas, engaging different levels of motivation, from amotivated to intrinsically motivated (Bisset, 2011b).

Fogg’s Behaviour Model
Fogg (2009) presented a model, known as Fogg’s Behaviour Model, to understand human behaviour and the factors underlying behaviour change. In this model, he identifies motivation, ability and triggers as the three factors which form behaviour. In other words, a person should be motivated, have the ability to perform the behaviour and have a trigger. A trigger can be a reminder, a sign which tells people to perform the target behaviour at a certain time. This psychological model can also be used to control or change the behaviour by controlling these three factors. In order to do that, first a behaviour target is selected. It is important to target a simple behaviour to increase the possibility of success. Secondly, after selecting the target behaviour, what is preventing it must be identified. Thirdly, the barriers should be removed. Fogg says that one should target simple behaviour and start with small steps in order to be successful with behaviour change, and then grow in time. The barriers should be investigated and determined as to whether this is lack of motivation, lack of ability or lack of a trigger. In the case of this thesis, I chose the target behaviour as repairing products when they are broken rather than throwing them away. When a thing breaks, some people inherently think about ways to bring it to its original state. However, they do not or cannot usually repair it, because of the lack of motivation and lack of ability. In my research, I recruited people who have the trigger to repair products, in other words, people who want to repair products. The trigger was thus not identified as a barrier. 
Fogg and Hrena (2010) presented a method for identifying different types of target behaviours, called The Behaviour Wizard, and proposed solutions to achieve those behaviours. They also developed the Fogg Behavior Grid, in Figure 29, which includes fifteen types of behaviour targets. Encouraging people to repair products corresponds to the Green Path type of behaviour change. Green Path represents a long-term commitment to a new behaviour, such as starting to grow one’s own vegetables or leading a vegan lifestyle. This type of target behaviour brings a life change and it is not easy to achieve. Thus, Fogg and Hrena (2010) identified two significant challenges in this change process: commitment and fulfilment. Commitment refers to the willingness to spend time and energy for something and do it for a long time, and fulfilment signifies achieving the target behaviour. Fogg provides the solution to achieving Green Path behaviour as increasing the motivation and ability level by simplifying the behaviour.
Bisset and Lockton state that services and products should be designed by considering users’ different levels of motivation and in a way that supports their sense of autonomy for the behaviour change to be successful and sustainable (Bisset & Lockton, 2010). Lockton (2013), in his doctoral thesis, developed an approach that helps designers visualise the different models of users easily and understand their various needs and wants. This approach models users as ‘Pinballs’, ‘Shortcuts’ and ‘Thoughtful Users’, and provides different ways of influencing people’s behaviour. Pinball users are assumed to be the simple components of the system who do not think about their actions (Lockton, 2013). This view creates fast but unsustainable behaviour change, as users are not aware of the main reasons for their action (Lockton, 2013). The problem with considering users as pinballs is that it thwarts people’s sense of autonomy and can cause poor user experience (Bisset & Lockton, 2010). Shortcut Users are assumed to get things done in the easiest way possible, and their actions are based on ‘intuitive judgements’ (Lockton, 2013, p.149). This view is based on the fact that people’s irrational and heuristic behaviour occurs in patterns, and ‘the basic example of this is that people take shortcuts’ (Lockton, 2013, p.149). Thoughtful Users are considered as mindful of their behaviour (Lockton, 2013). They internalise the values related to the target behaviour and are aware of the main reasons behind it. Although enabling the internalisation of the values behind the target behaviour by the user is a challenging task in behaviour change, it is crucial for sustained motivation (Bisset & Lockton, 2010). Lockton (2013) suggests that thoughtful users can be motivated by providing information and feedback. In the case of this PhD, the participants were assumed to be Thoughtful Users, but at the same time I also considered the other models, as people may show different levels of motivation.

The Gap in Knowledge
Governmental organisations, business representatives and researchers propose various approaches to overcome growing environmental problems and encourage businesses to produce long-lasting, circular, purposeful products (IPCC, 2014; WBCSD, 2016; Ellen MacArthur Foundation, 2013; McDonough & Braungart, 2002; Fletcher, 2008; Bakker et al., 2014a; Cooper, 2013; DEFRA, 2011). It may be helpful and desirable for commodities to be designed for closed loops and in such a way that they can be repaired, but consumers need to have the desire, knowledge and skills to repair and maintain these goods once they are in the system (Middleton, 2012; Brook 2012; Lilley, 2007). In order to enable the transition towards a circular economy, all aspects of the system – environmental, social and economic – should be considered together as a whole, with the interaction between these aspects (Preston, 2012; Bakker et al., 2014a; Shah, 2014; Ghisellini et al., 2016). Significantly, an increase in a user’s awareness and responsibility as well as the producer’s awareness and responsibility is crucial to the success of this transition (Ghisellini et al., 2016). Circular economy relies on users to be active participants in reuse, recycling or return of products, this is the opposite version of the passive, throwaway society of current linear system (Shah, 2014). Although both producers' and consumers' roles and responsibility are crucial for the change, existing research in the field has mainly studied the economic and business aspects of the problem and excluded social issues and consumer participation. 
Although they are not common, high-quality, long-lasting, repairable products are available, as well as repair services and repair organisations. However, environmental and social gains may not be strong enough to motivate people to use their products longer, compared to individual desires to buy new ones, as the current hegemonic ideology values and emphasises what is new and despises what is old and damaged. Today’s ‘passive consumers’ of the linear economy are expected to become ‘active users’ of the circular economy, yet there is not much research exploring this change. Research on design needs to be oriented towards understanding the implications of the circular economy on the users’ side, particularly the effects of the transition from selling products to selling services and to leasing, repair, reuse and remanufacturing (Ghisellini et al., 2016; Bakker et al., 2014b). The transition from ‘passive consumers’ to ‘active users’ requires a change in user behaviour, a different way of thinking about products and eventually a transformation of the value system relating to products. Additionally, recent research suggests self-production (e.g. users’ reusing, repairing, repurposing and appropriating products by themselves) as an opportunity to foster positive environmental and social change through extending the product lifespan (Salvia & Cooper, 2016). 
People do not throw away products because they are broken, they do so because their relationship with products has malfunctioned (Cooper, 2013; Chapman, 2005). So how can we fix people’s problematic relationship with products and enable them to see the value of the things that already exist? Valuation is a continuous process evolving throughout the object's lifespan. My aim is to design a service or system to encourage users to repair products more often because repair is an important field of activity and knowledge through which values are maintained and transformed, and new values are elicited (Jackson, 2014; Houston et al., 2016). Houston et al. (2016) further explain, ‘At the same time, repair can change its human participants, transforming “mere users” into something slightly more, better versed and engaged with the object worlds around them’(p. 2). Therefore, this research aims to bring a new consciousness to the relationship between people and objects through repair that enables them to see the value of things that already exist.
The current problematic situation and circular economy thinking are complicated for laypeople to relate to. However, repair brings this major social problem down to a human level. It is the inner loop in a circular system where they can participate actively, and it is where we can shift consumer thinking and behaviour. 
Few examples of materials and methods such as kintsugi (see Section 4.3.1.4) and Sugru (see Section 4.3.1.6) exist that improve the value of damaged products. Both examples suggest a different aesthetic understanding of repaired objects. By investigating the conventional repair methods and new technologies, and testing them with users, this research aims to identify other possibilities that challenge the stigma attached to repair and provide concrete examples. 
The literature review highlights the lack of research into ways of encouraging people to repair products. As I described in section 2.14, the majority of research that study repair is sustainable design practices and studies that aim to inform HCI scholarship. These studies did not explore repair methods or motivations and barriers in relation to repair. However, there are two papers that explore user barriers in relation to clothing repair. Gwilt (2014) investigates the community-based approaches aiming to revive the clothing mending practices. She examines online and offline activities to enable knowledge exchange and build communities. Rather than having one focus this paper discusses many subjects related to clothing repair including the methods that would revive the community-based approaches to clothing repair, potential roles of online and offline activities, what people do with damaged clothes, repair barriers. She identifies one barrier to clothing repair namely ‘lack of skills’ (Gwilt, 2014). Finally, the author claims that a larger study is needed to investigate the ways to encourage people to engage in repairing (Gwilt, 2014, p.5). Similarly, McLaren and McLauchlan (2015) focuses on clothing repair and investigate the barriers to mending and suggest solutions. This paper presents a detailed and clear historical review of clothing repair. It provides a more detailed investigation in relation to clothing repair barriers compared to Gwilt’s paper (2014). The barriers they identified are financial cost, lack of time and skills, negative stigma attached to repaired clothes and psychological barriers which refer to the psychological effects of the availability of endless cheap products on users (McLaren & McLauchlan, 2015). To conclude and make the gaps in knowledge more clear, these two studies only focus on clothing repair. The barriers they identified are limited. They are not focused on motivations which people experience in relation to product repair.
Therefore, two important gaps are identified throughout the literature review: 1) I have not come across to research that studies different repair methods to create a new aesthetic language around repair; 2) few and limited research exists that explores the motivations and barriers which people experience in relation to product repair. 
This section has identified a gap in the research relating to the circular economy and repair. The next chapter will outline the methodology of this research that is best suited to achieve its aims and to meet this gap in knowledge. 

Chapter 3 : Methodology

Epistemology and Theoretical Perspectives 
Crotty uses the terms ‘epistemologies’ and ‘ontologies’ (1998), while others have called it ‘worldview’ (Guba, 1990) and ‘paradigms’ (Mertens, 2010). ‘Epistemological stance’ refers to the theory of knowledge that the researcher employs in a study (Creswell, 2013). Crotty identified three major epistemological stances: objectivism, constructionism, and subjectivism (1998). The theoretical perspective is the philosophical position of the researcher about the nature of the research which informs the methodology. An approach that uses mainly constructivist research methodology (Crotty, 1998), together with a phenomenological perspective (Giorgi, 2009; Moustakas, 1994), was considered most appropriate for this research.

Constructivism
According to the constructivist stance, truth and meaning do not exist in the external world: they are not discovered – rather, subjects construct their own meaning through interactions in the world (Gray, 2013). Human beings can construct different meanings, even with the same phenomenon (Gray, 2013). The constructivist stance is a typical approach to qualitative research (Creswell, 2013). The researcher aims to understand meanings others have about the world (Creswell, 2013) through inquiries. From the point of view of this thesis, the constructivist stance dominates the methods and methodology employed, since my main intent was to make sense of and interpret how people understand and experience the repair process, in order to find the ways of encouraging them to repair their products. The subjectivist stance might also be apparent during the design studies (Section 4.3), but the objective was still the same in this section. As discussed in Section 4.3, I aimed to study the repair experience intuitively and understand my own experience before exploring other people’s experience and analysing the data received from them. Researchers who employ a constructivist stance develop a theory or pattern of meaning intuitively rather than generalising and narrowing the data. It is important to include the complexity of perspectives that individuals construct.

Phenomenological Research, Materiality and Existential Engagement with a Product
As Sokolowski (2000) states, ‘Phenomenology is the study of human experience and of the ways things present themselves to us in and through such experience’ (p. 2). Phenomenology is a disciplinary field in philosophy. It is directly related to design as it studies the ways we experience things and the meaning things have in our experience (Gallagher, 2013). Based on Gallagher ‘s work (2013), I identified a phenomenological method as the best means for this PhD because the preliminary focus of this research is to gather data regarding the perspectives of people about the phenomenon of product repair and ways that encourage people to repair products in order to create deeper relationships with things. In the course of this PhD, I have needed to perceive these phenomena intuitively, without preconceived ideas, and consequently reflect on my experience and interpret these phenomena through insight gained from participants. 
Husserl is considered to be the founder of twentieth-century phenomenology, with influence extending to thinkers such as Martin Heidegger, Jean-Paul Sartre, and Maurice MerleauPonty (Smith & Thomasson, 2010). In Husserl’s view the central structure of an experience is its intentionality, its being directed at something or being about something (Smith & McIntyre, 1982). ‘Noesis’ and ‘the noema’ constitute the two aspects of the intentional structure of experience. Noesis refers to mental acts such as judgement, memory and desire, whereas the noema is the ‘something’ as it appears to the consciousness (Gallagher, 2013). Heidegger approaches from a different angle to that of phenomenology (Gallagher, 2013). He states that the aim of phenomenology is to make an ontological analysis of our ‘being in the world’ (Heidegger, 1996). ‘Dasein’ refers to being in the world, and human beings’ existence is different from that of non-human beings. Dasein discovers itself in specific possibilities and in interacting with others in an intersubjective way. This is a part of their existential nature. Heidegger argues that the way we exist involves being related to our environment, not detachedly observing it (Gallagher, 2013). He asserts that we see things in terms of their relevance to our pragmatic use (1996). However, we do not look at the object to observe. We tend to pick up and experience it. From this perspective the things around us appear as ‘ready to hand’ (Zuhanden), and Heidegger uses a hammer as an example of this idea (1996). A hammer is not something that a carpenter theorises about or thinks about. It is something that he picks up and uses. And when he does that, the hammer becomes experientially transparent and barely noticeable. It dissolves into the carpenter’s project. Thus it is regarded as a tool, instrument or a piece of equipment that supports a project or act. However, when the hammer breaks, or is badly designed, it is experienced in a different way, which is known as ‘present at hand’ (Vorhanden). It becomes something that is noticed and theorised about. It turns into a problem that prevents one from pursuing an action or aim. Repair becomes significant between the breakage and restoration. It bridges the two realities – the visible tool and the concealed tool – and also demonstrates to us the power of things (Graham & Thrift, 2007).

The Structure of the Phenomenological Research
This part includes an explanation of phenomenology as a research method. The specific phenomenon that this research focused on is the relationship between user and product, which encapsulates the rich, subjective and diverse aspects of human experience. Phenomenology helps to explain the dynamic character of human experience (Gallagher, 2013). Each repair activity is unique and spontaneous in nature. I explored the dynamic character of repair and subjectivity with the help of phenomenology. This part explores the structure of the phenomenological research, including the stages and main concepts central to this method.
Epoche: Epoche is the first stage of the phenomenological study. The researcher should become free from their own assumptions when reporting life experiences. Here the primary source of knowledge is researcher’s own perception: things cannot be known before internal reflection (Moustakas, 1994). 
Phenomenological Reduction (Bracketing): This stage involves describing exactly what you see and experience, focusing on the relationship between the phenomenon and the self. The researcher must bracket his/her own preconceptions and use self as an experiencing interpreter (Miller & Crabtree 1992). I used field notes (memo-ing) (Miles & Huberman, 1984) as a data source during practice work and workshops. This process includes taking notes on what I experience, including what I hear and see during the research process and reflecting on what is happening without judgmental evaluation. Validity is obtained by re-examining the notes a number of times, avoiding preconceptions and considering different perspectives. Truth depends on pure perception in this method. 
In the case of this research, field notes and phenomenological reduction were used to collect data for the purpose of answering the research question. Since 2013 I had been taking notes about my supervision meetings, the articles I read, perceptions and reflections. These notes were recorded in four personal notebooks (Figure 30). Photographs of objects were taken before each repair was carried out and included in the field notes. Field notes helped me collect and organise data and remember every process without missing the details.
Explicitation of Data : The term ‘explicitation’ is more appropriate to use in this research method than analysis: this is because analysis implies the systematic process of identifying the essential features and relationships of a phenomenon (Coffey & Atkinson, 1996), whereas explicitation is the elucidation of components of a phenomenon as a whole (Hycner, 1999). 
Imaginative Variation : This is the phase of explicating frames of reference and perspectives, including polarities and reversals (Hycner, 1999). The units of meaning are clustered to create structured themes (Moustakas, 1994). Although units of meaning are grouped together, it is crucial for this research method to identify the significant parts, which are called units of significance. 
Synthesis : Synthesis is the summary of the research that includes all the themes and individual variations that have been created. This phase is the reconstruction of the essence of the experience of the subject (Hycner, 1999). This part also includes a validity check, returning to the data and checking whether the essence of the research has been correctly derived. A validity check provides the truth value of this qualitative research method, together with the bracketing stage. Throughout the research, I bracketed myself consciously in order to perceive the experience that I was studying. Then I compared this perception with the final essence of the process. The video recordings and bracketing myself during the transcription of the workshops further contributed to the reliability of this research.

PhD by Practice and Links between the Textual and Practical Components of this PhD
The terms ‘research through design’ or ‘practice-based research in design’ are used in various academic discourses to describe an inquiry process through making and designing a product, service, or system (Durrant, Vines, Wallace, & Yee, 2015). Although the term holds different meanings in different contexts (Rust, 2007), it refers to using the making and designing process as a knowledge-generating activity. 
Debates in design research about how knowledge can be created through design paved the way for the development of this approach as a design method. Nigel Cross was one of the pioneers exploring the relationship between design and science (Durrant et al., 2015). He argued that designers must concentrate on forms of knowledge particular to designers, noting the emergence of ‘designerly ways of knowing’ (Cross, 2001). Christopher Frayling (1993) further advanced the discourse on design research and developed three different approaches, including research into (art and) design, research for (art and) design and research through (art and) design. ‘Research into design’ refers to understanding the activity of design while ‘research for design’ aims to improve design practice (Frayling, 1993). Finally, ‘research through design’ focuses on the process of designing artefacts. Much of the work undertaken for this PhD can be identified as ‘research through design’. However, research for design is also a possible description for some parts of this PhD, as this research is valuable in improving design practice.
The design approach, which is the core of the creative process of a designer, was used to explore the ways we can encourage people to repair products in order to have deeper relationships with things. The question is explored throughout the three studies: design and research evolved simultaneously by informing each other and resulted in the creation of new knowledge. In other words, research generated the knowledge to feed the design and design created the means to achieve the research goals. Insights into how people experience repair, including their motivations and barriers, were produced by the research. Accordingly, design ideas were developed in the light of these insights. During the design studies, I experienced the repair process from different angles and used my ability to reflect and create emphasis to develop various design ideas. Key to the design process was the workshops study, because the design ideas and all the data generated became meaningful after testing them with the participants during workshops. 

Research Methods
This section describes the three main data collection methods used in this thesis: cultural probes, design studies (research through design) and workshops.

Cultural Probes 
Cultural probes is an exploratory research method designed to inspire people to respond to designers in creative ways (Gaver, Dunne, & Pacenti, 1999). This method involves developing a probes kit, which can be seen as a physical metaphor of the question asked, and a tool for participants to reflect their answers (Wallace, McCarthy, Wright, & Olivier, 2013). The probes approach is applied in this research to explore participants’ motivations and barriers and to inspire them to reflect on and report their experiences and concerns about repaired and broken products. I have considered using techniques such as collages, asking open-ended questions and voice recording, by means of items such as postcards, cameras, journals and diaries. Finally, I decided to ask participants to tell me stories of products in their homes that were broken or repaired, and to take photographs of them. 
Advantages and limitations of cultural probes as a research method 
As an exploratory research method, cultural probes was applied in the early phase of this research, and it enabled me to broadly map the participants’ motivations and barriers in relation to product repair. I designed a booklet for the cultural probes kit, which includes open-ended questions. I asked participants to take photographs of broken and repaired products and answer questions about why they have or have not repaired the product. The kit stayed with the participant for up to a month in this research, allowing people to thoughtfully consider and answer the questions. 
Cultural probes is a flexible and open-ended method. Thus it can be designed in various ways, according to the research question and the characteristics of participants, in order to get the best results. For example Gaver et al. created a cultural probes kit to identify the views of elderly people in a study looking at interaction techniques to increase their presence in local communities (1999). Their kit included various items such as postcards, maps, a photo album, a media diary and a disposable camera for the purpose of learning about participants’ everyday life. Mapping activity is an interesting technique which has been used to explore elderly people’s attitudes towards their environment. In this activity, researchers asked the participants to mark the places where they meet with others, the places they dream of going but cannot. This example shows that rather than creating a list of facts about participants, cultural probes enable us to understand their stories and find out about their everyday life (Martin & Hanington, 2012)
Another limitation is that the results might be impossible to analyse or even interpret, as they could be unclear, incomplete or biased. Although it might be very hard to grasp participants’ responses, these nebulous qualities are valuable for design and differentiate the cultural probes approach from other traditional research methods (Gaver, Boucher, Pennington, & Walker, 2004). 

Research Through Design (Design Studies)
‘Research Through Design’ starts by determining the problematic situation and verifying that it requires a design inquiry rather than an engineering approach (Frayling, 1993). Then the researcher explains the characteristics of the project that makes the ‘research through design’ method the most effective approach for the project. The results of this method take the form of artefacts, design theories, conceptual frameworks, new research methods and so on (Frayling, 1993). 
I identified the problematic relationship between users and products throughout the literature review (Section 2.14) and concluded that besides using natural resources and filling the earth with waste, badly designed, low-quality products which shape our world also negatively affect our value system, including the way we value products. 
Things cannot be known before internal reflection has taken place (Moustakas, 1994). The aim of the practice is not to design products or analyse the making process to develop frameworks: the practice in the case of this research focuses on the making process in the form of visible repair, and explores the ways in which we can encourage people to repair products in order to have deeper relationships with products and raise awareness about environmental problems. 

Advantages and limitations of research through design as a research method 
The problematic situation determined in the context of this thesis can be most effectively explored with a systematic design inquiry because of four characteristics of this research. Traditional research is usually concerned with understanding the world as it is, but designer researchers attempt to change it. In Frayling’s words, ‘Where artists, craftspeople and designers are concerned, the word ‘research’ - the r word - sometimes seems to describe an activity which is a long way away from their respective practices. The spoken emphasis tends to be put on the first syllable -the re- as if research always involves going over old territory, while art, craft and design are of course concerned with the new.’ (1993, p. 1). First, together with other consumption strategies, the product design profession has played a significant part in the development and expansion of the problematic situation which is the subject of this research. Therefore, as design is a part of this problem, we need an environmentally conscious design inquiry that takes into account the nature of human behaviour to overcome this problematic situation and accelerate the transition to a circular economy. Second, the problematic situation that this research addresses is between users and products. It is the subject of design discourse, and cannot be studied effectively other than through a design inquiry. Third, the way to encourage people to repair more products can only be studied effectively through practice. Finally, providing people with inspiring tangible artefacts is an effective strategy to encourage them to repair products. This can only be done through practice. 
‘Research through design’ methods requires time and effort, as the researcher is the main creative agent embedded in the process. The researcher is in the middle of a knowledge network that is informed by literature, the ongoing research and practice. This process is completely different from doing research and compiling a list of results, as the researcher should thoroughly understand, internalise and finally synthesise the raw data to create new knowledge.

Workshops
Workshops are a type of participatory design technique created for a certain number of participants, and which includes several activities such as collage, mapping and sketching, for the purpose of understanding the user’s world (Martin & Hanington, 2012). 
This method can be used for design exploration such as generating ideas, testing a product or an idea. Co-design exercises are also common and useful in workshops to collect data about the user’s world, needs and wants. The number of facilitators should be determined according to the participants and the workshop structure (Laurel, 2003). A workshop may start with an introductory presentation to explain the process and reason for conducting the workshop. As workshops include intense creative activity, the workshop structure should be carefully planned and required materials should be prepared before the workshop in order to successfully reach the research objectives. Video recorders, cameras and voice recorders can be used to document the process. 
Advantages and limitations of workshops as a research method 
Workshops are efficient and enjoyable ways to gain data from participants, which provides a wealth of insights (Martin & Hanington, 2012). Involving multiple participants particularly enhances the potential diversity of perspectives and ideas generated (Lockton, 2013), which affects the quality of the data.
The workshops as a research method facilitates the environment that enables the researcher to observe the participants’ experience and collect the data on the spot, rather than expecting them to remember and reflect on their previous experiences. 
The main difficulty of this method is that it is labour intensive to organise and run, but the results were worthwhile. It is critical to plan the process, gather necessary materials and set the scene before the workshop. Timing is another significant issue: workshops should stay on track with the plan in order to meet the goals successfully

Affinity Diagrams
The affinity diagrams approach is a bottom-up research method which is used to draw out common themes from a large amount of information (Martin & Hanington, 2012). It is an effective method for designers: previously unseen connections can be uncovered, which allow a design direction to be established (Moggridge & Atkinson, 2007). Additionally, this method provides ‘a focus as a whole’ to the design team while they are working on complex problems (Beyer & Holtzblatt, 1998). In this method, observations, insights or requirements acquired from the data are put on sticky notes, and these notes are put on a wall or a large paper. They are clustered into meaningful categories which form themes based on the data. This allows the researcher to make meaningful connections and identify the problems. The affinity diagrams method is useful in revealing the scope of the problem and making connections between diverse subjects, as different data can be analysed together to reveal commonalities while retaining individual characteristics (Beyer & Holtzblatt, 1998). 

Participation Selection
When choosing the sampling method, the question that the researcher aims to answer is of the utmost importance, as it defines the basis of the methodology. The researcher first decides whether to study the entire population or to choose a sample population efficiently. As the research question of this PhD investigates ways of encouraging people to repair products more frequently, the participants are selected from the group of people who are interested in repair, and want to repair products. The purpose of this is to identify their motivations and the barriers to repair activity which are the building blocks of this research. The people who are not interested in repair and who do not see the advantages of this activity are not included. I decided to sample the population and concluded that purposive sampling is the most suitable tool for the study. Purposive sampling is a non-random technique for choosing participants with certain characteristics deliberately (Robson, 1993). The researcher considers what needs to be known, according to the research questions. Then s/he determines what the characteristics of the population for this activity in terms of specific qualities. Finally, the researcher finds people who can, and are willing to, provide related data (Bernard, 2011). 
Participant recruitment involved two stages in this study: defining an appropriate study population, and identifying strategies for recruiting participants from this study population. Professional repair technicians are not included as participants in this research. The participants in this research are users who are interested in product repair activity. They were recruited for two research studies, the first being the cultural probes study (Section 4.2) and the second the workshops (Section 4.4). 
For the cultural probes study the participants were mainly found from repair parties which were held in London. Additionally, advertisements were hosted on websites in order to reach a wider range of people. The websites I used were callforparticipants.com, twitter.com and facebook.com. 
I put up posters and placed advertisements on various websites to recruit participants for workshops. The posters included information about the aim of the workshops and the workshop schedule. They were posted around my college and neighbourhood, and were also put on websites, including callforparticipants.com, twitter.com and facebook.com. I accepted all the participants who were willing to attend workshops because none of them were professional repair technicians. The people who asked to attend the workshops were people who wanted to repair products. This sampling method might be regarded as random sampling. However, it can be best described as purposive sampling because the recruitment strategy attracted people with certain qualities who had some level of interest in repairing things. 
No limit exists on participant numbers in purposive sampling, as long as the researcher realises the data to answer the research question (Bernard, 2002). It is crucial to decide on the correct sample size to decrease the bias and allow for variation for relevant results. Fifty people were recruited for the cultural probes study and thirty-two of them completed and sent the cultural probes kit back. The sample population was sixty per cent female and fourty per cent male and was between the ages of twenty and fifty-seven. The participants included people with various occupations, such as designers, university students, electrical engineers and teachers. 
For the workshops fifty-two people were recruited. Workshop participants were between the ages of eight and sixty-six, with a range of different occupations, including university students, designers, and retired teachers. The sample population was fifty-four per cent female and fourty-six per cent male participants. To conclude, participants were from diverse age groups and occupations who represented potential users of the repair kits. They provided the relevant and necessary data for the development of this research.

Validity and Reliability
Validity and reliability are both used as measures of the research quality of qualitative and quantitative research. Validity refers to how well an assessment tool measures the intended proposition under study, while reliability is concerned with how consistent the assessment is, and the degree to which an assessment tool produces stable and accurate results over time (Fusch & Ness, 2015). In a phenomenological approach, validity and reliability are established differently from the way these are in quantitative research. Phenomenology aims to describe the human experience as it is. This aim is based on the guiding term of phenomenology, ‘back to things themselves’ (Husserl 2001/1970, p. 252). Giorgi (1988) proposes two strategies to establish validity and reliability in phenomenological studies, namely bracketing and intuiting. He defines bracketing as setting aside one’s own presuppositions about the phenomenon studied. Bracketing, in the case of this research, was accomplished through field notes that were written throughout the design studies and workshops, reflecting on what was happening without judgmental evaluation. Notes regarding presuppositions and assumptions were eliminated by re-reading and considering the data several times. Besides achieving bracketing, the notes were useful in recording the data and increasing the quality of the results. Intuiting refers to studying the phenomenon carefully and capturing logical insights, and only accepting what is found, rather than relying on preconceived ideas or interpretation (Giorgi, 1988). Intuiting is critical to understanding the meanings in the phenomenological study and can only be achieved through bracketing (Giorgi, 1988). 
Aiming to include diverse perspectives and improving the quality of the research, the continuous process of imagining variations (Moustakas, 1994) of the motivations for, and barriers to, repair activity took place during design studies and workshops. With the help of this process, the polarities and reversals are included in the categories during the explication of data. Additionally, throughout the workshops the aspects that were considered essential were recorded, which helped to validate the quality of the inquiry. 
Another important factor in terms of establishing validity is to reach data saturation. In their article ‘Are we there yet? Data saturation in qualitative research’, Fush & Ness (2015) explain the point at which data saturation is achieved in the case of a phenomenological study. Creating the state of epoche, the first stage of the phenomenological study, in which the researcher becomes free from suppositions, is crucial in the search for data saturation (Fush & Ness, 2015). Reaching the aim of the study is also a significant factor for arriving at data saturation (Fush & Ness, 2015). Although there are no established rules for reaching data saturation (Giorgi, 1988), some general principles exist that inform the researchers in this quest. The point of reaching data saturation is achieved when further data adds no new information to the research aim, and when there is enough information to replicate the study (Fush & Ness, 2015). Data saturation was achieved in this research when the data became repetitive, and did not necessarily add anything new to the aim of the PhD. In the last two workshops, no additional data can be found to develop new properties or categories.

Summary
This chapter has described the epistemological stance, theoretical perspective and research methodology adopted in this PhD. This thesis adopts a mainly constructivist stance, with a phenomenological perspective. The chapter continues by explaining what ‘PhD by practice’ means, and the links between the textual and practical components of this PhD. The knowledge generated through the research studies was used to inform the design, and the design studies helped to create the means of reaching the goals of this PhD. The research methods employed in this research are then presented, with their advantages and limitations. After explaining the participant selection process, this chapter concludes by explaining the validity and reliability of research. The next chapter presents the way in which the cultural probes, workshops and ‘research through design’ methods were applied in this thesis.

Chapter 4 : Research

Introduction
This chapter introduces the three research studies, including cultural probes, design studies and workshops, which are the building blocks of this research. These studies are presented by explaining the aims, context, process, participant involvement and the results of each one. A paper, including parts of Section 4.2, was published as a part of my presentation at the Sustainable Innovation 2015 Conference. 

Cultural Probes 
The throughput-based linear economy has created a society where people are programmed to pursue an endless cycle of buying and disposing of products. This is expensive and inconvenient, and it is mostly impossible to get products repaired. However, there are people who still want to repair things despite the fact that many existing factors and strategies implicitly force them to buy new products. I wanted to explore these people’s motivation, and also the barriers that they experience in relation to repair in the early stages of this research. This part presents the cultural probes method, including the development of the toolkit and the results of the research. 

Development of the Cultural Probes Toolkit 
‘What do people repair?’ and ‘Why do people repair things?’ were the initial questions in my mind before I decided to use the cultural probes method. It is not easy for people to express their motivations and barriers because these experiences have a multi-layered, complex structure. Simple tasks are thus required to prompt participants to think in a broad, lateral way and enable them to say what they want to say. 
In this research, I wanted to identify the things that people repair, and also the things that they want to repair but cannot because of certain barriers. Thus, I asked the participants to take photos of their objects that were repaired and the broken things that they save to repair in the future. Taking photographs helps people to remember the experiences, to inspect the product and include the aspects that they usually do not reflect on. Additionally, the photos also help the researcher to access fragmentary clues about participants’ thoughts and experiences. Clues about people’s repair stories provide crucial knowledge for the future of this research in terms of understanding participants’ motivations and the barriers that exist in relation to repair.
After taking the photos, I asked participants to explain in the booklet how the product was repaired and why they repaired it/got it repaired, and if it is a broken product I asked why they have not repaired it or got it repaired. The first design of the cultural probes kit involved question cards (Figure 31). Stickers with numbers were included to understand which answer belonged to which photograph (Figure 31). I decided to present the questions in a booklet instead of the cards to keep the questions and the answers orderly (Figure 32). Figure 33 shows the final, printed design of the booklets.
Task 1 
The first task aimed to acquire demographic information about the participants: their age, gender and occupation. 
Task 2 
For the second task, participants were asked to take photos of their broken and repaired objects and answer the questions for each object.
How was it repaired?
Why have you repaired it/had it repaired?
Why have not you repaired it or had it repaired? 
A camera was provided for the participants who did not have a camera or mobile phone. Taking photos helped people to remember the experiences, inspect the product, and include the aspects that they did not normally reflect on. 
Task 3 
In this task, participants were asked to return the kits in the self-addressed envelopes provided in the kit. I also asked the participants who were not sent a camera to email the photographs to the email address provided in the booklet. The rest of the photographs were received with the camera.
Participant selection strategies and the process of cultural probes research are explained in detail in Section 3.4. The participants were mainly recruited from the repair parties held in London. Advertisements were also put on websites, such as callforparticipants.com, twitter.com and facebook.com. In total, fifty people were recruited and the information about the research was provided to participants via e-mail; twenty-eight probes kits were mailed to participants’ addresses and twenty-two of them were delivered by hand. Thirty-two of the probes kits were completed and received. Participants were between the ages of twenty and fifty-seven, sixty per cent female and forty per cent male. The probes kits contained one hundred and three objects in total; ninety-three of these were included in the analysis. Ten objects were not included because four of them were regarded not as repairs but temporary adjustments, such as putting a cardboard piece under the table, and six of them were building repairs such as painting the walls of a room. After receiving the kits, the photographs which had been sent by participants were printed and attached to the related booklets (Figure 34).
Photographs of repaired and broken objects and participants’ answers in relation to these objects were analysed. Insights were derived from these answers and each insight was put on an individual sticky note to evaluate each, both on its own and as a whole. I numbered each note because it was important to reference each note to the original data in case a question arose about it. As different product types are included in this research, I used different coloured sticky notes for each product type (Table 1). I put the notes on a sheet of paper and hung the paper on the wall in order to see all of the notes together and interpret them easily (Appendix A). The notes were divided into two different affinity diagrams because there were two types of questions in the cultural probes kit, referring to both motivations and barriers in relation to repair. The notes with similar content were grouped together, and finally the categories of motivation and barriers were developed.

Research Outcomes
Categories of Motivation
Financial/Labour/Time Gain 
Motivation derived from financial, time and labour gain arose as a result of the cost and benefit calculation that participants made while considering these three aspects. People might want to repair an expensive product even if the repair cost was high, depending on the cost of a new one. For example, Participant 19 had her espresso machine repaired because the cost of a new one was very high compared to the repair cost. 
Emotional Attachment 
Some participants said that they repaired their damaged products because of the emotional connection they feel to them. Users are emotionally attached to the product ‘due to the service it provides, the information it contains, and the meaning it conveys.’ (Chapman, 2009, p.33). This category includes products that have a special meaning for the user, such as gifts or products that have been used for a long time. For example, Participant 9 received her hairdryer as a gift nearly 30 years ago. She explained that she had it repaired when it stopped working because she loved the object, it was a gift and she had had it nearly for thirty years. (Figure 37). Similarly, Participant 2 repaired her earphones because they were a birthday gift and had emotional value (Figure 37). 
Everyday/Essential Need 
Everyday/essential need is the motivation category that refers to the desire to meet an urgent necessity. Boilers, beds, and cookers are some of the products without which users cannot fulfil their everyday essential needs. Thus, they might prefer to repair these kinds of products immediately when they break. For example, Participant 13 called the repair technician to have her boiler fixed because she needed hot water urgently. The first category, financial/time and labour gain, is also an important factor in this case. Users might prefer the fastest solution in this case in order to get hot water. They might get the boiler fixed even if the repair is expensive but quicker.
Condition of the Product (New/Warranty) 
Participants tended to get the products that were new and under warranty repaired. For example, Participant 6 said that he had his dishwasher repaired as it was under warranty and new. He contacted the technical service department about the problem and the repair technicians collected it from his house and returned it after repairing. He said if it had not been under warranty, the repair and the transportation would have been expensive and taken longer. Similarly, Participant 27 had his shoes repaired. He said he would not have spent time and money on getting his shoes fixed if they had not been under warranty. 
Desire to Relieve Negative Feeling 
This motivation originates from users’ desire to relieve negative or aversive feelings triggered by throwing a product away before the end of its use life. For example, Participant 20 explained the process of getting his toaster fixed, with the reasons for this. He took the toaster to a technical service department after it stopped working and learnt that the problem was a disconnected cable inside the appliance. He had it repaired, although the labour cost was more than half of the price of a new toaster. He explains the reason: ‘I would feel bad if I junked it when all the other parts were working well’. Sometimes users try to repair their products themselves when the labour cost is high and they do not want to dispose of the product. Participant 15’s laptop battery stopped working. The repair service was expensive and he thought it was not right to throw a laptop away just because of a damaged battery. Eventually, he changed the battery by himself by watching a repair instruction video.
Personal Pleasure/Satisfaction 
Some participants were inspired to repair products by being able to display their skills, and this process gave them personal pleasure and satisfaction. Participant 9 said, ‘I thought a drying rack was not something that you show everyone so I repaired the broken plastic connection parts because trying to get an old object to work is more satisfying than buying a new one’ (Figure 38). She also had a broken hairdryer that she could not repair, and added that ‘I really want to know how to fix things and what causes them to fail. The learning process is awesome, and after something is fixed I am filled with pride and happiness’. Participant 17 helped his mother by fixing the cable connection of a lamp. He expressed his feelings of pleasure that he had the skill to fix it, accomplish the task and help his mother.
Environmental Concerns 
Some participants’ environmental concerns motivated them to repair their products. Most of the participants were aware of the damage the current economic system causes to the environment and they wanted to reduce it. Participant 10 said that he was interested in repairing small appliances and he wanted to learn more about fixing objects in order to decrease environmental problems, and added, ‘I came from a background where you first of all attempt to repair broken stuff before replacing them’. Participant 17 had his luggage repaired after its wheels broke. Although he complained that it took too much time to find for a repair technician to fix it, he said that he was happy about doing the right thing for the environment. 

Product Repair Barriers 
Financial/Time/Labour Loss 
Participants decided whether to have the product repaired or not by calculating their loss or gain in terms of time, money and labour. The prevalence of cheap, low-quality products, in particular, directs users’ behaviour towards buying a new product instead of maintaining and repairing it even if they know it is not environmentally friendly behaviour. Participant 6 reported that he did not want to have his kettle repaired because he thought it would cost more than buying a new product. Similarly, Participant 13’s camera’s flash did not work. She said she did not have her camera repaired because of the high repair cost. 
Condition of the Product (Old/Low Quality/Technologically Outdated) 
The condition of the product (old/low quality/technologically outdated) refers to the situation in which a product becomes old, unfashionable and behind technological trends, losing the identity and status it once had. Sometimes products fail to satisfy the human search for new experiences, so they become despised (Chapman, 2009). Finally, the relationship between the user and the object fails and leads to disposal. For example, Participant 18 stated that he did not want to have his mobile phone repaired as he had a more technologically advanced one. Some participants thought that products had a certain use life that ends when they are worn out because of long-term use. Participant 11 stated that she would not have her shoes repaired since she thought they were old and had reached the end of their life. 
Unavailability of Spare Parts 
Currently, most repair processes actually take place as replacement of product parts. However, it is not a widespread practice for manufacturers to provide spare parts to users. This fact made the unavailability of spare parts one of the main barriers that participants encountered. Participant 17 stated that he could not find the spare part needed because it was not provided by the producer, as the mobile phone was technologically outdated. 
Lack of Knowledge 
Participants were discouraged from the repair process when they did not have the required knowledge about repairing the product, or could not find someone to repair it. For example, Participant 6 stated that he tried to repair his mobile phone but he could not, due to a lack of correct information (Figure 39). He explained, ‘I ordered a new screen from China. I didn’t realise it was important to wear insulating gloves while fixing, but the phone is now completely dead, due to my body electricity’. Participant 1 predicted that the problem with his kettle was the loose cable connection (Figure 39), but he did not have it repaired because he did not know where to take it. 
Design-Related Problems 
Attaching product parts permanently during the manufacturing process with methods such as gluing and welding was one of the most prominent design-related problems. This increased the cost of repair and amount of waste as functioning parts had to be removed with the broken ones. Participant 9 complained about the old worn-out appearance of her hair straighteners. She wanted to change the outer part but this was not possible because of the way the product was designed. Participant 1 wanted to have the broken water tank of his iron changed but this was not possible as it was permanently attached to the product. 
Planned Obsolescence Participants were discouraged from repairing products if the product had been broken more than once. They thought the product was designed to last for a predetermined time and that other parts would continue breaking down. 
Participant 2 stated that she had the same problem with her last two pairs of boots (Figure 40). She had the first one repaired. However, after one week they had torn again. She did not want to repair her newer boots because she thought that they would not last long after repair, like the previous ones. Similarly, Participant 10 indicated that he had his loudspeaker repaired twice (Figure 40). He did not want to spend time on taking it to a technical service department for the third time because he thought it would break down again. Moreover, he complained about how users were dependent on manufacturers, indicating his desire to be self-sufficient and to have the ability and the knowledge to carry out repairs.

Types of Repair
Depending on the level of skill of the person carrying out specific repair activities, these were categorised into three different types. 
Assembly repair: This repair type requires no particular skill or knowledge. A good example here would be putting product parts together and gluing or binding them. 
Medium-level repair: This repair type consists of activities which require some level of skill and knowledge, such as gluing knowledge and material knowledge: sewing and darning, for example, are medium-level repairs. 
Advanced-level repair: This repair type includes activities that require advanced skill and knowledge, such as changing a laptop screen. 
According to the research results, a correspondence between the barriers to product repair and the major problems associated with the current linear economic system can be seen. The unavailability of spare parts, expensive repair services, most design-related problems and planned obsolescence have been widely studied in the literature. Business models of a circular economy that can overcome these major problems have been known since the mid- 1970s, and currently prevail in some sectors (Stahel, 2012). The implications of the results of this research can be used by stakeholders in the circular economy system: product designers, researchers, policy makers and companies. 
To conclude, this research project has shown that the act of repair is not limited to fixing faults but is also a generative process that is motivated by complex emotional drivers and behavioural aspects. It gives a sense of accomplishment, teaches how things are made and informs about their material qualities. The insights raised from this research can be applied to explore these various dimensions of product repair. 

Design Considerations 
The motivation and barriers that relate to product repair were specified and divided into categories at this stage of the research. These categories were utilised as design considerations and were developed throughout this research. They were employed to evaluate and explore the repair methods during the design studies (Section 4.3) and the workshops, and were used as the building blocks of the Do-Fix repair kits. However, some of the motivation and barriers were not included as design considerations. First, ‘design-related problems’ and ‘planned obsolescence’ are two categories of barrier which could not be answered within the scope of this research, as this research focused on users’ perspectives and experience. Second, ‘emotional attachment’, ‘everyday/essential need’ and ‘condition of the product’ were three categories of motivation which were not included as design considerations, since they could not be controlled, altered and measured in relation to product repair methods and the scope of this research. They are formed between user and product throughout the product lifespan. Specifically, the user’s emotional attachment to the product is a powerful motivation that directs the user to repair the product. Moreover, the activity of repairing a product can itself prompt this attachment between user and product. However, these topics were outside the scope of this research. 
The repair decision is a complex process, like any other human behaviour. Therefore, these design considerations should not be evaluated and explored as independent variables. People consider them as a whole before making a decision about the repair process, so these considerations are a part of a complex network. Categories of motivation and barriers which will be used as design considerations in the next stages are: 
Financial Cost 
The first three design considerations were developed with regard to the financial/time and labour loss/gain categories. This consideration refers to the cost of the repair, materials and tools that were used in the process. If the process requires expert knowledge or any kind of repair service, its cost is also considered under this title. 
Repair Duration 
Repair duration represents the time required for completing the repair process. Participants preferred to carry out repairs which do not take a long time. 
Ease 
Ease represents the amount of work required to complete the repair. Participants preferred to carry out repairs which do not require great labour or effort. This category is closely related to that of required knowledge and skills. For example, some kinds of damage may be regarded as easy for a person who is experienced and has the required skills; however, it may also be thought of as a difficult repair when the user has no actual hands-on experience. 
Personal Pleasure/Satisfaction 
Personal pleasure/satisfaction refers to the pleasure experienced by carrying out the repair and the pride felt as a result of doing the repair. It includes the enjoyable aspect of the process, and emotions such as the feeling of relaxation and enjoyment it triggers. Additionally, people often feel proud as a result of accomplishing the repair and enjoy receiving praise from others when they share the experience of the process. These aspects of the ‘desire to relieve negative feelings’ category of motivation are included within the category. 
Required Knowledge 
The consideration of required knowledge involves aspects of the ‘lack of knowledge’ category. This category refers to the knowledge that is required about the repair methods, where to get the necessary materials and tools and how to use them. 
Required Skills 
Using one’s hands and fingers to make and manipulate things is a natural human ability. Anyone can repair objects using their natural skills and creativity. The quality of work improves in time with practice. 
All these considerations have huge potential to be addressed through research and design. Some of the participants indicated that they cannot repair their products because they do not have the required knowledge, or they do not know where to take the broken products. There are a number of implications for design in improving the content of product maintenance and repair manuals. Moreover, repair kits for products could be developed during the design process, taking into account potential future faults. These design considerations were developed during the design studies, and tested in detail and finalised during the workshops.

Design Studies
This section includes the design studies that I completed, and the various repair methods that I tried and tested. Here I present twelve of these repair methods which were relevant to the context of this research and had the potential to answer the research question. Examples were given for each repair method with ‘before’ and ‘after’ images of these objects. 
The repair methods were explored throughout the design studies in order to identify the feasible and infeasible aspects of each method to encourage people to repair products and develop the design considerations further. 
The repairs can be described as the materialisation of theoretical ideas that I reviewed in the literature on tangible objects. Initially, various traditional repair techniques were explored. Traditional repair methods have survived for centuries through numerous implementations, and incorporate the accumulated knowledge of centuries of experience. In time, they have evolved according to the human capacity for creativity and skill. Some of the conventional methods were applied in a similar way to the original process, while others were applied with new technologies and materials. The resulting artefacts were intended to help to stimulate my exchanges with the workshop participants. 

Repair Methods 
It is possible to find repair instructions or related videos on various websites such as YouTube regarding most of the objects that need fixing. iFixit is one of the best examples of websites focusing on electronic product repair (see Section 2.12.5). Besides providing repair instructions, iFixit sells repair kits, including specialised tools. Repair methods included and developed in this research are briefly explained, with examples, because this is not a repair methods book and the instructions, materials, processes and examples of various repair methods are available elsewhere in books and online. The focus here was a phenomenological analysis of the repair experience to identify different ways to encourage people to repair products. 
There is an immense number of breakable objects in this world. Each of these objects can become damaged in various ways. It is not possible to cover all these possibilities; however, the methods applied in this research could be applicable to many types of damage. The repair methods and instructions involved in these design studies come from my own observations, some of them invented by combining different methods. The next section includes examples of practical repair, together with the repair methods applied in design studies, as well as how and why they were used. A paper, including parts of Section 4.3.1, was published as a part of my presentation at the Sustainable Innovation 2016 Conference. 

3D Printed Product Parts 
Three-dimensional (3D) printing is an additive manufacturing process that builds objects from individual layers of material based on a digital file (Warnier, Verbruggen, Ehmann, & Klanten, 2014). A wide variety of 3D printers exists, using different technologies and materials (Warnier et al., 2014). Since its invention twenty years ago, 3D printing has drawn attention from a wide range of disciplines, used in diverse areas of application (Manyika, Chui, Bughin, Dobbs, Bisson, & Marrs, 2013), and has affected the way we think about manufacturing. The interest in 3D printers has grown further since the maker movement has become widespread (Hagel et al., 2014). The technology has developed very fast and paved the way for businesses that provide a 3D printing service as well as low-cost desktop 3D printers. Although the main application area of 3D printing is prototyping in product design, today many products are produced by this method, including bicycles, buildings, cars – and even organs, using living cells as a raw material.
3D printing embodies numerous possibilities of extending product lifespan through product repair particularly in terms of physically damaged products. This method can also be used as an effective way to draw people’s attention to repair activity. These include technology ‘geeks’, who are not specifically interested in the repair, and children, as it is easier to sustain their attention with entertaining products. 
The unavailability of spare parts was one of the barriers that participants specified in the results of the cultural probes research (see Figure 36). This barrier could be overcome in relation to physically damaged products by 3D printing the damaged parts. Moreover, these parts could be designed in a different way to improve the product or personalise it. Distinctive and complex designs are also possible, as 3D printing enables the easy production of intricate shapes. 
I repaired shoes, teapots and watches, by 3D printing the spare parts (Figure 41). This was an experiential process in which I explored the different solutions that 3D printing can offer to the repair of products, rather than exploring the best ways and methods of repairing a product. Some of the repairs were unsuccessful, and this gave me the opportunity to see the advantages and disadvantages of this method. For example, the shoe heel in Figure 41 was slippery to walk in. Digital precision is one of the advantages of 3D printing. However, it can be difficult to create a precise computer-aided design (CAD) model, especially in the case of products with organic shapes. For example, it took a long time to create a spare part that fits the broken spout of the teapot in Figure 41. 
3D printing is capable of creating complex shapes, unlike conventional manufacturing methods, which are restricted in the types of shapes that can be achieved (Warnier et al., 2014). 3D printing offers the potential to create even eccentric designs. The spare parts do not have to be the same as the originals; instead, they could be designed in a different way to improve the products or personalise them. The toy sword in Figure 42 are examples of this category. The owner of the sword wanted it to be stronger and longer than before. Additionally, he wanted his name written on it. 
Although 3D printing is an effective method, with endless possibilities for producing different shapes, there are some difficulties that should be addressed. Developing 3D CAD models requires skill, knowledge and precision. The 3D modelling service is also very expensive. However, there are open-source websites such as Thingiverse where users can find CAD models of various product parts. Instructions for repairing products with 3D-printed parts are also available. As the opportunities of 3D printing rapidly improve, it may be possible for manufacturers to provide downloadable 3D models of spare parts in the near future.

3D Printed Patches
The idea of 3D printed patches was initiated by designing and trying different shapes of patches that could be pinned or sewn onto holes in fabric. The starting point of this method was conventional repair techniques such as darning and patching (see Section 4.3.1.7 and Section 4.3.1.10). The first patches were two-dimensional, and similar to badges. After this, I explored the flexibility of 3D-printed parts. Inspired by 3D-printed textiles, I worked on patches with joints and chain-like structures (Figure 43). After experimenting with various fabrics, results showed that 3D-printed patches which are rigid or had a certain level of flexibility are more suitable for mending purposes than chain-like patches because they do not move together with the fabric. Chain-like patches were too flexible: they creased the fabric and the garment looked deformed (Figure 44).
Creating the CAD model and finding a 3D printer are difficulties associated with fixing products with 3D printing. However, these issues could be addressed in the future with the increasing prevalence of 3D printing technology. This technology has been developing fast, and people’s interest in 3D printing indicates that it could penetrate more into our everyday life. Repairing our products might thus become more convenient than buying a new product, and this might change typical user disposal behaviour.

3D Printing Pen
A 3D printing pen was employed in the design studies, most importantly because it is an interesting new technology that is likely to attract people's attention and encourage them to engage in the repair activity. Moreover, involving technological products might be an effective way to combat the negative stigma attached to repair. 
The working mechanism of a 3D printing pen is similar to that of a glue gun. It heats up in one minute after it is plugged in. A PLA or ABS plastic string inside the pen melts with the heat and comes through the nozzle. The product is easy to operate, but it is very hard to create neat shapes with it. 
I repaired a damaged lace doily with the 3D printing pen as I thought it would be fun and easy to create intricate shapes with the narrow nozzle (Figure 45). I draw the pattern on a paper and followed the lines with the 3D printing pen. Although the pattern was two dimensional, it was hard to create the exact shapes. However, the final result was aesthetically pleasing and interesting. It is not effective to buy this product for repairing textiles or other products but it could be available in repair cafes and maker spaces. People can lease or use it when they need it. I decided to test the method in the workshops and use it as a way to attract people’s attention and help the process of engaging people in repair activity. 

Kintsugi
Kintsugi is a traditional Japanese repair method employed to mend cracked or broken ceramics with precious metals like gold and silver. Broken ceramic parts are joined together using Japanese lacquer. This lacquer is made out of the natural resin of the urushi tree. Afterwards, the crack lines are filled with gold powder and varnished. The gold, the labour and the time spent on the object make it more valuable than before it was broken. This technique was applied to mainly ceramic products during the design studies (Figure 46). The origami vase in Figure 47 was one of these products.
I found this vase after moving to a new flat. I thought it shouldn’t be thrown away, as it was beautiful. I mixed gold-coloured liquid and glue and applied it on each piece. This produced results similar to kintsugi. The original method is rarely applied today because it is labour intensive and the materials are difficult to find. The kintsugi method that was used here was easy to apply: the materials were low-priced and the process was not time intensive. The pieces were joined together with gold-coloured glue. The only difference from glueing was that I added a gold-coloured liquid to the glue and put more glue than necessary in order to get the ‘raised’ gold effect. 

Kintsugi for Textiles
The philosophy behind the kintsugi correlates strongly with the aim of this research. This led me to think about different versions of the same method, such as applying it to different products or using different materials. I applied the material onto textiles in order to test the aesthetic qualities. The results can be seen in Figure 48. The material definitely showed the texture of the tear underneath it and the result did not change when the tear was sewn up. The process was easy to apply and enjoyable. However, it was messy and the final appearance did not satisfy my expectations.

Kintsugi Sugru
Sugru is a kind of mouldable glue that turns into rubber (Ball, 2013). It is an inspiring material that can be used for many purposes, from repairing to personalising products. It can be also used like kintsugi to join ceramic products: this is called kintsugi Sugru. I applied this method to a broken mug and to a broken, antique plate that I bought from an antique shop (Figure 49). Kintsugi Sugru is included in the design studies and workshops, as people might want to try it, and it might inspire different methods of repair. 
Sugru is an amazing material. It is easy to apply, like play-dough; however, some difficulties exist in the process. If the object is broken into more than four or five big pieces, the Sugru between the pieces creates a thickness, and makes it hard to join the pieces neatly. Although, as noted, Sugru is similar to play-dough, it should be applied directly and quickly as it collects dust and loses stickiness. Finally, no research exists into whether Sugru is food safe, and the company is currently working on this issue (‘Sugru’s Amazing Properties’, n.d.). The object thus cannot currently be used to contain food until this is resolved.

Darning
Darning is a fabric repair technique involving sewing holes and worn areas in fabric or knitted textiles using a needle and thread. It is done by hand and it is also possible to apply using a sewing machine. The thread is woven in rows along the grain of the fabric. I have used this technique all my life but I was improvising. I researched instructions to improve my skill and technique for this research. The instructions seemed complicated at first but once I started doing it the process was enjoyable and relaxing. The application of this method on socks can be seen in Figure 50.

Darning Kintsugi
The results of trying kintsugi on textiles did not completely correlate with the design considerations of this research in relation to either ‘aesthetic’ or ‘ease’ (see Section 4.3.1.5). After the success of the darning method (see Section 4.3.1.7) on repairing knitted jumpers and socks, I wanted to combine kintsugi and darning together and to try gold and silver thread (Figure 51). This method could be studied in the darning section; however, darning kintsugi would interest more people as a separate method and inspire different repairs during workshops.

Boro
Boro is the name given to traditional clothes worn by Japanese peasants since the seventeenth century, and it also refers to the special way of repairing these traditional clothes (Figure 52). They are passed down through generations, become damaged or worn out, and then amply repaired and reused. It has a strong effect that invites people to reassess the concept of value and consider the meaning of fixing in our consumer society.
This method originates from the theory of mottanai, meaning ‘too good to waste’ (Wada, 2004). Boro fabric is woven with cellulose fibres and dyed with natural indigo. It is used and maintained throughout its owner's lifetime and passed down through generations. These clothes are also tangible remnants of the humble stories lived by the common people who are the owners of these clothes (Wada, 2004). Hence, they convey emotional power as well as authentic aesthetic value. Family histories can be traced through their patterns which have been darned by successive generations. Today, these objects are valued and presented as art.
Boro was studied in this research as it is an inspiring and stimulating method. I used this method to mend the holes in the espadrilles in Figure 53.

Patching
Patching is a widespread mending technique and has various versions of its application in different cultures. A selection of decorative patches can be found anywhere with sewing and craft supply stores. Hence, at first I did not know how to incorporate this ancient and widely applied repair method into this research in a creative way. However, in the end, this method was the starting point for some of the most engaging repair methods in this research, such as Sugru patching, kintsugi textiles, textile patches and 3D-printed patches.
First, I started experimenting with this method on shoes and then used it on backpacks. For example, I tried fixing the torn straps of the backpack in Figure 54 with textile glue. However, it was not strong enough to carry the weight. I sewed the torn parts and joined them. I glued a leather patch on it to cover the damaged parts. I tried to sew the corners of the patch, but the leather was too thick to sew. After this attempt, I concluded that I should use thin patches that were easy to sew.

Sugru Patching
Various applications of this method are available on the Sugru website on knitted jumpers, shoes and bags. This method is included in the design studies and workshops, as it is easy to apply and a very effective solution. To apply Sugru patching repair on fabric, the repairer tears off a small pea-sized amount of Sugru and smears it through the fabric to create a strong bond. After that, the repairer adds more Sugru to work on the desired shape. It is machine washable and tumble-dryer safe. This method worked with jeans and thick cotton but the result was not successful with synthetic textiles and knitted garments. For example, I tried to fix the beanie in Figure 55 but sugru did not stick to it properly.

Basket Weaving
Basket weaving is one of the oldest craft activities in the history of humankind. This process involves weaving pliable materials into three-dimensional artefacts. This method was used in the design studies because it is easy to apply, low cost and sturdy. 
I was inspired to try basket weaving methods after finding the damaged rattan chair in Figure 56. Its backrest was damaged and some of the parts were missing. I wove the missing parts in the same pattern and used a rope in a contrast colour to emphasise my contribution. I used the same method to fix the yellow basket in Figure 57. I wove the rattan reed through the side walls of the basket. The unity of different materials and colours was emphasised in these two examples, highlighting the work of the repairer.
Both the feasible and infeasible aspects of various repair methods were examined and the design considerations were developed with a phenomenological perspective. The next section describes how the design considerations were developed during the design studies.

Design Considerations
The first six design considerations were formed, considering the results of the cultural probes research and explained in Section 4.2.9. Seven more design considerations were also developed, based on the repairs I completed in the design studies.
1. Financial Cost 
2. Repair Duration 
3. Ease 
4. Personal Pleasure/Satisfaction 
5. Required Knowledge 
6. Required Skills 
The aim of the design studies was to study my repair experience in detail and understand it thoroughly before attempting to understand other people’s repair experience. Phenomenology helped me explore the unique and complex character of each repair activity. 
The process started with phenomenological reduction (see Section 3.1.2). Becoming aware of the preconceived ideas is the first and a crucial step to bracket them. Field notes were used to collect data during the design studies (Figure 58). Taking field notes is an effective method that helps researchers to eliminate personal bias and preconceptions during phenomenological studies, which are essential for establishing validity and reliability (Miles & Huberman, 1984).
I want to explain how the design considerations were created with an example. ‘The interest in the method’ category was developed while I was working with the small teapot in Figure 59. I bought it from an antique shop and its lid was missing. I started the research process by analysing the product, taking measurements and thinking about the repair solutions. My first repair idea was 3D printing the lid. I also developed an alternative idea which was finding another lid from second-hand shops or antique shops. I designed the lid and created the CAD model. Finally, the repair process was completed after 3D printing the part. 
My perception (epoche, see Section 3.1.2) was the primary source of knowledge in this phenomenological research (Moustakas, 1994). I took notes on what I perceived during the research process and reflected on what was happening, without judgemental evaluation (phenomenological reduction). My brief thought process can be seen in my field notes (Figure 58). After the repair is finished I thought about the barriers and motivations that I experienced. I asked myself questions about my choices, the enjoyable parts of the process and the difficulties. I realised that I wanted to try the 3D printing method because I was interested in the technology and CAD modelling. 3D printing technology attracts other people’s attention as well. This method can be effective to encourage people to try repairing and to overcome the barriers and negative stigma attached to repair activity. Consequently, the ‘interest in the method’ category has been created.
  Objects were photographed before and after they were repaired. The collected data was analysed and seven categories of design considerations were developed. Finally, I visited the field notes again, to make sure that I had included all the polarities and individual variations. 
7. Aesthetics 
During the design studies, I enjoyed the repair process more and wanted to complete it more enthusiastically when the final product was aesthetically pleasing, leading to the development of the ‘aesthetics’ category. This refers to the pleasure which results from the sensory perception of the repaired object. As physical damage is the focus of this research, the aesthetic quality is mostly related to sight and touch. 
8. Attracting Interest 
‘Attracting interest’ refers to the incorporation of interesting contemporary methods or new technologies into the repair activity. Using interesting methods is an effective strategy to overcome the stigma attached to the act of repair. If people focus on the interesting techniques they are using, it might be easier for them not to experience the barriers, and engage in the activity.
9. Accessibility of materials and methods 
In the current economic system, it is often easier and cheaper to buy a new product rather than repairing one that is broken. As a result of this, the methods, materials and tools for repair should be made easily accessible if we want people to repair products more often. 
10. Functionality 
Products might become non-functional after being damaged. This category refers to restoring the damaged product to working order as much as possible. 
11. Negative stigma attached to repair 
This category refers to the socioeconomic perception of repair (Middleton, 2014). Damaged, frayed and repaired products are associated with economic hardship and poverty (Kelley, 2009; McLaren & McLauchlan, 2015). Therefore, people might feel ashamed of repaired products. This fact might also affect user’s motivation to use a repaired object and discourage him/her from repairing. 
12. Improving the design of the object 
This category refers to making a product more valuable and more beautiful than a new product by repairing it. Is it possible to make the product ‘better than new’ through repair? The stigma attached to repair is a socially constructed idea that relates to the current social value system. For example, in a different social context a repaired product could be regarded as more valuable because it represents our respect for the environment. 
13. Storytelling 
Every repaired object tells a story. The main aim of this research was to encourage people to repair products more often and to create an awareness towards environmental problems. Stories are a significant part of creating awareness and spreading the message. As a result of this, one of the design considerations was the creation of a conversation piece through visible repair. 
Four Design Ideas 
After the design studies, I developed four ideas with the potential to address the research questions: 
1. Online social repair platform: The first idea was to create a platform such as a website or a mobile application to bring ‘people with repair skills’ together with ‘people with damaged products’. I designed the website and worked with a software engineers to develop it. The fully working website was completed within one month (see Appendix B). This website has two types of users: the repairers and people with damaged products. Repairers register on the website by clicking the ‘Join’ link and creating a profile. They can present the objects they repaired, their repair skills and contact information. Similarly, users who want to access the repair service also need to register and create a profile. They can look for certain products by using the search bar or the ‘Categories’ link. The newly completed repairs are shown on the home page and are listed according to popularity. Users can view the repairers’ profiles and ‘like’ their works. They contact the repairers whose work they like best to access the repair service or to learn how to repair their damaged item by themselves. I presented the website to participants in the first two workshops. I did not pursue this idea subsequently for three reasons: first, workshop participants did not register on the website; second, it requires a lot of effort to create the user network, and third, repair kits that addresses the research questions emerged naturally during the workshops. 
2. Repair Products: Designing products that users need to repair before they use them. For example, products which have parts that are incomplete or broken, and which become complete after users repair them using the methods I developed during the design studies. 
3. Inspirational Repair Booklet: This booklet presents practical and visible repair examples, repair instructions and interesting stories to inspire people to repair products more often. I planned to include the repairs that I completed during design studies, together with the workshop results. 
4. Repair Kits: These repair kits are designed based on the repair methods I developed during the design studies, and aim to inspire and encourage people to repair products more often.
Various repair methods were explored during the design studies. I briefly explained twelve methods, including 3D printing product parts, kintsugi, darning and patching. The aim of this process was to identify the repair activities that have the potential to encourage people to repair products more and to study the repair experience in detail before the workshops. Some similarities, repetitions and patterns started to emerge among the repair methods and the types of damaged products during the design studies. I will explore these patterns further in next section, which includes the workshops and how the findings of the design studies and workshops led to the four design projects. Finally, design considerations were employed to evaluate and explore the repair methods during the workshops.

Workshops
This section presents Phases 3 and 4, namely the project development and the evaluation phases of this research (see Figure 1). First, the structure of the workshops and the participants’ experiences are described with examples. Then the research outcomes and concludes the testing of the design ideas are presented. Four repair workshops were conducted in this research, in which participants were asked to bring their damaged products. The workshops were conducted at the Royal College of Art. Each workshop process started with booking the room and continued by putting up the posters (Appendix C) and placing advertisements to recruit participants, printing worksheets, hiring the recording equipment, arranging the workshop tool bag (see Section 4.4.2), including the required materials, and finally setting the scene. Because of the workload, it was convenient for me to organise two sessions in one workshop rather than running two separate workshops on different days. Additionally, the ideal number of participants for the workshop is between six and eight if there is only one facilitator. Thus, I divided Workshops 1, 3 and 4 into two sessions; Workshop 2 was conducted as one session because there were two facilitators (Figure 60). The workshops were video-recorded, with a camera situated in the corner of the room. Photographs of the repair processes and the ‘before’ and ‘after’ phases of the repaired objects were taken during the workshop.
Each session started with an introductory presentation explaining the outline and the aims of the workshop, the scope of my research and finally the repair techniques developed during the design studies. The first two workshops primarily intended to:
Explore both the feasible and the impractical aspects of four design ideas developed after the design studies.
Investigate the motivations and barriers (design considerations) that people experience in relation to repair.
Test the product repair techniques developed during the design studies (investigate how participants make use of these methods and materials). 
The first two workshops aimed to identify the most appropriate answer for the research question among the four design ideas developed after the design studies (see Section 4.3.3). For this, I explored the specific repair methods which participants chose and were interested by, the activities they were successful at and the parts they either struggled with or enjoyed during the repair process. I also presented the idea of the online repair platform to observe the participants’ reaction and thoughts in the first two workshops. I explained the website and said that anyone who was interested could register and upload the repair works s/he had completed. Participants were not interested; no-one registered or asked any questions about the website. Thus, I did not pursue this idea after the second workshop. 
Participants were interested in the repair methods and asked questions about where to get the materials and the tools. Some of the participants stated that they wanted to learn the details because they wanted to practise these methods by themselves. Additionally, the repair methods started to turn into kits, as some examples of damage started to emerge repeatedly. For example, certain shapes were used more frequently than others in textile patches. Consequently, I decided to work on these methods further and to design the repair kits, because they were the most appropriate answer to the research question in the context of this research.

Workshop Plan
I first introduced myself and presented the repair methods, with examples, in order to inspire the participants and help them visualise the methods they were going to apply. I explained the repair methods briefly by showing examples and describing the advantages and disadvantages of using each method. 
Before the workshops, I prepared a worksheet to collect data and guide the workshop process (Appendix D). The worksheet explained the four tasks of the workshop. I handed out the worksheet to participants after the presentation. After the participants chose the most suitable methods to repair the products, they repaired them and filled in the worksheet according to their experience. 
Task 1-Discover: The first task was for the participant to observe the object and understand the problem. Each participant explained his/her product and answered the questions: What is your product? Can you explain its features? Can you describe the broken part? 
Task 2-Ideation: This task represented the generative stage, focusing on developing repair ideas. It oriented the participants to quickly visualise their design and the repair process by using the available tools and materials (play-dough, post-its, coloured pencils, markers, cardboard, paper, textiles etc.). Participants also did some sketches during this task before implementing their idea. 
Task 3-Feedback: This task aimed to discuss the participants’ ideas and to develop them further. Participants received feedback from the facilitator and also gave feedback to each other. 
Task 4-Implementation: Participants implemented the ideas and concepts from the previous creative stage with the help of the facilitator and other participants. 
Final Discussion: Each participant explained and evaluated the process by answering the questions: Can you please explain to us your process and your work? 

Workshop Tool-bag
During the design studies, I explored various traditional repair methods, together with new materials and technologies. The more products I repaired, the more materials and tools were collected. I organised these materials in a tool-bag and redesigned the tool-bag for the repair workshops to conveniently inform and inspire the participants. This package of materials included fabric, a 3D printing pen, patches, Sugru, sewing tools, etc., which would be needed for the repair activities (Figure 61).

Research Outcomes
This section describes the outcomes of the workshops, covering the participant information and the workshop tasks: discovery, ideation and implementation. 
Fifty-two participants attended the workshops: fifty-four per cent were female and forty-six per cent were male. They were between the ages of eight and sixty-six and were from a range of different occupations, including university students, designers, and retired teachers. Table 2 shows the workshop participants in numbers with the products they repaired and the repair methods they used. Participant selection strategies for the workshops are explained in Section 3.4 in detail. 
The data about participants’ experience was collected from the worksheets and through my observations. First, in the worksheet, I asked them to explain their repair process, including the parts they enjoyed and the difficulties they encountered (Appendix E). After the workshops, I wrote each participant’s answer on a sticky note and put all the notes on a paper on the wall to explicitate the data (see Section 3.1.2) and see it as a whole (Appendix F). Secondly, I took notes on the conversations I had with the participants and my observations. These notes also enabled me to better understand participants’ motivation and the barriers they experienced in relation to repair. In phenomenological studies, validity is obtained by looking at the field notes multiple times. This helps the researcher to become free of preconceptions and merely report what s/he sees and experiences (see Section 3.1.2). Meaningful clusters started to emerge from the participants’ answers and two design considerations were developed after the analysis. The outcomes are presented below with examples from the repair processes and participants’ quotes, to explain the contribution of the workshops in answering the research questions. 
It is important to include the diverse aspects of human experience in phenomenological studies (see Section 3.1.2). In the context of this research, the motivations and barriers were explored considering the polarities and reversals of participants’ experience. The motivation and barrier categories were finalised after the second workshop and tested in the last two workshops to investigate and search for further individual perspectives. Four workshops were conducted because I observed that the research had reached data saturation. In other words, the data started to repeat itself, and it did not add anything new to the objectives of this research (see Section 3.5).

Workshop 1 
This workshop consisted of two sessions. There were three participants in the first session and six participants in the second (Figure 62). The first session took ninety minutes, and participants repaired three objects, while the second session took two hours and participants repaired six objects.

Workshop 2 
Eighteen people participated in Workshop 2. It was conducted in one session because I had another person to help me facilitate this workshop. It lasted for three hours. The participants were divided into five groups, but they repaired their products individually (Figure 63). Eighteen objects were repaired in total. 

Workshop 3 
Fourteen people participated in the two sessions of Workshop 3 (Figure 64). Unlike the introductory presentation in the first two workshops, I explained the Do-Fix repair kits in Workshops 3 and 4. After the idea generation stage, I asked participants to choose the appropriate kit or repair method to repair their damaged products. The first session took two hours and a half and included nine participants. The second session lasted about an hour and a half, and there were five participants. Three participants used textile patches, two participants used plaster patches and two participants used 3D-printed patches to repair their products.

Workshop 4 
Workshop 4 was conducted in two sessions and included four participants in the first session and six participants in the second. Both sessions took ninety minutes. Three participants repaired their objects with the kintsugi kit, two participants with 3D-printed patches, two participants with plaster patches and one participant with textile patches (Figure 65). 

Repair Experience 
The repair process in the workshops was guided by the tasks on the worksheet. I asked participants to observe and explain the object and the damage to it at the beginning of the workshops. Participants wrote their observations on the worksheet, including the product features and details about the damage (Appendix E). In the second stage they developed their repair ideas, considering the repair methods I presented. Finally, they repaired their products and explained the process on the worksheet. 

Discovery (Constructing the Repair Decision) 
Based on Desmet and Hekkert’s (2011) framework of product experience, participants defined their products according to three aspects: the meaning of the product, its aesthetic features and emotional value. The meaning of the product refers to its symbolic value that a human gives to the product. For instance, Participant 4 explained that his watch was an ‘impressive’ watch from a well-known brand. Other participants focused on the aesthetic aspects of the products: Participant 1, for instance, explained that his product was an antique bowl with a gold rim, and participant 15 defined hers as one hundred per cent wool jumper. Lastly, some of the participants described their products by considering their emotional value. For instance, Participant 28 was concerned about fixing his girlfriend’s dress, which had an emotional value for the couple (Figure 66). He phoned his girlfriend before every step he took and repaired it carefully and slowly. The emotional value was not only a factor that affected participants’ repair processes, it was also a result of it. In other words, an object might become emotionally valuable after repairing it because of the unique memory users share with the product. Chapman (2009) explains that a product possesses a narrative when users share a unique personal history with it (p.33). Participant 15’s knitted jumper was a good example of this: she said, ‘It has become very personal, unique and valuable to me now’ after repairing it (Figure 63).

Ideation 
Participants explored various repair solutions for their damaged products at this stage. They explained their colour choices, design ideas and possible material selections (Figure 68). For example, Participant 5 brought her brown leather boots to the first workshop. One of the pair was frayed on the front right-hand side and had a small tear on it. She considered repairing it with textile patches and Sugru. She designed star-shaped and lightning bolt shaped patches to repair it. After discussing this with me and other participants, she decided to use both of the materials. She made the frayed parts stronger with a textile patch glued inside the boot and also put a Sugru patch covering the torn part on the outside.
Some of the participants identified the ideation part as the most enjoyable part of the workshop (P5, P6, P11, P13, P14, P19, P24, P27, P34, P38, P49, P51). Participant 14 said that making design choices while fixing the object was entertaining. Similarly, Participant 27 stated that he enjoyed searching for new possibilities and trying design ideas during the idea generation stage.
Besides the enjoyable aspects, participants also stated that they had some difficulties in coming up with solutions and choosing the right techniques and materials during the ideation part (P2, P19, P20, P23, P25, P32, P36, P37). Participant 36 explained her struggle as ‘Finding a solution about how I could fix this sweater was difficult. I think if the sweater were not expensive I would not fix it’ (Figure 69). Another thing was that although most of the required materials were available, some participants struggled in choosing the appropriate technique. Participant 32 stated that he had difficulty with choosing the right method for the product and he did not want to spend time and money on trying different materials and methods. Similarly, Participant 37 asserted, ‘Finding the right material to fix was difficult’. This feedback demonstrated that providing the materials and instructions required for the specific repair activity via repair kits could be helpful in encouraging people who were not experienced at doing repairs. Consequently, after I explained the process and gave suggestions about the materials, they easily repaired their products.
Some participants said that they had never tried fixing an object before so they needed basic information about the repair process. For example, Participant 23 was hesitating to repair his laptop case, and he said, ‘I do not know how to join leather. I had difficulty in thinking about the ways to join leather’ (Figure 70). This showed that repair kits should provide the basic instructions for all skill levels and the materials which were adequate for the purpose. The textile patches technique was developed as a kit after the conversation with Participant 23. The design and development process of textile patches kit is explained in Section 5.4 in detail. The kits aimed to give people the confidence that the repair would be successful, so that eventually they would not worry about the time and money spent.

Implementation
The implementation stage was the active part of the workshops. Participants implemented the ideas which they had developed during the idea generation. People usually think repair is about disguising damage. One of the reasons for this idea could be the negative stigma attached to the act of repair and repaired products. Although there were some participants who wanted to hide the traces of the repair, the majority of the participants declared that they liked the idea of making the repair visible. For instance, Participant 4 stated that he enjoyed repairing his watch strap with contrasting colours and different patterns instead of trying to hide the fixed part (Figure 71). He added that trying diverse materials and generating possible solutions in order to make the damage beautiful was satisfying and fun. Similarly, Participant 1 said, ‘I like the idea of making the repairing visible with other materials’. At the end of the workshops, participants stated that they were pleased with the repaired products (P1, P2, P4, P6, P13, P15,). Participant 15 explained her feelings as ‘Very happy with the result’ (Figure 67). Similarly, Participant 49 stated that ‘I enjoyed the design and implementation stage and I loved the idea of fixing visibly and emphasising that the object is different now’. Contrary to this, some participants wanted to repair their products in a way that would make the damage and repair invisible. For example, Participant 27 wanted to return his product to its original appearance and he said he wanted to make it perfect again (Figure 72). He described his shirt as a business shirt in blue, perfectly tailored. The area around one of the buttons of his shirt was ripped. We discussed various visible repair solutions, such as Sugru, sewing and patching, but he stated that he did not want to repair his shirt visibly and stated, ‘The solution is not matching my perfectionism either in craftsmanship or in look’. However, he changed his mind after other participants persuaded him. He was afraid of taking any risks while repairing his favourite shirt, although there were many reversible repair methods, such as sewing and patching. After this case occurred, and in discussion with Participant 27, I decided to include ‘reversibility’ as a new category to the design considerations. Finally, Participant 27 preferred patching the ripped part with a neon yellow fabric, as the method was reversible, and in the worksheet he stated that it was fun to try new things.
Similarly, another participant was worried about taking risks during the repair process. Participant 5 said, ‘I am scared of doing something that I cannot go back on if I change my mind’. Consequently, these cases showed that if the repair process was reversible participants found it easier to engage in the activity. Another category, ‘endurance’, was also added to design considerations after the first two workshops as some participants stated that they were worried about the strength of the repaired part and how long the repair was going to last (P1, P3, P4, P10, P20). For example, Participant 3 said that she needed the product and was worried about whether the repair would last. 
Although most of the participants stated that they enjoyed the implementation, it was one of the most challenging parts of the workshop. Participant 19 was one of the participants who struggled during this process. He had brought his sweatshirt to the second design workshop to repair. It had some small holes in it. After deciding together to use darning method to mend it, I left the table to talk with other participants. After a while, I observed that he was hesitating to start mending the sweatshirt. Then he stated that he could not sew. When I suggested to him that he could glue on small patches he replied that he was not good at glueing and would mess it up. He did not repair the sweatshirt at the end. This incident again showed that the real problem is not the damage, but is rather human behaviour and people’s relationship with the products. After this case, I focused on thinking about ways that could encourage people like Participant 19 to repair their products easily. Consequently, the idea of plaster patches emerged, which is explained in Section 5.5.

Design Considerations
Design considerations were finalised with the two categories generated through the workshops.
14. Reversibility: If the repair method is reversible it is possible to restore the product to its previous state. If the repair was reversible this might reduce users’ negative feelings, such as worry and stress, which is usually seen when the users are not confident about their skills and experience, or when the product has special value for the user. 
15. Endurance: This consideration refers to the strength of the repair and how long it lasts. Participants preferred long-lasting repair solutions, as they might get frustrated in spending time on the same damage repeatedly.

Testing the Do-Fix Kits and Design Considerations 
This section presents the testing of Do-Fix kits during Workshops 3 and 4. These workshops were focused on how participants use the Do-Fix kits, as well as exploring the parts they enjoyed and the difficulties they encountered during the repair process. I asked participants to choose one of the repair kits to fix their product and fill the questions in the worksheet according to their repair process. The results are based on participants’ answers, and my observations are explained for each repair kit. 
Kintsugi is an inspirational repair method that transforms the damaged product into a beautiful and interesting object. The kintsugi kit was designed for low skill level users and requires a low level of repair knowledge. The majority of the participants stated that they enjoyed the process and they were pleased with the final product. For example, Participant 48 wanted to try the kintsugi kit and repaired the small ramekin that comes with the kit (Figure 73). At the end of the process, he said that ‘Preparing the mixture, mixing the gold powder with glue and turning it into a gold liquid, was enjoyable’. Similarly, Participant 45 repaired her broken plate with the kintsugi kit and said that ‘When I fixed the plate with glue and gold particles it looked really nice, like a new plate with a new design’. However, some participants found it difficult to hold two broken pieces together for two to three minutes until the glue dried. Here, it is important to be patient and careful, otherwise the gold glue smudges and creates an undesirable result.
The textile patches kit was designed after similar damage was seen frequently among bags, shoes and other leather goods during the design studies and workshops. Participants brought these kinds of products to workshops with the aim of using them for longer rather than creating a decorative object. Therefore, in the case of textile patches, functionality is one of the most significant categories of the design considerations. For example, Participant 34 brought a faux leather jacket to Workshop 3. Although it was frayed on the shoulders, she said that she wore it frequently. She used green faux leather patches to cover the frayed area. 
After the repair, she stated that she liked the idea of giving new life to a damaged object by redesigning the damaged parts. 
The majority of the participants were interested in 3D printed patches. They asked questions about this method and wanted to try it. Some participants said that the object turned into something different and original with these patches (P41, P47, P52). For example, Participant 47 used the patch to create a strap for her watch. She declared that she chose that particular kit as the 3D printed pieces look like a piece of jewellery, such as a bracelet. Similarly, Participant 52, who used this patch on the edges of the sleeves of her jumper, said that the patches transformed her jumper into something extraordinary. 
Plaster patches were designed for enabling easy and low-cost repairs. Using this kit requires neither skill nor knowledge, and users can create different designs by using patches in different colours and shapes. For example, Participant 50 brought her damaged tights to Workshop 4 (Figure 74). She said she has nearly fifteen pairs of tights: all of them were laddered and she did not want to throw them away. She wanted to find an easy, quick and cheap way to mend them. After applying plaster patches, she stated that the repair was very easy and the end result was surprising. She added that she enjoyed choosing different colours and shapes of patches and creating her design. 
As this kit is specifically designed to make the repair easy, participants did not find it difficult to apply. For example, Participant 29 declared that the process was very easy, adding, ‘I just pressed the patch with an iron’. Some participants preferred using bright colours: for instance, Participant 49 repaired his socks with a big red circular patch (Figure 75). He said that ‘I loved the red patch. I think it looks really nice on a light grey sock’. On the other hand, some participants wanted to make their repairs less visible and used the patches of the same colour with their clothes. 
To conclude, participants used Do-Fix kits to repair their products during Workshops 3 and 4 and reflected on their experience, based on the repair process they used and the repaired product. As the majority of damages were fixed and the participants’ responses were positive, we can say that Do-Fix kits were successful at empowering and encouraging the participants to repair their products.

Chapter 5 : Do-Fix Repair Kits

Introduction 
This chapter presents the Do-Fix repair kits, reflecting on how the findings of the design studies and workshops led to these design projects. Do-Fix consists of four kits, namely a kintsugi kit, 3D-printed patches, plaster patches and textile patches, which were designed to help people fix products more often and encourage them to have a deeper relationship with things through repair. The Do-Fix kits were designed for the transition stage towards a circular economy, and for products that are not designed for a circular economy. We are currently at the beginning of this transition stage, and the majority of the products that we are using today are not designed for repair, remanufacturing or recycling. Although they are not circular, we cannot throw all of them away and start using circular products. This transformation will take time and we need to get the most value from the products to minimise their negative environmental impacts. Do-Fix kits are a solution for keeping these non-circular products in use for longer through repair. Moreover, this ‘throwaway’ mentality has damaged the relationship between people and products. People have become passive users who consume products for their symbolic value and socially constructed meaning, and cannot see the real value of things anymore. These kits also enable people to engage with products at a material level through repair, and help them to better realise the value of products and the material embodiment of meaning. 
The ultimate aim of these design projects was not to find the best repair methods suitable for a range of damage. It was to identify ways that would enable people to repair more products and experience deeper relationships with products to create awareness. 3D-printed patches might not be the best solution for mending a knitted jumper; however, it was one of the methods that drew participants’ interest and helped them engage in the repair. Participants focused easily on the process of fixing, and did not engage with their preconceptions and negative assumptions, such as the idea that the repaired products were tainted or scarred, or their lack of skill and confidence. 

Why Kits? 
The repair kit concept is common for certain products, such as bicycles, clothes and wooden furniture. The bicycle kits and sewing kits are usually designed for unexpected situations and urgent repairs. For example, bicycle kits include tools and materials for fixing tyres quickly. As mentioned in Section 2.12.1, the clothing company Patagonia developed a pocket-size expedition sewing kit in collaboration with iFixit, for the purpose of encouraging self-repair. Similarly, this kit is for quick fixes during expeditions. Scaling these examples up and creating more kits for various products and other types of repairs would be helpful in encouraging people to repair more products.
After the design studies, I developed four design ideas to address the research question (see Section 4.3.3). However, considering participants’ reactions and comments after Workshops 1 and 2, I concluded that repair kits were the most suitable way to addresses the research question, for a number of reasons. First, the workshop participants were interested in the repair methods rather than the other design ideas. They asked questions about the materials and where they could get them. Second, the repair methods that I developed during the design studies started to become like repair kits as more participants used them for similar damages during the workshops. In other words, the repair methods naturally evolved into repair kits throughout the design studies and the workshops (Figure 76). Third, the kit concept is the best way to reach the objectives of this research, as it encourages people to repair products more often by offering methods, materials and instructions in a convenient way to guide users through the process. Fourth, visible repair gives voice to everyday ordinary objects to spread their story and value. It enables people to create powerful stories which spread the message and raise awareness about environmental problems.

Kintsugi Kit 
The Japanese repair method known as kintsugi is employed to mend cracked or broken ceramics using precious metals such as gold and silver. Kintsugi transforms the damaged object’s value, meaning and appearance. Inspired by this traditional method, the kintsugi kit makes this method more accessible and easy to use by offering instructions (Figure 78). It contains metal powder, ceramic glue, an application stick and gloves (Figure 79). Also included is an instruction booklet with examples and a pre-broken ramekin (Figure 80). 
The conventional kintsugi method is a labour-intensive art and requires skill, knowledge, experience and a lot of time. This method requires a number of materials, most of which originate from Japan, and which are expensive and hard to access elsewhere. However, kintsugi-like repair can be accomplished with other materials, thanks to recent polymer technology. In the design studies I had worked on broken ceramics, including the origami vase (see Section 4.3.1.1), using two-part, food-grade epoxy to join ceramic pieces together. I had tried many acrylic and oil-based paints to imitate the gold and silver. Although the final objects looked good, their appearance did not reflect the metallic effect. I then experimented with powdered brass and aluminium on various ceramics, and they looked similar to the real kintsugi repairs. 
My specification for a ‘kintsugi kit’ took final shape after considering comments from the workshop participants. The most frequent enquiry I received was about where they could get the materials. Thus, the idea of providing the materials and instruction methods in a kit came up. Users would be able to achieve a kintsugi effect without struggling to find the right materials. Some of the participants said that they wanted to try this method, but they did not have any broken ceramic products: when any ceramic or glass objects break they throw them away. In addition to this, some of the participants who did have broken ceramic goods, and wanted to apply kintsugi, hesitated to do so. They asserted that they had no experience and were worried about their skills. After these comments, I decided to include a ‘testing piece’ in the kit, a broken ramekin. Users can experiment and gain confidence using the broken ramekin provided in the kit, and after fixing it they can confidently fix their own objects. As the kit has more kintsugi materials than those which are needed to fix a small ramekin, the remaining materials could be used to fix other objects when they break. Providing a prebroken object as a part of the kit enables the user to learn and gain confidence, while s/he also ends up with a repaired ramekin. The experiential dimension of providing a pre-broken object can be compared with Droog Design’s ‘Do create’ project (see Section 2.12.4). For example, in the case of the ‘Do Hit’ chair the user hits a metal box with a sledgehammer to transform it into a seat. The final product depends on the user’s strength and imagination. Users are invited to engage with the product, and accordingly their engagement completes the product. Moreover, this engagement enables the user to experience a relationship with the product which is different from, and deeper than, the passive user-product relationship allowed by the dominant linear system. 

3D Printed Patches
3D printing is a relatively recent manufacturing technology with definite potential for enabling product longevity through repair. This technology potentially drives people to focus on the ‘fun’ and ‘cool’ aspects of the technology instead of thinking about barriers, such as their lack of experience and skill level. 
3D-printed patches were inspired by conventional mending techniques for textiles, such as darning and patching (Figure 81). Initial designs were two-dimensional pieces that could be sewn on fabric (see Section 4.3.1.8). I also worked on flexible structures including chain-like designs and patches with joints (see Section 4.3.1.8). These patches were developed and tested during the workshops (see Section 4.4.4).
Seeing endless possibilities of sizes and shapes of damage, and considering workshop participants’ feedback, I concluded that the 3D-printed patch design should be adjustable for different examples. However two-dimensional one-piece designs did not answer all of these problems, as they were rigid. For example, a one-piece patch does not offer a range of solutions for different kinds of damage, and it was too rigid for mending textiles that bend in three dimensions. Thus, I worked on modular designs that users can play with according to the type of damage.
An exploration of the movement of sewing and the form that thread creates inspired this design. The 3D-printed patch is made out of semicircular button-like 3D printed parts, strung on a fishing line (Figure 82). Each button has two holes. Users can adjust the length of the patch by adding and removing beads as required. The 3D-printed patch is sewn onto the fabric through the buttons (Figure 83). 
Fishing line is used in this design because it is stronger and durable than using small joints between 3D-printed parts. Fishing line enabled the seam-like shape of the design. As the 3D printed buttons are small, adding joints to them would change the design completely. Additionally, small joints can get worn or damaged during the assembling and disassembling. Moreover, these patches are designed to be reused several times. 
The kit was designed to take into account people’s worries about sewing perfectly, as elicited through discussions in the workshop sessions (see Section 4.4.1). The sewn parts stay between the beads, so that they are not visible, which eliminates the worry for users about their level of skill. 

Textile Patches
Initially, I did not know how to include this conventional repair method in this research in a creative way when I started experimenting with patching. Then it inspired various new repair methods. For example, textile patches were designed for pragmatic reasons. The need to fix bag straps, damaged belts and holes in shoes during both the design studies and workshops informed this kit design. The kit contains textile or faux leather patches, a needle, thread and textile glue. The patches are used to join the ripped parts with textile glue. After this, depending on the damage, they are sewn in order to make the repair durable (Figure 84).
This repair method was frequently applied during the design studies and workshops as it is very practical for mending bags and shoes. I initially experimented with this method on a backpack. The straps were torn apart, and I tried using textile glue, sewing and patching. Then a repetitive pattern started to emerge regarding the types of damage types to bags and shoes during the workshops. Most of them were fixed easily and effectively with textile patches (Figure 85). One of the most common problems was torn straps and worn parts of the bags. As the damage became repetitive, I designed a range of differently shaped patches to make the process easier. The patterns were also designed with sewing dots to make the mending easier, and the result more aesthetically pleasing (Figure 86). Users who already have the materials and tools can download the patterns with instructions to apply this method, as they are available on open-source websites. 
The kit worked very well for bags made out of textiles such as cotton, synthetic fabric and thin leather during the testing process in workshops. Participants found the sewing patterns practical, and at the same time enjoyable to apply. However, some users faced difficulty in sewing the patches when the bag’s material was thick. In some cases there was no need to sew, as the patch adhered strongly to the bag. 

Plaster Patches
Inspired by putting on plasters and the ease of applying them, this kit is designed for users with a low level of skill (Figure 87). Throughout this research I aimed to overcome perceived barriers, to encourage people to mend their products. Changing certain behaviour or adopting a new behaviour is not always an easy task; therefore, I aimed to target what is preventing the behaviour, and started with simple tasks, as suggested by Fogg (2009) (see Section 2.16.2).
The idea of the plaster patches came up after a conversation with a participant in the second design workshop. Participant 19 had brought his sweatshirt to the second design workshop to repair. The fabric had some small holes in it. After deciding together to use the darning method to mend it, I left the table to talk with other participants. After a while, I observed that Participant 19 was hesitating to start mending the sweatshirt. Then he stated that he could not sew. When I offered to glue small patches, he replied that he was not good at glueing either, and would mess it up. Afterwards, he added that he had never repaired anything before. I tried to help him but he had the idea that he was not skilled and experienced enough for this task. As the purpose of the workshops was to encourage users to repair their own items, the sweatshirt ended up being unmended. This incident again showed that what we are dealing with is not just the damage, but human behaviour and its relationship with the product. Anyone can find a way to fix any damage; however, the challenge is to make repair part of our relationship with products again.
We live in a world which is constantly in need of repair, so anyone can be called a mender (Spelman, 2002). Rewriting the research question specifically for this case, ‘How can we encourage Participant 19 to repair his sweatshirt?’ I thought about the possible repairs that he could have managed without considering the processes as an explicit ‘repair’, such as healing a wound or a cut in a finger. That reminded us of plasters. The majority of people are experienced in putting plasters on cuts. So, I decided to use it as a metaphor, as anyone can fix things in the same way as they might apply a plaster. 
The material of the plaster patches is vinyl. This patch is suitable for many fabric types. However, fabrics like cotton provide the best base for iron-on patches. The patch is positioned on the fabric and ironed for 15 seconds with pressure over a thin towel. It is ready to use after being allowed to cool down (Figure 91). 
After finishing experiments with the patch, I tested it with the workshop participants. I also contacted Participant 19 and conducted a mini workshop with him to test the plaster patches on his sweatshirt (Figure 88). The result was positive and he was pleased with the repair; he wrote on the worksheet that ‘I have never fixed anything before. This was my first attempt. It was pretty easy to fix with these patches, I just put an iron on it. I am glad that I have managed to fix it before the holes get bigger’. To conclude, the plaster patches can have a wide area of application, from umbrellas to shoes and tights (Figure 89, Figure 90). They are significantly effective for small holes in the fabric and designed for users with a low level of skill. 
Do-Fix repair kits invite people to reassess the concept of value and consider the meaning of repair in our throwaway culture. They are potentially important for consumers in terms of helping them to understand the value of objects and materials and their relationship with things through the lens of repair activity.

Chapter 6 : Discussion

This chapter discusses the research questions and how they were answered based on the results of three research studies and design projects. It continues by presenting the discussion of how Do-Fix repair kits can be scaled up to a broader design field or can be of use to other stakeholders of the circular economy. The chapter concludes by describing the limitations of this research and suggests recommendations for further research. 
Research Questions Revisited 
The importance of repair in the circular economy and during the transition stage toward the circular economy in terms of creating awareness about the value of products and materials in society was described in Section 2.9. However, the scholarship on the circular economy pursues a business-focused approach in which the relationship between people and products is neglected. Based on the gap in knowledge identified in Section 2.17, the first research question was formalised as: 
How can we encourage people to repair products in order to experience deeper relationships with things and create greater engagement with environmental problems? 
The research questions are closely connected to each other. Thus, in order to answer the first research question I needed to identify the motivation and barriers that people experience in relation to repair. Accordingly, the second research question was formalised as: 
- What are the motivations and barriers that people experience in relation to product repair?
Fogg’s behaviour model (2009), with its focus on removing the barriers and boosting motivation, was useful as a framework for determining the effective methods by which to address the first research question. Destmet and Hekkert’s (2007) framework of product experience, together with Crilly et al.’s (2004) cognitive response categories, were also instrumental in forming my approach to and understanding of, this research, and exploring how people experience the product repair process. This answered the research questions, in the light of these theoretical building blocks, through the systematic research conducted including the literature review, cultural probes, design studies and workshops. 
A rich collection of insights about the motivation and barriers that people experience in relation to product repair were generated throughout this research. First, the motivation and barriers that people experience in relation to product repair were investigated through the cultural probes research (Section 4.2). This research was successful in giving me an idea about what people repair and an initial idea about their behaviour. Additionally, the participants provided rich and diverse data which helped me to set the scene for the rest of the research. Seven motivation and six barrier categories were developed as a result of this research. Six of these categories were included in the design considerations. After the cultural probes research, I further explored the motivation and barriers that people experienced in relation to repair by reflecting on my own experience through phenomenological research, in which I visibly repaired damaged objects during the design studies. Six more design considerations were developed during the design studies. Two more design considerations were developed with a phenomenological perspective by observing the interactions of people with products during Workshop 1 and 2. The development of the design considerations was finalised after testing them with participants during Workshops 3 and 4 (see Section 4.4.4). Finally, fifteen categories of design considerations which influence people’s repair decision were identified. Consequently, the second research question was answered by systematically bringing the repair methods and motivation and barrier categories together as design considerations. 
These considerations were the building blocks of the Do-Fix repair kits. Together with the theoretical knowledge from the literature review, the design considerations were incorporated into the design of these repair kits. The core of every stage of their design process was choosing a simple behaviour target and removing the barriers (Fogg, 2009). I developed simple repair methods by taking into consideration the barriers. These methods were tested with participants during the workshops. I explored whether they were encouraged to repair their products with the help of these methods, and found out which methods were preferred taking into account the enjoyable experiences and difficulties they faced. 
Throughout the workshops, a wide variety of user perspectives were collected. Feedback from the participants confirmed that the repair methods which were designed as repair kits were found to be useful by the majority of the participants. Most respondents also said that their confidence increased, and their knowledge and skills were improved as a result of using the Do-Fix Kits. Participants used them to repair products throughout the workshops, which indicated that these kits enabled and encouraged them to repair their products and engage in a deeper relationship with things through repair. These results suggested that the Do-Fix repair kits were useful, and had an encouraging effect on participants. Consequently, the first research question was answered. 

Reframing the Function and Position of Repair in the Circular Economy and Adaptation of the System Diagram 
The role of repair in the circular economy in relation to the significance of users in the circular economy was discussed in the literature review (see Section 2.9). Based on the existing research, I concluded that the majority of the circular economy scholarship ignores user participation while focusing on the business aspects. For example, the Ellen MacArthur Foundation has developed a wide range of publications and learning materials with a view to promoting circular economy thinking to businesses and higher education institutions (Ellen MacArthur Foundation, 2015). However, users have not been directly included in the transition plan that it follows. A contradiction can be seen here, as the Ellen MacArthur Foundation, in its publications, emphasises that the circular economy requires a transformation from ownership to usership (Ellen MacArthur Foundation, 2013) and also ‘the user’ is situated in the centre of the system diagram created by the foundation, emphasising the user’s role further. Additionally, Pitt and Heinemeyer (2015), in their article documenting a case study of the work of the Ellen MacArthur Foundation, compared the systems thinking approach and behavioural change studies in terms of their impact on change towards the circular economy. They argued that the focus should be on the economy and system thinking rather than user behaviour and ‘persuading consumers’ (Pitt & Heinemeyer, 2015, p. 245), and the authors stated that ‘Its [Ellen MacArthur Foundation’s] priority has been to reach new audiences, both in business and education, with a novel approach based on design, systems thinking and economics, rather than individual behaviour change’ (Pitt & Heinemeyer, 2015, p. 258). It was outlined during literature review that all aspects of the system – environmental, social and economic – should be considered to successfully transition to the circular economy (Ren et al. 2013, Bakker et al., 2014a, Ghisellini et al., 2016). This research focuses on persuading and encouraging people to engage in the system through repair in order to create consciousness about the value of products and raise awareness about environmental and social problems. The ‘active user’, who is responsible and aware of his/her actions, is the basic unit of the circular system (Shah, 2014). S/he maintains the product to make it last longer, repairs it when it breaks, and s/he can also reuse or repurpose the product, with the aim of to making the most of its value. At the end of the use phase, the active user is responsible for returning the product back to the manufacturer for remanufacturing or recycling. 
Similar to the argument above, the system diagram (Figure 92) relating to the Ellen MacArthur Foundation does not completely reflect the changing role from the passive consumer to the active user. The system diagram based on Michael Braungart and William McDonough’s (2002) ‘cradle to cradle’ diagram illustrates the continuous flow of technical and biological materials. One side of the system diagram illustrates the consumption flow of biological materials while the other side shows the technical materials which are revalued through continuous cycles. The user who is in the centre of the diagram is the last destination of products before they go into the loops. The system diagram illustrates the responsibilities of the user towards the manufacturers, such as returning the product back to the service provider, product manufacturer and parts manufacturer. However, it only shows the ‘maintain’ loop among the active user’s inner loops (Figure 92). In other words, ‘the user’ has its own loops, including ‘maintain’, ‘repair’ and ‘reuse’, which make them an active participant, but the systems diagram illustrates the active user as a point in the system through which products pass. Additionally, the inner loops are different from the outer loops, and they are as important as the outer loops for the system because the user creates value himself/herself with his/her labour. 
To reflect these deficiencies, I have adapted the diagram (Figure 93) to illustrate the user as an active unit with the inner loops, by which s/he engages with the system and returns value to it. The ‘repair’ and ‘reuse’ loops were added to the inner loop of ‘maintain’. These inner loops were illustrated as a part of the user’s active role (Figure 94).

Scaling up Do-Fix Repair Kits to a Broader Design Field 
How often do we think about products? The majority of people do not pay attention to the material value of things in our current throwaway society, which has engendered significant environmental, social and economic problems. This research highlights the consumer society’s disengagement from the materiality of things and their material value. It is not possible for the current linear system to continue, in the context of the earth’s finite resources. People can learn to perceive the real value of products beyond their symbolic meaning, and they can create new relationships with their environment, not mediated merely by signs but through consciousness that can be created via a physical engagement with products. New values can be created by repairing products and interacting with them at an existential level. The most important thing here is to create an awareness and confidence that they can change the current problematic state. This explanation sounds reasonable from an environmentalist researcher’s perspective, but why would a company be interested in repair kits or product life extension? Perhaps because it might be a way to create increase its market share, and might reduce competition by getting customers to return back to the company. For example, a backpack company is well aware of the fact that the backpack they sell is going to wear out over time and need replacing. When a company provides long lasting, high-quality products that enable a deeper relationship with objects, it might increase the possibility of customer loyalty. If it provides a repair kit customised to the product, it might increase the likelihood of the user repairing the product by him/herself. Accordingly, this would increase the warranty costs. When we consider the same example in the circular economy, there are more benefits in a business model in which the company retains ownership of the backpack and users have monthly subscriptions. In this case, the company sends a backpack to the user every year, repairs the old backpacks or recycles the ones beyond repair. Besides the advantage of increasing the customer loyalty and decreasing the warranty costs, the company saves on the repair service costs. As the possibility of the user creating a deeper relationship with the product increases, the user might keep the product for longer, which means that it is more resource-efficient for the company and results in a reduction in material costs. Consequently, there are four important reasons for a company to provide repair kits with their products: the possibility of increasing customer loyalty, decreasing warranty and repair service costs and enabling resource efficiency

The Scope of This Research on the Spectrum of Maintenance and Repair 
Although repair and maintenance are two closely related, they differ in terms of the state of the product that requires one of these activities. The spectrum of maintenance and repair is divided into two parts with the line of ‘breakdown/damage’. This research is located on the repair side of this spectrum. The products that require maintenance and any maintenance acts were not included. 
This research aims to create awareness about the problematic relationship between users and products. Repair addresses this aim as it is an activity that engages people with the products materiality and helps them create deeper relationships. This can be achieved by maintenance as it also requires a materialistic engagement with products. However, I wanted to focus on repair because of the creativity involved in visible repair, the visible aspect of it that enables storytelling and it is an act of design activism (Section 2.13). A visible repair is a creative act of fixing an object aiming to create something artful and beautiful out of it. It enables people to spread the message about environmental problems through creating powerful stories. Additionally, a product demands immediate attention when it breaks. This might create a stronger trigger for people to spend the effort and time for it. On the other hand, a product requiring maintenance can be more easily ignored than a broken product. As I explained in Section 2.16.2, motivation, ability and triggers are the three factors which form a behaviour change according to Fogg’s Behaviour Model (Fogg, 2009). 
As I explained in Section 4.2.1, I received one hundred and three photographs of broken and repaired object from participants. Ninety-three of these were in the scope of this research. I did not receive any product maintenance photographs. Ten objects which were not included were regarded not as repairs but temporary adjustments, such as putting a cardboard piece under the table, and six of them were building repairs such as painting the walls of a room. I focused on repairing physically damaged products during design studies (Section 4.3). Similarly, participants brought their broken products to the workshops and they repaired them (Section 4.4). As I explained in Section 2.11 there is no single product category focus in this research. However, the focus is on physical damage which defines the scope of this research as repair. Mainly, physically damaged textiles, ceramic products, shoes and leather goods were repaired. Small furniture, glass products and toys were also included. Patching, sewing, and darning are three examples of the repair methods utilised to repair textiles. Maintenance acts such as cleaning and removing pilling from clothes were not included. As the focus of this research was physical damage, electrical or electronic problems were not included. However, two mobile phones, three MacBook chargers and one computer mouse were repaired as they were physically damaged.

Limitations of This Research and Recommendations for Further Research 
This research aimed to design a product or service that empowers people to repair products more often, and accordingly started with certain research questions. While these questions were addressed through systematic inquiry, new questions emerged which are not possible to address within the time limits. In this section, these new questions are discussed and a number of topics are presented on which further research would be beneficial. 
This research is focused on the transition stage towards a circular economy. Do-Fix kits are designed for non-circular products, aiming to make the most of their value and decrease their negative environmental impacts. Further studies might explore the development of repair kits for circular products that are suitable for each product’s technical and biological materials. As the relationship between users and products and businesses will change after the transition, it will become easier to get users’ insights and collect data about product use and disposal. This in-depth data would be beneficial for developing repair kits customised to each product, taking into account users’ needs and wants and the reasons why products break. 
I developed four repair kits out of the twelve repair methods that I explored during the design studies. These four kits were chosen based on the design considerations; however, some of the remaining methods can also be designed as repair kits. Further studies can be done to develop more repair kits by focusing on various types of damage.
In this research, I explored the different ways to enable users to repair their damaged products by themselves. Further research in terms of the business aspects of self-repair would provide opportunities for increasing the product lifespan and empowering users to repair more products. The repair business models were explained in Section 2.10.3 and include the repair service offered by manufacturers and reuse organisations. Self-repair can be developed as a business model and incorporated into other circular business models. Throughout this research, I studied motivated people and the things that motivate them to repair products as well as the perceived barriers that prevent them from fixing things. Further research can be carried out on the people who are not interested in repairing things. Identifying their insights and why they think and behave in this way would be helpful for a better understanding of human behaviour to change it to a more sustainable approach. 
Do-Fix kits were developed in a social setting during the workshops. Participants used the kits to repair their products by themselves which indicated that these kits enabled them to repair their products. However, there are some limitations of this research which require further studies. First, it is not known whether the kits will be used by individuals, outside of this social environment. The workshop provides a social environment that might have a more encouraging effect on the participants compared to repairing alone in their everyday environment. As there were other participants with different skills level, they had the chance to help each other. They talked to each other. Accordingly this gave them the opportunity to solve the problems momentarily. Otherwise, it is more likely that people give up before completing the repair when they stuck with a problem outside this social environment. Second, it is not known whether customers would decide to buy the kits when they see them on the shelf of a shop. People might not feel the need to buy a repair kit when they have not got any damaged product. It is also unknown whether they would like to shop online or go to a shop to buy these repair kits when any of their products break. Third, it is unknown whether they would remember to use these kits or not when any of their products break before throwing them away. It is a common user behaviour in today’s consumerist society to discard products when they are damaged. The answer to this question changes according to the product category and the type of damage. For example, it takes a while a backpack shoulder strap to rip off. The strap does not loose its functionality instantaneously giving the time to its user to think about solutions. This can act as a trigger to remind the user to buy textile patches and mend his/her backpack. On the other hand, the case might change for a ceramic plate. The user might prefer to throw away the broken pieces of the plate rather than keeping them until s/he thinks a repair solution like buying a repair kit. The fourth limitation is similar to the third one. It remains unknown whether they would like to use these repair kits instead of throwing them away when any of their products break. This research showed that Do-Fix kits had an encouraging effect on participants to repair their damaged products in the workshop environment. However, it cannot be said that they have the same effect outside the workshop setting. To account for these discussions future work is recommended to explore the consumer adoption of the Do-Fix kits. Further research can be conducted to explore the individual interest in these kits. Do-fix kits can be distributed to people who want to try them. Advertisements can be put on the websites such as callforparticipants.com, facebook or twitter to reach wider audiences. Repair parties could be a good opportunity to present these kits to people who are interested in repair activities. Then, data about the kits and how these participants make use of them can be collected to address the questions about enabling people to repair their damaged products in everyday context.
Additionally, further studies can be conducted by collaborating with businesses. Do-Fix kits can be produced to explore the adoption of these kits by people in the everyday environment. The kits can be provided to consumers in two ways. First, they can be sold or given to consumers by companies such as MUD jeans and Patagonia similar to the way spare parts are provided. In this case, kits can be adapted tailored to the company’s products. Second, they can be sold separately like a sewing kit or bicycle repair kit in shops. Besides testing the consumer adoption, further research might explore the consumer demand and the results of the use of kits in the home environment without the presence of experts or other people.

Chapter 7 : Conclusion

Original Contributions to Knowledge 
This research makes four original contributions to knowledge that presents value for researchers, users and design practice. 

Development of Do-Fix Kits 
The problematic relationship between users and products is a widely studied topic, as identified in the literature review (see Section 2.15). This research directly addresses this topic by developing a range of product repair kits that help encourage people to engage in repair activity to create a different relationship with products. A contribution to knowledge in design practice is offered by Do-Fix repair kits. These kits were developed based on the motivation and barriers that users experience in relation to repair, in order to motivate users towards repairing more products and empowering them to fix their products without the presence of an expert by making the repair process easier, thus decreasing the required skill level. This research is important for users in terms of helping them to understand the value of objects and the problematic relationship with products through the lens of repair activity. This research makes an original contribution to knowledge through ‘using already known material but with a new interpretation’ (Phillips & Pugh, 2010, p.63). Kintsugi and patching are not new methods, but they have been adapted in a new way, I provided an original design for each kit customised to the user’s needs and wants. Providing these methods as kits with required materials and instructions is an original contribution that removes barriers for users in order to encourage them to fix things. 
The Kintsugi kit transformed a labour-intensive traditional method into a practical one. I decided to include a pre-broken object for testing after considering the participants’ comments during workshops. This is a strategic design decision because people have a habit of throwing broken things away when they think it is impossible to repair, as they do not know how to repair it. Ceramic and glass products, in particular, lose their value after sustaining physical damage. However, the possibility of a user fixing a broken ceramic object might increase if s/he has access to the kintsugi kit. The second situation is that during workshops some participants wanted to test the kintsugi repair method on another product before repairing their own object, because they said that their object held value for them and they might have ruined it, as they thought they were not skilled or experienced enough to fix it properly. The test piece addresses both of these issues. Additionally, it adds an experiential dimension to the kit as it encourages the user to engage with the product through repair, and in end the product becomes complete with the user’s involvement.
3D-printed patches have an original design mainly based on the design considerations ‘interest in the method’, ‘personal pleasure/satisfaction’ and ‘aesthetic’ (see Section 4.3.2). The aim of creating this kit is to design a repair kit that attracts people’s attention in order to overcome the barriers and negative stigma attached to repair activity. 
A fabric patch is not an original idea. Various types of textile patches are available on the market. Textile patches, however, are designed out of necessity during the design studies and workshops as a result of repetitive damage to backpacks and shoes. 
The Plaster patches kit is an original design idea which is developed for users with low levels of skill inspired by the ease of putting on plasters. This kit provides quick and easy fixes for various types of fabric and damage. 
A diverse set of repair methods and examples were synthesised and organised during the design studies. These were then tested and further developed into repair kits. The value of this research for designers is that it helps them to understand the possible application of various repair methods and materials. For academics and researchers, the value is in implementation and exploration of practice-based research methods. 

Development of Design Considerations in Relation to Product Repair 
The literature review shows the lack of research into user motivation and barriers in relation to product repair and ways of encouraging people to repair damaged products. An original contribution to knowledge in design research is made in this research by ‘carrying out empirical work that has not done before’ (Phillips & Pugh, 2010, p.63) through the development of categories of motivation and barriers based on user experience of repair. The cultural probes method (Gaver, Dunne & Pacenti, 1999) was used in order to initially explore the motivation and barriers that users experience in relation to repair, and to inspire them to reflect and report their experiences and concerns about repaired and broken products. A range of motivation and barrier categories were developed in diverse contexts that suggest opportunities to understand and change user behaviour, through design, to reduce their environmental impact. These motivation and barrier categories were then developed further as design considerations through the design studies. Finally, the workshops helped to test the motivation and barrier categories and also to frame the process of product repair experience by enabling participants’ engagement with products. 
The second research question was answered by organising the data developed through three research studies into design considerations. Answering this question resulted in the original contribution to design research. The design considerations can be of value for design researchers as it can facilitate future attempts to ‘design for repair’, and they can serve as a baseline for future research in this area. Furthermore, this research serves as baseline research for future investigations in how to integrate repair into design processes and business models in order to extend product lifespan.

Reframing the Role of Designer in the Circular Economy and Contributions to the Design Practice 
Products are not designed and manufactured for the activities including repair, reuse, recycle and remanufacturing which enables us to restore and regenerate their value. Conversely, manufacturers use various strategies to intentionally make them obsolete. They produce with low-quality materials, permanently attach product parts with glueing or welding in order to decrease the production costs. Additionally, special and various types of screws are used in one product to make the disassembly harder. Most of the manufacturers do not provide spare parts. Finally, the repair knowledge is not available to users. In the context of this research, I am proposing that first the design of products should enable circularity: repair, reuse, remanufacture and recycle. Second, the information about circularity should be available to users. 
This research makes an original contribution to knowledge through ‘making a synthesis that hasn’t been made before’ (Phillips & Pugh, 2010, p.63) as I synthesised the existing knowledge and offered two different roles for designers based on this knowledge. 
Designing enabling products: Designing enabling products refers to designing products that are possible to repair, considering frequently broken product parts, and designing products suitable for self-production. Salvia and Cooper (2016) explains self-production as enabling users’ reusing, repairing, repurposing and appropriating products by themselves by considering their skill level, motivations and barriers. It is a common saying in sustainable design literature that designers should consider products’ after-use phase as well as the use phase. I want to repeat this saying and add that designers should also consider the breakage rather than ignoring it (Jackson, 2014). The breakdown is a part of the object’s life and Jackson (2014) describes it as ‘broken world thinking’ in his paper ‘Rethinking Repair’. 
Designing enabling solutions: Designing enabling solutions refers to accessibility and applicability of repair information for each product designed. Guiding users who want to repair their products through online tutorials, instructions, invitations is important to help them improve their confidence. Fairphone 2 can be given as an example of this approach. It invites the users to repair their phone with its transparent back cover, modular parts and the saying ‘Yours to open, yours to keep’ on the back cover. 
Reframing the Position of Repair in the Circular Economy and Contributions to the System Diagram 
It is suggested in Section 6.2 that Ellen MacArthur Foundation’s work on the circular economy mainly focuses on the economic aspects, ignoring the user’s role in the system. This approach can also be seen in the foundation’s system diagram. The diagram does not show the inner loops where the user directly creates value for the system. An original contribution to knowledge is made through ‘making a synthesis that hasn’t been made before’ (Phillips & Pugh, 2010, p.63) as I synthesised the existing knowledge and changed the system diagram based on this knowledge. The system diagram is adapted in a way that the active user’s integration to the system and responsibilities are represented, as well as his/her relationship to the other stakeholders in the system.

====================

VISUALISING CULTURAL DATA : EXPLORING DIGITAL COLLECTIONS THROUGH TIMELINE VISUALISATIONS by Florian Krautli

Abstract

This thesis explores the ability of data visualisation to enable knowledge discovery in digital collections. Its emphasis lies on time-based visualisations, such as timelines. 
Although timelines are among the earliest examples of graphical renderings of data, they are often used merely as devices for linear storytelling and not as tools for visual analysis. Investigating this type of visualisation reveals the particular challenges of digital timelines for scholarly research. In addition, the intersection between the key issues of time-wise visualisation and digital collections acts as a focal point. Departing from authored temporal descriptions in collections data, the research examines how curatorial decisions influence collections data and how these decisions may be made manifest in timeline visualisations. 
The thesis contributes a new understanding of the knowledge embedded in digital collections and provides practical and conceptual means for making this knowledge accessible and usable. The case is made that digital collections are not simply representations of physical archives. Digital collections record not only what is known about the content of an archive. Collections data contains traces of institutional decisions and curatorial biases, as well as data related to administrative procedures. Such ‘hidden data’ – information that has not been explicitly recorded, but is nevertheless present in the dataset – is crucial for drawing informed conclusions from digitised cultural collections and can be exposed through appropriately designed visualisation tools. 
The research takes a practice-led and collaborative approach, working closely with cultural institutions and their curators. Functional prototypes address issues of visualising large cultural datasets and the representation of uncertain and multiple temporal descriptions that are typically found in digital collections. 
The prototypes act as means towards an improved understanding of and a critical engagement with the time-wise visualisation of collections data. Two example implementations put the design principles that have emerged into practice and demonstrate how such tools may assist in knowledge discovery in cultural collections.
Calls for new visualisation tools that are suitable for the purposes of humanities research are widespread in the scholarly community. However, the present thesis shows that gaining new insights into digital collections does not only require technological advancement, but also an epistemological shift in working with digital collections. This shift is expressed in the kind of questions that curators have started seeking to answer through visualisation. Digitisation requires and affords new ways of interrogating collections that depart from putting the collected artefact and its creator at the centre of humanistic enquiry. Instead, digital collections need to be seen as artefacts themselves. Recognising this leads curators to address self-reflective research questions that seek to study the history of an institution and the influence that individuals have had on the holdings of a collection; questions that so far escaped their areas of research

Chapter 1 : Introduction

For the past three years I have been researching the use of interactive visualisations of cultural data, with a particular emphasis on mapping data against time. Visual timelines are among the earliest examples of graphical renderings of data, yet today they are often seen merely as a medium for linear storytelling rather than as tools for visual analysis – a purpose that is studied and advanced in the present thesis. 
Digital catalogues of collections form the starting point of my research. Cataloguing an archive, library or collection is done for a variety of reasons. On the most pragmatic level, a catalogue helps to keep track of where items in a collection may be physically located. In addition, it can hold information of what is considered to be known about an item, such as its origin, its age, its value, its dimensions, etc. All these descriptions make up the metadata: the data about the ‘actual’ data in the form of an item in a collection or archive, or a book in a library.
The increasing digitisation of collection catalogues has enabled them to contain far more (meta) data than their paper and card based equivalents. Digital catalogues have become digital collections in their own right and valuable resources for research, a development that cultural institutions are beginning to acknowledge. 
The present thesis is motivated by these developments and the inherent question of what kind of knowledge digital collections are able to contain and how new insights may be enabled by digital methods. It is based on two core propositions: the expectation that interactive data visualisations are able to serve as tools for knowledge discovery and the notion that the model of time provides a suitable frame of reference for sense-making regardless of the content and structure of the datasets that are to be studied. 
My research has involved engaging with the topic of timeline visualisations for digital collections on a practical, theoretical and social level: by writing code, designing functional prototypes and acquiring and refining the skills necessary for doing so; by immersing myself in the discourse around visualisation and the implications of digital tools on humanities scholarship; and by collaborating with curators and archivists from different institutions, negotiating the use of their datasets and getting their insights and feedback on the way I visualised their data. 
The research contributes practical approaches as well as a conceptual understanding of how we can design and use digital visualisation tools in the shape of visual timelines to extract new knowledge from existing digital collections, and presents new findings on the nature of such knowledge that encompasses their content and histories. I position my research within the framework of the Digital Humanities, a relatively young area that seeks to pursue and understand research at the intersection of digital technology, design and humanities. My research contributes to the ongoing challenge of developing and (re)defining digital methods for knowledge production in the humanities. 
My methodology is grounded in a practice based approach of iterative prototyping and critical reflection, where new knowledge emerges through the process of making and collaborating: what Frayling (1993) describes as research through art and design. It is informed by the challenges I have identified in the process, as well as by studying the relevant literature, participating in workshops and conferences, and conversations and collaborations with expert users. While initially I considered the potential beneficiaries of visualisations of digital collections to be the general public, my focus soon shifted to people within the institutions owning the collections: their curators, archivists and researchers. 
Despite the fact that they are experts in the subject matter, digitisation exposes them to new challenges. Visualisation, it turned out, enables these users to gain new perspectives on their own digital collections. In addition, their expertise allowed me to verify the efficacy of my visualisations – see if patterns that are visible in the visualisation align with their knowledge of the subject matter –, and find out what kind of discoveries they allow beyond what is already known by collaborating in the design process. These collaborations produced valuable insights in the research areas of the scholars and institutions I worked with, as well as on the potential of interdisciplinary research in the Digital Humanities. My research contributes a thorough understanding of the kinds of knowledge that is embedded in digital collections with regards to the cultural artefacts they represent and, most importantly, in relation to the embedded histories and biases of collections data that will become evident through the course of my research. I offer novel approaches to the visualisation of temporal data and suggest new ways for timeline visualisations to be used to access and analyse collections data with regards to their identified potential as resources for knowledge within and beyond traditional humanities scholarship.

Definitions
A glossary is included on page 339 to offer explanations and working definitions of some of the technical terms that appear in this thesis. Here I offer a brief description of essential and recurring concepts. 
Timeline 
A timeline is, in this context, a specific kind of data visualisation which visually represents data organised by a model of time – be it by calendrical dates, sequence, cycles or any other temporal structure. Many types of datasets may be visualised on a timeline, such as categorical and numerical, or structured and unstructured data. A timeline is different from a time series, which plots a regular series of measurements over time. In contrast to other diagram formats such as bar charts or histograms, timelines do not need to summarise events – although they can – and often represent events graphically as individual instances. Although the term ‘timeline’ may also be used to describe simple text-based lists of chronologically ordered events or the display of content on a social media website, I will refer to timelines mainly as time-centric visualisations and will sometimes use the term ‘chronographic’ to make the distinction between this and other concepts evident. 
Digital Collection 
I have worked with digital collections obtained from institutions I collaborated with, which are listed in appendix B on page 263. In addition, I obtained datasets from institutions that let the public download a copy of their collections data, such as the Museum of Modern Art and the Cooper Hewitt Design Museum. What constitutes a collection more broadly and a digital collection in particular will be discussed in more detail in chapter 2 (page 62). 
Curator 
I will use the term ‘curator’ to refer to a diverse group of experts with whom I collaborated. The title is not necessarily applicable to all of them, nor does it cover their area of work entirely. While some of the people do carry ‘curator’ in their professional roles and are responsible for putting together public exhibitions, others have different areas of responsibilities. The commonality of the people I collaborated with is that their profession involves accessing and curating cultural datasets; in the original Latin sense of the word ‘taking care of’.
Their comments and remarks, which I have transcribed from audio recordings of our meetings, are included in this thesis and distinguished as C1 to C12. For reasons of confidentiality and privacy, I have not included the complete transcripts of our conversations. Nevertheless, I have taken great care that the original context of the extracted quotes is retained.

Research Questions
The central question I seek to answer through my research is: What kind of knowledge can we gain from visually analysing digital collections through timeline visualisations? 
I aim to contribute to our understanding of how digital tools shape and enable humanities knowledge production, through their application as well as during their development. What kind of knowledge is embedded in digital collections, which timeline visualisations could provide access to? What can we learn by examining collections data in visual timelines? 
In order to address my main research question I need to answer a range of sub-questions: What is collections data? How does it relate to collections? What are the implications of digitisation in this context and in humanities research more broadly? What are the particular challenges around time based visualisations of large cultural collections? How can we approach them? What questions do those that use cultural collections want to ask? How do visualisations benefit them?

Thesis Structure
The present chapter continues with a description of the methodology and framework of my PhD, followed by an introduction of the individuals involved. The rest of the thesis is structured as follows: 
Chapter 2: Foundations I contextualise my research through a discussion of its field and the central concepts of my PhD. I offer a brief account of the history and promises of the Digital Humanities, as well as the criticism it faces. 
A historic perspective on visualisation emphasises the important role that timelines have played early-on in the development of data visualisation formats, both for the purpose of communicating and analysing data. Time acts as a unified framework for structuring and making sense of data – an ideal model for historic research on cultural collections. Time however poses its own challenges specifically with regards to digitally stored date descriptions that form part of collections data. Collections and the consequences of their digitisation are discussed. 
I present current views on the prevalent understanding of collections, including my own findings on the representation of time and objects in collections data that I have gathered by collaborating with museum experts. These conversations illustrate how collections increasingly cease to be understood as neutral sources of evidence; curators begin to show awareness for the subjectivities in collection practices. 
Embedded interpretations, I argue, must be considered as a fundamental aspect of digital collections in order for visualisation tools to not be misleading: a recurring critique of software for humanities research, but also one that diverts the responsibility to the tool. What is also necessary is that humanities researchers become more informed concerning the kind of questions that digital tools can and cannot answer. 
Chapter 3: Digital Timeline (Tools) 
In this chapter I review existing projects and software tools that implement timeline visualisations for analysing data. I employ a schema for classifying visualisation tools according to their supported level of interactivity. 
To ensure a rigorous analysis of this broad class of visualisations, I draft a set of criteria according to which I examine the presented projects. The criteria act as a kind of checklist in order to prevent me from taking familiar graphical representations for granted and instead question their underlying assumptions. 
In my review I look closer at established concepts and identify potential shortcomings with regards to the time-wise visualisation of digital collections. Current timeline visualisations tend to focus on the representation of individual events or sequences, making them unable to visualise large cultural datasets in an insightful manner. 
In addition, events are generally treated as occupying a singular and clearly defined point in time – an expectation which cultural data is unable to fulfil. Historic events often have a multiplicity of associated dates and these temporal descriptions are defined with varying degrees of certainty. 
Lastly, the readability of a timeline visualisation depends to a great extent on the graphical layout – nevertheless digital timelines often employ pragmatic layout algorithms that tend to hide patterns that may be present in a dataset. These focus issues form the starting point of my practice-led explorations. 

Chapter 4: Prototypes 
The fourth chapter discusses the progression of my research through iterative prototyping and evaluation. I discuss eight prototypes (P1–P8) with a focus on the insights they produced in order to enable the reader to retrace the progression and refinement of the outlined issues.
Beginning with innovations in the time-wise representation of cultural data based on mathematical concepts and model implementations, my process soon takes a turn closer to experimenting with existing datasets; the messiness of real-world datasets and the intricacy of humanities research cannot be simplified, but need to be addressed in all their complexity. 
The issues of timeline layouts and the representation of large datasets soon converge and I discover how both can be tackled by developing a timeline format that produces a representation of a complete dataset through an emergent behaviour operating on every individual record – which is different from existing approaches that either represent each event separately or summarise several events based on predefined thresholds. The issue of multiple and uncertain temporal descriptions in cultural data leads me to a conceptual shift in seeing them not as additional qualifiers, but as a defining property of cultural data which facilitates new perspectives and multiple viewpoints on an individual digital collection. 
Based on the defined focus issues, I formulate principles for the design of timeline visualisations for cultural data; these relate to distant reading, embedded uncertainties and multiple temporalities

Chapter 5: Paradigmatic Prototypes 
The proposed design principles derived from my prototype-led explorations manifest in two example implementations. This chapter describes their architecture, discusses their conceptual background and relevant aspects of their design, and puts them in context by comparing them with previous work in the field. 
Timeline Tools is a reusable visualisation library that facilitates exploration and visual analysis of arbitrary cultural datasets. It is specifically aimed at large datasets and has successfully been tested with collections that contain several hundred thousand records. 
Temporal Perspectives implements an algorithm that restructures cultural datasets according to multiple temporal dimensions and produces a timeline layout that enables researchers to study the temporal relationships within a cultural dataset. It is put into practice in a prototype that extracts and visualises the relationships of authors whose writings were used in compositions by Benjamin Britten. 

Chapter 6: Evaluation 
Finally, I return to my main research question: What kind of knowledge can we gain from visually analysing digital collections through timeline visualisations? 
This is answered, in one part, through an account of the specific insights that surfaced through the application of the presented visualisation tools. In addition to ofering an impression of a collection’s content, collections data – visualised according to the developed principles – reveals embedded characteristics of a collection: how its structure has developed, how embedded biases in cataloguing determine the shape of a collection and how the use and public understanding of a collection has changed over time. 
The second part of the answer is given through the voices of collaborating curators. Visualisation tools, paired with an improved knowledge of the implications of digital methods on their research practices enables them to ask new questions. These show a departure from ‘traditional’ research interests that concern aspects of cultural artefacts and the biographies of their creators – questions which would not necessarily require digital means to be answered. Instead, curators became interested in ‘meta-questions’ that explore the history of their institution as represented by data and how they and their predecessors shape and reshape the knowledge contained in collections.

Chapter 7 : Conclusion
The thesis concludes with a summary of my contributions to knowledge and puts the findings in perspective by pointing out the limitations of my research and follow-up questions. I reflect on the implications of an interdisciplinary research project for my PhD and Digital Humanities scholarship more broadly. Finally, I highlight some of the immediate outcomes that have so far resulted from the presented research.

Methodology
I address my research questions through a combined methodology of theoretical and practical research, whereby my main focus lies on the practice-based elements: the knowledge that I have acquired through my research and which is made explicit in this thesis is derived from a method of enquiry that depends on the design of digital prototypes. The order in which the methods are presented below is not a chronology of how the research was conducted; the different steps intertwine and informed each other, but are presented here, for clarity, as a sequential model. 
Beginning with a literature review I embed my questions and subsequent findings in the ongoing discourse of the field. Through a thorough study of current and historic research, and a review of existing timeline visualisation projects I am able to identify gaps that my work should address which I formulate as ‘focus issues’ that will later be developed and explored. 
By conducting interviews with curators, archivists and other representatives of cultural institutions I gather insights on the nature of digital collections and their embedded assumptions, specifically with regards to time and temporal descriptions. My findings contribute to a better understanding of the significance of collections data and will be vital for my further practical enquiries. Conversations with curators and archivists continued throughout my research process. These produced valuable insights leading to a deeper understanding of the role of digital data and visualisations for cultural institutions in general, and most importantly served as evaluation method for my prototypes. 
By making prototypes of timeline visualisations I am able to instantiate and test my ideas and hypotheses, and critically reflect on their implications. Making constitutes my main research method: the creation of an artefact, the interaction with it and its evaluation leads to discoveries, insights and new questions. Prototypes tackle one or several of the focus issues that I have identified and help to refine them through ongoing testing and evaluation. This practice based element is the main driving force of my research and I discuss its purpose below, along with my reasons for addressing my research questions through a design-led approach. 
Evaluation of the prototypes occurs through several ways. First of all through critical reflection on the process of making as well as while interacting with the prototypes. In instances where I have published work in progress on my blog or through conferences, peer critique serves as an additional mode of evaluation. Finally, I evaluate and test the prototypes together with their future users. Over time, my interaction with curators and archivists developed from consultation on matters of data access and collection specifications towards collaboration on the design and development of visualisations. The resulting discussions were critical for the evaluation of my prototypes. 
Evaluating the prototypes leads to insights on several levels. On a local scale, I can identify the potential and drawbacks of individual prototypes. Furthermore, evaluating allows me to reflect on what kind of practical insights may be scalable and transferable. Most importantly, the evaluation process enables me to develop an understanding of the kind of knowledge that is contained in digital collections and how it appears in time-wise visualisations. The knowledge gained through evaluation is made explicit in writing and feeds into later iterations of prototypes. By refining and redefining the goals and challenges, evaluation defines the approach and criteria for the next iteration of prototypes. 

Research Through Design 
My practical research method is based on iterative design of functional visualisation prototypes for digital cultural collections. Prototyping acts as a method to generate knowledge by making and reflecting on the creation process as well as through interaction with and evaluation of a created prototype. 
I work with publicly available datasets as well as data I have obtained directly from the institutions I collaborated with. Because my prototypes are based on existing cultural datasets, they reflect and expose the challenges of time-wise visualisation in real-world applications. 
A core element of my process is the constant evaluation of the created artefacts in the form of critical reflection and ongoing dialogues with museum curators and archivists, who are both experts and the future users of my visualisation tools. This is a form of Critical Making (Ratto 2011) which emphasises iterative and collaborative methods and uses the working process itself as the locus of evaluation, rather than employing a separately designed user study.
The starting point of every prototype iteration is a problem statement. It defines the specific focus issue the prototype should address and the proposed solution that is implemented by the prototype. Through the course of the research these are refined and reformulated. Design researchers have to regard the design brief as part of the problem, as was pointed out by Archer (1968). I present my point of departure – my own design brief as it were – and hypothesis at the beginning of the discussion of each prototype iteration, and specify the datasets the visualisation is based on or has been tested with.
The creation of a prototype and the subsequent interaction with it constitute the research by uncovering new insights and questions that emerge during development and evaluation of the prototype, as well as by providing evidence-based support or disproof for a hypothesis. Hereby, the practice-based elements are not disconnected from the theoretical foundations. Prototyping and making both inform and are informed by my theoretical enquiries. Making cannot be separated from the other methods of a practice based research project as it necessarily causes one to reconsider and reformulate issues, questions and problems, which may only have been revealed by the design process itself and newly discovered issues require a further engagement using all available methods. 

Why do I Conduct Research Through design? 
Design based research methods lend themselves to address a particular type of problems: the kind that Rittel and Webber called “wicked problems”: The problems that scientists and engineers have usually focused upon are mostly “tame” or “benign” ones. […] the mission is clear. It is clear, in turn, whether or not the problems have been solved. Wicked problems, in contrast, have neither of these clarifying traits […] (1973, p.160) 
Rittel and Webber refer to problems that can not be solved through analysis; the process of enumerating all possible solutions in order to pick the best one. Wicked problems exhibit incomplete and often unrecognisable characteristics, making them nearly impossible to solve completely. Designers address such problems not by analysing – the scientific method – but by making. 
There are numerous factors that may determine what a visualisation may reveal in cultural data, even without the additional and potentially arbitrary requirements mandated by a specific dataset and the individual expectations of a researcher. The problem at hand is a wicked problem, one where trying to make is more likely to lead to satisfactory results, or any results at all, than attempting to first comprehend the problem in its entirety. As Archer writes: There are circumstances where the best or only way to shed light on a proposition, a principle, a material, a process or a function is to attempt to construct something (1995, p.11). 
Attempting a solution in practice is, of course, no guarantee for success. In fact, it may even reveal more and previously unidentified problems. In practice-based research however, this does not constitute a failure. We can use these instances where a system breaks due to the complexity of the problem as a way of getting insights. Attempting to create a solution rather than drafting a complete analysis enables one to problematise what may not initially be identified as a problem, thus creating knowledge and uncovering new opportunities for research.
Practice-based research is not without its drawbacks. By making and acting on the real world, a design researcher influences and is influenced by the problem at hand (Schön 1983; Dorst 2003); he cannot simply position himself as a ‘neutral’ observer. Practice-based research is always to a certain degree subjective. It is therefore essential to compensate for a lack in objectivity by following a rigorous and transparent process and to strive to make the plans and decisions, as well as one’s beliefs, encounters and experiences that may have influenced them, explicit in writing or using another appropriate method of documentation. 
For the same reasons, practice-based research may not be completely reproducible. A person undertaking the same research, following the same questions based on the same materials, may nevertheless produce different artefacts and arrive at different conclusions. Again a thorough documentation is therefore necessary in order for a research process to be – if not exactly reproducible – at least comprehensible. The research outcome will then nevertheless be deducible and can be subjected to review and peer critique.

When does design Constitute Research? 
Design is the discipline which addresses problems through an act of making. The problems may be specific, such as the design of an exhibition in a particular space. They can be reproducible, such as the design for a mass-manufactured product. We speak of graphic or communication design, when the design problem applies to the optimal arrangement of type, shapes and images in a two dimensional space, or of vehicle or transportation design when the problem has to do with people or goods overcoming distances. 
Designing for these problems is informed by research, involves doing research and results in new knowledge for the people participating in the design process. Can we therefore argue that doing design inherently results in doing research? 
Design is interdependent on research, yet it is not equivalent. Where design seeks an acceptable solution for a particular problem within the given circumstances, research aims to arrive at communicable and generalisable ‘truths’: Design is a way to ask questions. Design Research, when it occurs through the practice of design itself, is a way to ask larger questions beyond the limited scope of a particular design problem. (Zimmerman 2003, p.176)
In order to determine when design constitutes research, we have to answer: […] was the practitioner activity an enquiry whose goal was knowledge? Was it systematically conducted? Were the data explicit? Was the record of the conduct of the activity ‘transparent’[…]? Were the data and the outcome validated in appropriate ways? (Archer 1995, p.10) 
If, and only if, the intention of doing design is to arrive at communicable knowledge and if the design process is undertaken transparently and rigorously, can we speak of research through design.

Framework
I undertake this research project in the framework of an industrial CASE studentship funded by the EPSRC in partnership with System Simulation, a central London software engineering company with decades of experience in database applications for the heritage sector. Their clients include a wide range of holders of cultural collections, such as the V&A, the British Museum and the Wellcome Trust. Part of the PhD included an industrial placement at their offices and supervision by Mike Stapleton. This provided me with access to their staff’s expertise and enabled me to collaborate with many of their clients. At the Royal College of Art I am enrolled in the Innovation Design Engineering department and supervised by Professor Stephen Boyd Davis. This constellation creates a unique triad for an interdisciplinary PhD in the Digital Humanities; covering the areas of humanities, design and computing equally.

Technical Methods
To develop functional prototype visualisations I made use of standard web-development tools. Languages such as JavaScript, HTML and CSS were used for the public-facing interfaces, server-based languages such as PHP for communicating with APIs of online collections. Most visualisations are based on D3.js, a widely used JavaScript library geared towards web-based interactive data visualisations.

Users, Experts, Collaborators
Hereby a brief introduction of the individuals involved in my research: first, there is the staff of System Simulation, a group of highly skilled software engineers. To them I turned to learn about the technical aspects of cultural datasets; the inner workings of the databases and the conceptual and computational strategies for dealing with the particularities of collections data and processes. I developed many of my visualisations inside their offices, which often made them some of the first to test and give feedback on prototype visualisations. Such informal tests on a small number of users are highly effective for identifying most of the common usability problems – researchers find that testing with more than four to five subjects does not lead to substantially better insights (Virzi 1990; Nielsen & Landauer 1993; Nielsen 2000). 
Then, there are the scholars and professionals working at museums, archives and other cultural organisations who I met over the course of my research. Seeking institutions willing to share their datasets for my visualisation projects, I was lucky to meet early on with Dr Lucy Walker, director of Learning at the Britten-Pears foundation. Having herself experimented with Microsoft Excel diagrams of the dataset she just finalised, she already had an idea of the potential of visualisations for cultural data and the possible questions they might be able to answer. 
Once I had my own prototype visualisations to offer, I could better communicate the purpose and potential of my research to curators unfamiliar with the topic and it became easier to encourage other scholars and museum professionals to share their data and expertise. Individuals with whom I collaborated include scholars, curators and technical staff from (in alphabetical order) Britten-Pears foundation (Aldeburgh), Courtauld Institute of Art (London), Gefrye Museum (London), ICA Philadelphia, King’s College (London), National Archives (Kew), National Library of Wales (Aberystwyth), London Transport Museum, Museum of Domestic Design and Architecture (London), Oxford Beazley Archives, Science Museum (London) and Tate (London). In addition, participating in conferences, workshops and a summer school on the topic of digital museum collections and visualisation allowed me to meet and discuss with representatives of a range of other institutions and gather feedback on my prototypes on an informal basis. Initially I approached institutions mainly seeking material to experiment with. Collections data and APIs were still few and far between when I began my research. Only recently have museums started to be more generous with their data. Meeting with curators in person, however, also gave me the opportunity to learn more about the history of their institution and the nature of their collection. Last but not least, I need to introduce the envisaged users of visualisation tools for cultural collections. But who are they? Existing work in visualising museum collections largely explores their benefits for the general public. Hinrichs et al. (2008) discuss the use of interactive information visualisation within the museum exhibition environment and consequently by museum visitors: a “diverse audience […] ranged from toddlers to elderly people” (ibid., p.1185). Hinrichs is a co-author of continuing studies on visualisations of digital collections in museums (Rogers et al. 2014) and libraries (Thudt et al. 2012), which evaluate interfaces with actual library users or simulated groups of typical museum visitors. Whitelaw (2009) who continuously studies and works on visual interfaces for cultural collections since 2009, assumes that “a user who is unfamiliar with the collection’s scope, contents, or structure” (ibid.) would benefit most from visualisations of archival collections; the main target group are “visitors unfamiliar with a collection” (Whitelaw 2012).

Users as Experts
In my own research I look at the topic from the opposite direction: regarding informed users, who are interested in scholarly analysis as the primary beneficiaries of visualisation tools of cultural collections, while assuming that also casual users will be able to take advantage of them. While visualisations can enable even uninformed viewers to observe patterns and make discoveries that, without the aid of diagrams, would require a great amount of desk research and expertise, it does not follow that visualisations of cultural collections have nothing to offer to those who are already familiar with the datasets. Existing work appears to suggest that the common search interfaces are sufficient for the normal tasks of expert users, while my interest is precisely in finding out what alternative perspectives on cultural datasets in the shape of time-centred visualisation tools may be able to offer even for advanced users. 
Focusing on scholarly use still constitutes a large target group. Museum visitors span a wide variety of individuals, but so do researchers who might be looking into a specific archive for very different reasons. Oxford’s Beazley Archive describes their main users as a “small, but loyal number of researchers” (C7) who turn to the collection as a substantial resource for studying ancient pottery. More and more scholars, however, are looking at this archive to learn more about the personal life of its founder Sir John Beazley and may arrive at the data with relatively little knowledge, or immediate interest, in classic archeology. It therefore makes sense, as Whitelaw does, to not presuppose that users of an archive are necessarily knowledgeable about its field, scope and content. However, in my own experience, we should also not underestimate the potential of visualisation to offer new insights even to expert users; those who have in-depth knowledge of a collection and are very able to also use conventional interfaces effectively.
Involving this type of user in my research allows me to identify the requirements and abilities of visual interfaces to reveal ‘genuine’ new knowledge: insights which an expert equipped with detailed understanding of an archive and its subject domain has not previously gained, discoveries that deepen existing knowledge, and new research questions which have been stimulated by using and examining a collection through a visualisation tool. In addition, collaborating with experts allows me to verify the discoveries which I and my users have made; to see if what we may read from a diagram or from interacting with a visualisation is effectively telling of the dataset itself and not just an artefact that resulted from the visualisation process. Expert knowledge provides a baseline for evaluating the honesty and ‘truthfulness’ of a visualisation tool. 
The type of users of my visualisation tools include therefore the very scholars, curators and archivists with whom I collaborate on the data-gathering, development and evaluation of the visualisation tools. This requires them to wear more than one hat; specialist and collaborator, and test subject. 
When meeting with these individuals, I steered our conversations so that the different roles – expert and test subject – of my counterpart stay, as far as possible, separated. First, we would talk about their subject domain, exchange views on the nature of digital collections and the potential of visualisations – these conversations contributed insights that informed the requirements of my visualisation tools and my understanding of humanities research more broadly. Then, I would prompt them with my visualisation prototypes and gather feedback and questions, while we jointly explore the datasets – this phase allowed me to collect evidence, to make and verify discoveries and to further evaluate my practical work. Both modes of conversation arrive at generalisable knowledge: questions and insights that are relevant within and outside the scope of a particular scholar or institution. The individuals with whom I collaborate are therefore not clients – I am not creating prototypes to meet their specific requirements – rather they are representative samples of the type of scholarly user my work seeks to address.

Chapter 2 : Foundations

Coming from a background in design and computer science, I initially saw my research at the intersection of these two disciplines: the field of human-computer interaction (HCI). HCI studies the relationship between digital technology and its users in order to make computerbased systems more efcient, more ergonomic and more rewarding to use. Soon it became apparent, however, that my research questions require a deeper engagement with the subject matter of archives and collections, their digital instantiations and the epistemological role of digital tools and visualisation. I found myself in the Digital Humanities, a field that describes the growing area of research in the humanities with and about digital technology, and builds on pioneering work that dates back to the 1940s (McCarty 1998). Digital Humanities is positioned at the intersection of humanities, computer science and – increasingly – design. I begin this chapter with a brief history of Digital Humanities along with a review of the prevalent criticisms it faces and the challenges it creates, to which my research responds. I then continue with a discussion of the fundamental concepts of my thesis: digital collections, time and visualisations of data. My review of collections consists of a look at their definitions according to the literature and the consequences and opportunities created at their coalescence with digital technology. Time is examined as an information-structuring model and we will see how representations of time have played an important role in the history of data visualisation. Next to a historic perspective, I will look at the specific claims of visualisation as tools for knowledge discovery. Finally, I complement the literature review with original research on the manifestations of time in digital collections and a brief study on the understanding of digital collections among the collaborating curators. The chapter provides the foundation of my research, ofering an overview of existing theory and an appraisal of the gaps in current knowledge and practices that my research aims to fill.

Digital Humanities
Humanities scholarship has adopted computational methods from the quantitative sciences to follow new research questions within its own field, but has also realised that available digital tools do not necessarily do justice to the nature of humanistic enquiry. In fact it seems necessary to consider the role of digital technology in humanistic knowledge production as a whole, to reconsider established concepts of data, interface and visualisation in a humanities context and subsequently to build new tools and methods for digital research in the humanities.
The Digital Humanities looks at the wider implications of the computational turn in humanities research. These include the introduction of computational methods to traditional humanities research, but also the contribution of humanities methods to computer science, the establishment of non-traditional forms of knowledge production and publishing as well as new synergies and collaborations between individuals and institutions. In this section I will outline the history and criticisms of Digital Humanities in order to provide the framework in which my research is positioned. 
Digital Humanities has fundamentally changed the work of many humanities scholars. Albeit, not primarily through the introduction of digital technology per se – any avid researcher will be well versed in the use of computers – but through a shift in humanities research from writing to making. As Lunenfeld et al. state: The advent of Digital Humanities implies a reinterpretation of the humanities as a generative enterprise: one in which students and faculty alike are making things […] (2012, p.10) 
The things that are being made by digital humanists – whether those things are visuals, software, objects or platforms – not only constitute their research output, but new modes of enquiry for the field of humanities. Design contributes to the Digital Humanities in two ways: most visibly in the form of interaction design by creating visualisation tools, employing best-practices of interface design and developing ways to graphically represent humanities data. More importantly however on a more fundamental level, through the application of practice based research methods to address questions and challenges in Digital Humanities scholarship. Design, as the discipline of making things, is able to contribute its knowledge and methods of practice based enquiries to the humanities, where digital methods have introduced scholars to new modes of artefact-based knowledge production.

Origins
Kirschenbaum (2012) identifies an event in 2001 as the birth date of the term ‘Digital Humanities’. Discussing the title of a reader which would be published three years later, John Unsworth suggested “A Companion to Digital Humanities” (Schreibman et al. 2004) as a reaction to the publisher’s proposition “Companion to Digitized Humanities” (Kirschenbaum 2012, p.3). In changing “digitized” to “digital” Unsworth wanted to shift the emphasis from mere digitisation of resources towards a wider scope of the area. Digital Humanities aims to divert the attention from the field of computing to the field of humanities. While the humanities have seen a number of pioneering projects using early digital technology, these endeavours have largely been considered as humanities research adopting methods from the computer sciences, a convergence that goes by the name of ‘humanities computing’. 
Roberto Busa (Figure 2.1) – an Italian Jesuit priest – is generally regarded as the father of humanities computing (McCarty 1998; Boonstra et al. 2004; Hockey 2004). As part of his doctoral research on the concept of ‘presence’ in the writings of Thomas Aquinas, Busa manually produced an index of 10,000 sentences by Aquinas containing the preposition ‘in’ (Busa 1980). He realised that his lexicographical enquiry could also serve as a basis for other scholars and started imagining an ‘Index Thomisticus’, which would contain a concordance of all the words of Thomas Aquinas. With the help of IBM and thirty years of work he completed an index containing 11 million lemmatised words, all stored on punchcards and ready for further computational analysis. Busa laid the foundation for a humanities scholarship that not only uses digital methods to contribute new knowledge, but at the same time makes these methods available for others. In fact, the endeavours in adopting computing technology in humanities research that followed throughout the 1960s (Hockey 2004) were primarily concerned with building databases and converting text-based material into digital formats (Lunenfeld et al. 2012) in order to make these resources accessible and usable with digital research methods.
Around the same time, the term Quantitative History was popularised to describe the growing adoption of statistical methods from the social sciences for research in history and, with them, the concepts of data and datasets : Quantitative history […] required a new set of skills and techniques for historians. Most importantly, they had to incorporate the concept of the data set and data matrix into their practice. (Anderson 2007, p.246f) 
While historians had incorporated quantitative evidence in their studies, the greater availability of computational processing in the form of mainframe computing offered new ways of looking at historical evidence. By aggregating a large number of events and using statistical analysis historians were able to look at long-term patterns and developments in events which, on their own, would be insignificant.

Distant Reading
The study of large-scale patterns across humanistic sources comprises the practice of “distant reading”. Franco Moretti introduced this term in an article proposing new ways to study world literature (Moretti 2000) – it has subsequently also been used to describe research practices in the wider scope of the field of humanities and is a continuation of earlier endeavours in the area of Quantitative History. 
Distant reading is the process of using computational methods to answer narrowly defined questions across a large body of works. In distant reading, Moretti writes, distance […] is a condition of knowledge: it allows you to focus on units that are much smaller or much larger than the text: devices, themes, tropes—or genres and systems. (2000, p.57) 
Digital technology enables the processing of much larger bodies of works through distant reading, in opposition to close reading; studying a small sample of works or even a single work in detail. Close reading expects a more thorough engagement with limited source material – but focussing on a small number of works is not necessarily done by choice. Moretti’s argument builds around the dichotomy between claiming to be studying World literature, when in fact what is being studied is only ever a tiny sample of existing literature due to limits in human interpretive capacities. Merely by selecting which works to study, a researcher inherently discards an enormous body of work without ever having looked at it. 
In contrast, distant reading allows an individual researcher to consider an archive in its entirety: By confronting scale, “distant reading” […] – or, in our case, “distant listening” – reveals structures, patterns, and trends that are not discernable when the focus remains on just a handful of close readings of individual texts. […] Distant listening facilitates whole corpus analysis and, potentially, the democratization of knowledge. Instead of privileging “human listening” (in which we necessarily have to limit ourselves to a tiny canon of works, probably a few hundred), distant listening is performed by a computer and can easily “listen to” thousands, if not millions, of works. (Presner 2015, p.23) 
Digital technology enables distant reading but in some respects the digital also demands it. Human researchers can make an informed guess as to what will be studied and what not. The fundamental principle of an algorithm by which a computer has to operate, is a set of step-by-step instructions that require each step to be executable independent of the entire process; therefore an algorithm cannot consider a set of sources as a whole, but needs to examine each one individually and often exhaustively.
Moretti did not expect his idea “to be particularly popular” (Moretti 2000) and opposition soon followed (Trumpener 2009; Culler 2010; Marche 2012). Humanistic knowledge production should not be systematised, Trumpener argues: We are, first and foremost, highly trained readers […] the unsystematic nature of our discipline is actually its salvation. (2009, p.171)
Endeavours in systematising humanistic enquiry are however not a recent phenomenon – see Boyd Davis (2016a) for an account of eighteenth century attitudes to mechanical knowledge production. The criticisms around close reading also echoed earlier concerns about the advent of Quantitative History. As Anderson writes ‘traditional’ historians expressed doubts about the new methods, challenging them as reductionist, brittle and not pertinent to the main goal of the historical narrative (Anderson 2007, p.257) 
With the main modes of accessing collections turning digital and a growing use in born-digital collections – such as archives of Tweets – historians are increasingly forced to use distant reading: As historians, we will need to reorient our approach to studying the past so that it does not involve reading every one of those thirtyone million lines of text. (Sternfeld 2014) However, distant reading is only useful if it also reveals novel insights. Distant reading entails not only processing large amounts of data to ask humanities questions, but to do so in a useful manner: The sheer size and scope of today’s digital sources demand a level of methodological rigor that we are not yet accustomed to applying. (Sternfeld 2014) 
Google’s NGram Viewer, for example, is an interface for distant reading that comes close to studying ‘all’ of World Literature in the way that Moretti envisaged. It is based on a corpus of literary sources printed between 1500 and 2008 and contains, for every year, an indexed count of n-grams.It enables users to trace – through graphical line plots over a horizontal dimension of time – the appearance of certain words and word combinations in the literature. However, the tool allows few insights into the cause of an apparent change in the use of certain words. NGram Viewer is a tool for distant reading, but largely fails in enabling humanistic enquiry into the history of the sources it represents. Sternberg continues to argue that big data visualizations […] wipe away any remnant of historical causality (2014) 
a statement which certainly applies to Google NGram’s line charts whose basis remains largely inaccessible. However, I argue, the existence of simplistic examples of implementations does not rule out the usefulness of distant reading, especially when it is combined with and in support of traditional methods of close reading. As Gibbs writes: Any robust digital research methodology must allow the scholar to move easily between distant and close reading, between the bird’s eye view and the ground level of the texts themselves. […] Historical trends – or anomalies – might be revealed by data, but they need to be investigated in detail in order to avoid conclusions that rest on superficial evidence. (2011, p.76) 
Distant reading must not replace, but can accompany close reading and if implemented in the manner that Gibbs describes, it can enable novel insights into digital collections whose size and structure requires the consideration and development of methods for distant reading.

Criticism
Many historians are critical of the methods inherited from the quantitative sciences and fear a discrediting of traditional humanities research. 
In the context of the Digital Humanities it is the, arguably blind (Swierenga 1974; J. Drucker 2011b), application of digital methods which is most susceptible to criticism. Historians especially faced the limitations of of-the shelf database software, which since their early days sufered from a range of challenges related to dates and the modelling of fuzzy data that immediately became apparent in historical research: The most obvious limitation that historians encounter [...] is the date function, since most programs cannot interpret or query nineteenth-century or earlier dates and a nest of problems in date functionality accompany any attempt to use historical dating in these programs. (Thomas 2004, p.60). 
Current software packages might have mostly done away with the problem of pre-twentieth century dates. Still, software is often seen as unfit for scholarly research (Borgman 2009). The problem of representing historic dates is not solved by simply extending the available timeframe. Dating historical events is a complex endeavour which may include conflicting evidence, missing data or varying degrees of certainty. Furthermore, the problem of digitally representing complex, fuzzy and uncertain information applies to all kind of data in the humanities. In order for digital tools to be usable for humanistic research, they have to be able to computationally model such data and, in addition, offer bespoke interfaces to query datasets and answer the kind of questions humanities researchers want to ask. According to Borgman (2009) it is the responsibility of humanities scholars to lead the development of new tools in line with the challenges and requirements of humanistic enquiry. 
With the advances in graphical user interfaces and improved usability, it has become even easier for humanists to adopt existing software originally designed for engineers, statisticians or business analysts for their own purposes. However, Drucker argues that these sophisticated interfaces tend to hide software’s underlying assumptions, which stem from outside the humanities discipline: Such graphical tools are a kind of intellectual Trojan horse. (2011b, §1)
The limitations of available software tools for humanities research have been pointed out since the 1980s (Winchester 1980), but early efforts in developing database tools specifically for humanities computing (Thaller 1987) found little adoption. Therefore, many of the available software tools and datasets still suffer from limitations related to fuzzy, uncertain or incomplete data and the handling of time and temporal information.
In addition to the challenges posed by software implementations, the Digital Humanities have inherited many of the criticisms already raised about Quantitative History with regards to the conceptual shift to a numeric, mechanistic knowledge production that is feared to replace traditional, interpretative humanistic scholarship. 
Carl Bridenbaugh, then president of the American Historical Association warned historians against “worship[ing] at the shrine of that Bitch-goddess, QUANTIFICATION” (Bridenbaugh 1963). The worry, shared by many historians, was that quantitative methods “may dehumanize history because of the emphasis on collectivities instead of individuals” (Swierenga 1974, p.1064). Few, on the other hand, were as dismissive to quantitative methods in history as Arthur Schlesinger, Jr., who announced that “almost all important questions are important precisely because they are not susceptible to quantitative answers” (Kousser 1980, p.434). 
Bridenbaugh’s “Bitch-goddess” has become somewhat of a dictum to illustrate the aversion of historians and other humanists towards numerical methods (Bogue 1983; Thomas 2004; Anderson 2007), although many historians were not completely opposed to these quantitative, and later digital, methods. Including Bridenbaugh himself, whose main concern was a disconnection of future historians from their craft and their subjects of study. His worry was not directed at quantitative methods per se, but at the danger of them being seen as a replacement, rather than an addition to qualitative methods. 
Similar concerns are still raised about the Digital Humanities and digital collections in particular. It is suspected that digital methods may be seen as a replacement, rather than an addition to traditional humanities scholarship. Schüler-Springorum observes a decline in student’s readiness to engage deeply with an archive on location as more and more collections are being digitised and made available online: “a specific intellectual space will get lost by providing online access to historical documents” (2015). 
Museums have indeed been concerned that they will make themselves and their physical presences obsolete by providing improved online access to their collections (Lejeune 2009). So far museums have seen their visitor numbers increasing after collections were made available online (Goldman & Wadman 2002; Thomas & Carey 2005; Thomas & Crossman 2006), but the studies allow for little insights about the change in numbers based on the purpose of the visits. It might well be that the numbers of casual visitors have gone up, while digital collections may have reduced the need for scholars to visit a collection in person. Oxford’s Beazley Archive, for example, experienced fewer visits after the complete catalogue was put online (C7). The Museum of Domestic Design and Architecture (MoDA) at Middlesex University, in contrast, observed an increase in usage of collection artefacts that previously saw little use, as a result of their collection being digitally accessible. A perceived competition between physical and digital collections stems from them being often seen as equivalent, rather than complementary. The digital is feared to replace the physical. To shed light on this apparent concurrence, I will take a closer look at how collections are generally perceived and defined in a later section. 
In the case of existing digital collections, the growing calls for more sophisticated methods of modelling humanities data may have come too late; these datasets necessarily have been created with and suffer from the limitations of available software. The question is: is it possible – to some degree – to reverse-engineer the complexity of the ‘original’ humanistic data, the “thick description” (Geertz 1973) that is likely to be only insufficiently represented in a collections dataset?

Visualization
Digital Humanities is a remarkably visual form of research. In contrast to traditional humanities research, visual materials act not merely as illustrative companions to written output, but visuals constitute the actual research output. Lunenfeld et. al see this development rooted in societal changes: Digital Humanities necessarily partakes in and contributes to the “screen culture” of the 21st century [...]. What this means is that the visual becomes ever more fundamental to the Digital Humanities, in ways that complement, enhance, and sometimes are in tension with the textual. (2012, p.12) 
However, the proliferation of screens is one that affects all aspects of academic, professional and social life. The visual enters the Digital Humanities, in my view, through the adoption of concepts of data and datasets and consequently the practice of data visualisation. 
In this thesis I will focus on the method of analysing data through visualisation. Visualisation refers to the use of graphical elements to encode data: data visualisation. Essentially it describes a mapping from the input space of data to a graphical output space: ordinal, quantitative or categorical data attributes control the shape, size, colour, area and other visual properties of graphical elements.
The development and study of visualisations that serve the purposes of data analysis, knowledge discovery and communication generally falls in the field of Information Visualisation (Gershon & Eick 1997; Card et al. 1999; Bederson & Shneiderman 2003; Ware 2004; Kerren et al. 2008). Data Visualisation is often seen as an equivalent term (Card et al. 1999; Bederson & Shneiderman 2003; Kosara 2013; Bailey & Pregill 2014) and sometimes treated as a sub-discipline of Information Visualisation (Friendly 2009). 8 Occasionally, Information Visualisation and Data visualisation are described as separate, but related fields (Gershon & Eick 1997).
When data visualisation is treated as a specialisation within information visualisation, it is generally paired with scientific visualisation (Friendly 2009) – for example 3D visualisations of natural phenomena – and Infographics (Kosara 2010; Gelman & Unwin 2013) – explanatory visualisations accompanied by illustrations. Infographics are often contrasted with data visualisations and the benefits of each, as well as the value of diferentiating at all, provide ample food for theorisation (Few 2011; Cairo 2012; Kosara 2013; Wickham 2013). For some (Gelman & Unwin 2013), all data visualisations that depart from traditional statistical charts count as infographics, along with their negative connotations. For others (Kosara 2010; Wickham 2013) – including myself – the difference between data visualisations and infographics lies not in their adherence to written or unwritten rules of information visualisations, but in their ability to generalise and – consequently – to be generated. Visualization is (largely) automatic, infographics are hand-crafted. Neither are objective, and both require hand-tuning and understanding to get right. (Kosara 2010) 
The automatic view on visualisation envisages digitally generated diagrams, which are also the focus of this thesis. However, the next section will introduce historic examples of hand-crafted visualisations, which have, to an extent, been produced mechanically, an aspect that also constitutes their main innovation.

History of (Time-Wise) Visualization
Graphical representations of – what we now would call – data are scattered throughout history, too numerous to pay them the attention here they deserve. By the end of the 18th century, data visualisation – in the strict sense of generalisable and mechanically achievable charts – became mainstream through the publishing of William Playfair’s (1759-1823) Commercial and Political Atlas in 1786 (Playfair 2005). Geographical atlases were already available at that time and had been since the 16th century, but Playfair’s book was not mapping land, it was mapping economic data.
To do so, Playfair invented the line chart (Figure 2.3) as well as the bar chart (Figure 2.4), although he credits a fellow Englishman for providing the inspiration for the latter (Wainer 2014). The bar chart actually originated from a compromise – Playfair lacked sufcient data to draw a continuous line (Wainer 2005). Line charts were also not completely novel; Christiaan Huygens’ (1629-1695) mortality chart is regarded as the earliest example (Wainer 2005). Huygens’ graph however depicts a mathematical function. Playfair’s graphs on the other hand are graphical mappings from empirical data and hence ‘true’ data visualisations. 
His book did not initially find a publisher in England, so Playfair tried his luck in France. When he sent a copy to Louis XVI in 1781, the king had never seen such diagrams, yet Playfair notes he at once understood the charts and was highly pleased. He said they spoke all languages and were very clear and easily understood. (Wainer 2014).
Others soon shared the king’s insight. Playfair’s Atlas was published, became known and his charts continue to be widely adapted. 
The Englishman who was Playfair’s inspiration for the bar chart is Joseph Priestley (1733-1804), remembered more for his discovery of oxygen than for his pioneering work on visualisations. Playfair was referring to Priestley’s Chart of Biography (1764, Figure 2.5), one of the first visual timelines published in 1764 and graphing the lives of about two thousand important individuals.12 Priestley drew lines of different lengths, representing the individual lifetimes of those he mapped, an innovation at that time (Boyd Davis 2011) which Playfair adopted by expressing quantities as lengths of bars. 
The history of data visualisation is, to a great extent, also a history of time-wise visualisations. Playfair’s charts visualised economical data on a (horizontal) dimension of time and drawn diagrams that visualise the movement of celestial bodies through space and time were used as early as the 10th century (Friendly 2006). Rosenberg and Grafton (2010) offer a comprehensive and richly illustrated history of timeline visualisations; here I will only focus on some key examples to which I will return later on in this thesis. 
I have already mentioned Priestley’s Chart of Biography as Playfair’s inspiration. At the same time, it is one of the first true arithmetic timelines that graphically maps data according to a linear time axis, which runs horizontally and is divided equally into centuries. The principle of using equal units of space to represent equal number of years was introduced only eleven years prior to Priestley’s chart.
Jacques Barbeau-Dubourg (1709-1779) produced a Carte Chronographique (Figure 2.6) of the “main events of every century, since the Creation of the world up until the present” (Barbeau-Dubourg 1753), a timeframe that covered 16.5 metres of paper, each year a quarter of a centimetre wide. On it the names of notable individuals as well as summaries of important events are positioned horizontally according to their time and grouped vertically by their country of origin. A category with unassignable or general events is positioned at the bottom of the chart and labelled “memorable events” (“événements mémorables”) (Barbeau-Dubourg 1753).
Barbeau-Dubourg’s and Priestley’s visualisations represent a significant step towards abstract visual representations of data. Earlier chronologies adhered to a text-based tabular layout while other examples of early timelines, such as the work of Girolamo Martignoni (died ca. 1743, see Boyd Davis 2016b), borrowed their visual language from geographic maps (Figure 2.9). A piece by Jean-Louis Barbeau de la Bruyère (1710-1781) appears like a cross-over between a tabular layout and a geographic map. Through his Mappe-Monde Historique (Barbeau de la Bruyère 1750a, Figure 2.7) he intended to offer a complete view of the history and geography of the known world.15 The Mappe-Monde borrows from a tabular layout, with geographical divisions marked at the head of the chart, forming a column for each country,16 with empires that extend across several columns set in colour. 
The ability of Priestley and Barbeau-Dubourg to graphically map data according to a coordinate system required a conceptual shift in the understanding of space and data that was offered by Descartes (1596-1650) through his proposition that anything that can be expressed in number can be represented graphically (1641/1996).
Another fundamental innovation for the development of arithmetical timelines was the advancement of a numerical model of time famously promoted by Isaac Newton (1642 – 1726/7). Newton considered time to be an absolute, uniform frame of reference where events could be ‘located’ independent of other events or external perceivers. Time, according to Newton, is “absolute, true, and mathematical” (Newton, 1687), a fundamental quantity like length or mass, which can be measured and expressed in a manner that may be universally agreed upon. While Priestley was not the first to draft a true arithmetic timeline, he was original in graphically representing duration as a line: THUS the abstract idea of TIME, though it be not the object of any of our senses, and no image can properly be made of it, yet because it has a relation to quantity, and we can say a greater or less space of time, it admits of a natural and easy representation in our minds by the idea of a measurable space, and particularly that of a LINE; which, like time, may be extended in length, without giving any idea of breadth or thickness. (Priestley 1764, p.6) 
It is worth noting, however, that the understanding of time as a quantity along with the affordance of quantities to be represented as space that Priestley describes, are a result of the conceptual shift in thinking advanced by Newton and Descartes; the “natural and easy” representation required a significant intellectual effort and decades of familiarisation. 
In the literature, arguments for the merits of particular graphical representation that rest on the assumption of one being more “natural” than the other are widespread; we will see more examples later on and the claimed ‘naturalness’ is rarely free of previously established and unconsciously acquired paradigms.
Priestley’s decision to map duration to length is one such innovation that stood the test of time; his graphic taxonomy is embedded in many modern visual timelines. While the effectiveness of the line was widely recognised, its problems that Priestley identified as well have found far less consideration later on. A line has a clear beginning and ending; historical dates however often do not. Having spotted the inconsistency, Priestley offered a solution (Figure 2.8): In this case the compiler must content himself with placing his line as near as he can conjecture from history where his true place was, leaving marks to express the uncertainty there is attending it. The method I have used in this chart is to express certainty by a full line, and what is uncertain by dots or a broken line […] (1764, p.11) 
Priestley, Barbeau-Dubourg and de la Bruyère each complemented their visualisations with detailed descriptions of the rationale for their design decisions, knowledge they acquired while making their charts as well as the insights they gained from inspecting them (Barbeau de la Bruyère 1750a; Barbeau-Dubourg 1753; Priestley 1764). One could see these pioneering works as a form of Critical Making (Ratto 2011), as their makers not only had to design new graphical formats, they had to develop a new visual rhetoric and, most importantly, explain and reflect on their ideas, processes, and rationales. 
Today, it is rare for designers to have to defend and justify their decisions in relation to visual representations of time, which is maybe why timelines are generally regarded as simple, even as “a bit of banal tedium” (Behrendt 2011). This brief look at their history however demonstrates that they can be, and have been, much more than that; effective tools for visual analysis, or in the words of Joseph Priestley: What words would do but very imperfectly, and in a long time, this method effects in the compleatest [sic] manner possible, and almost at a single glance […] (1764, p.9).
 
Visualisation for Sense-Making
Priestley’s quote that concludes the previous section leads me to address the question of what purposes visualisation serves. In the booklet that accompanies his chart, he dedicates his work “to the youth [...]; showing them what names will most frequently attract their attention, and how they stand related in point of time to one another” (Priestley 1764, p.5), underlining its educational qualities. Yet he also states that only through the use of visualisation, he was able to “see [...] the relation of these lives to one another in any period” (Priestley 1764, p.10), suggesting that he drafted the visualisation in order to understand for himself. These observations relate to DeFanti et al. (1989) who describe visualisations as either “a tool for communication and teaching” or “a tool for discovery and understanding”. Similar discriminations appear throughout the visualisation literature. My emphasis is on the second category of analytical visualisation, although there is often a wide area of overlap.
Few (2013) separates visualisations for the purpose of sense-making from visualisations for communication, while Kosara (2007) identifies “very technical, analysis-oriented work on the one, and artistic pieces on the other hand”. Tufte (2001) even coined the term “chartjunk” to describe elements of a visualisation which, according to him, may be justified as artistic additions, but are in his view purely decorative and unnecessary, even counterproductive for the readability of a visualisation (see Figure 2.10). Tufte’s radical dismissal of rhetorical elements in visualisations is debated however and experimental investigations found that so-called chartjunk may in fact be helpful for the reading of a visualisation (Craft & Cairns 2005; Inbar et al. 2007; Bateman et al. 2010; Hullman et al. 2011; Moere et al. 2012; Borkin et al. 2013). 
While there is largely an agreement that visualisations can enable understanding, how they might do so is still not fully understood. A reoccurring claim is that by visualising data, instead of for example displaying it in a table, one can take advantage of the human visual system’s abilities to recognise patterns immediately (McCormick et al. 1987; Gershon & Eick 1997; Van Dam et al. 2000; Ware 2004). In situations where large amounts of measurements are visualised in scatter plots, this explanation sounds reasonable. But there is more to visualisation than just seeing patterns. A different process is at play when, for example, two numbers are represented as lines of different lengths or quantities are encoded by colour ranges.
We may take for granted that visuals can enable understanding – we say “I see” to mean “I understand” – and to suggest that visualisation may be beneficial for our understanding of large datasets and complex issues is not a daring statement. During the first half of the twentieth century the credo was different. Arnheim, in his seminal work on visual thinking, quotes Karl Bühler’s (1879-1963) writing – “In principle, any subject can be thought and meant completely and distinctly without any help of imagery” (Arnheim 1969, p.100) – and the American psychologist Robert Woodworth (1869-1962), who goes as far as stating “the more efective the thinking process is at any moment, the more likely is imageless thought to be detected” (Arnheim 1969, p.100). In this context, it is no surprise that Arnheim sees his own theory – to suggest that the process of thinking is very close to seeing – as “an obvious contradiction. How can there be intelligence in perception?” (1969, p.13). 
Bertin argues in a functional way for the advantages of graphics over other forms of representation (1967/2010). He contrasts the visual system in the form of graphics to the auditory. The auditory also includes written transcriptions of language, music or mathematic as they are, in his view, merely ways of capturing what is essentially auditory. Graphical notation uses the two dimensional spatial plane while auditory systems operate in one dimensional time. This argument has to be used cautiously however, as an increase in dimensionality does not necessarily make a visualisation more understandable. In fact the usefulness of visualisation in a lot of scientific contexts stems from reducing high dimensional datasets in two- or three-dimensional projections. 
Bertin argues for the efficiency of visualisations: If, in order to obtain a correct and complete answer to a given question, all other things being equal, one construction requires a shorter period of perception than another construction, we can say that it is more efficient for this question (1967/2010, p.9) 
In his line of reason, a tabular representation, for example, would allow the same insights as a plot of the data, just with differences in speed. Is visualisation then a short-cut, but not a unique path to understanding? Larkin and Simon (1987) ofer evidential support for this hypothesis. Farquhar and Farquhar on the other hand are convinced that some conclusions can only be drawn from a graphical representation: The graphical method has considerable superiority for the exposition of statistical facts over the tabular. […] the popular mind is as incapable of drawing any useful lessons from [the tabular method] as of extracting sunbeams from cucumbers (1891, p.55). 
For Don Norman, “the power of the unaided mind is highly overrated” (1993). He introduces the concept of “cognitive artefacts” (Norman 1991) that enhance human abilities: like a megaphone amplifies voice, pen and paper can ‘amplify’ thought. Visualisations, too, are a type of cognitive artefact. 
Norman gives the example of a visual mapping of values to the sizes of graphical elements as a “superior form of representation” (1991) to arabic numerals. According to Norman, the superiority of the visualisation, in this case, stems from the ‘natural’ relationship between the “perceptual representation” (ibid.) of the visualisation to the numerical values: The “naturalness” of a mapping is related to the directness of the mapping, where directness can be measured by the complexity of the relationship between representation and value (Norman 1991, p.28) 
The problem with this line of reasoning is that it rests on the intuition of what one perceives as ‘natural’, even though Norman tries to circumvent this issue by suggesting that one is able to objectively measure how closely related a value and its representation is. Even if we could, according to Scaife and Rogers we cannot simply assume a privileged relationship between a graphical representation of a system […] and someone’s understanding or ability to reason about it. (1996, p.201) 
Scaife and Rogers explored and tested how diagrams permit “computational offloading” (1996, p.188); similar to Norman’s concept of cognitive artefacts, visualisations afford “external cognition” (Scaife & Rogers 1996) by relieving users from having to picture information mentally and instead allow them to focus on studying information by interacting with a visual artefact. While Scaife and Rogers, following a thorough review of existing literature, conclude that little is known still on why visualisations work, they do observe that interacting with a visualisation – be it through manipulating a digital representation or through pen and paper – benefits users’ understanding significantly. 
The, admittedly, unspectacular conclusion is that despite the wide range of possible theories and speculations, we do not know for certain why and how visualisations benefit understanding. Largely, I argue, because we also know very little still about the process of understanding itself.
The functionalist view of the mind argues that cognition is independent of the world and in principle realisable by a computer (Block 1980; Fodor 1987; Putnam 1988). This was the dominant philosophy of mind throughout the 1980s, when digital data visualisation was on the rise and its ability to assist in understanding was first theorised (Card et al. 1999). 
Functionalist explanations of how visualisations enable understanding focus on the idea of the mind as a “pattern-seeking machine” (Popova 2013) that operates on internal representations. Therefore, they have to argue for a qualitative diference in the internal processing of visualisations as opposed to other representations of data, for example by “exploiting people’s natural strengths in rapid visual pattern recognition” (Gershon & Eick 1997). As I have argued, claiming an advantage based on ‘natural’ human abilities can be problematic. More recently, an ‘embodied’ theory of mind is emerging which argues that consciousness arises from interacting with the world (Varela et al. 1992; O’Regan & Noë 2001; Noë 2004). Understanding stems not from operating on internal representations, but from acting and interacting with the world. 
Both the concepts of “external cognition” (Scaife & Rogers 1996) and “cognitive artefacts” (Norman 1991), and the improved understanding that arises from interacting with and manipulating a diagram that Scaife and Rogers observed, gives support to the embodied theory of mind and provides an explanation of how visualisations might support sense-making: not by offering universal functional advantage over other forms of representations, but by serving as tools that can be manipulated, both manually as well as by observation, and aid and extend our inherent and acquired means for cognition.

Collections
When I refer to collections within this thesis, I envisage the holdings of museums, archives, libraries, galleries, universities and cultural institutions more broadly, as well as the specific collections of the institutions I worked with. To define a collection is however far from straightforward, even with this pragmatic concept, which leaves the definition of a collection to the institution that owns it; the internal criteria of what comprises an institution’s collection may vary considerably over time: This system […] [contains] everything that’s catalogued, but not necessarily in the main collection. So for example this [artefact] is not considered – at the moment – a part of the collection. (C10) 
Archives and collections are diverse and dynamic – despite the common image of them being a static conservation of the past – and as a result there is not a unanimous definition of collections in the literature. 
Lee (2005) studies the concept of library collections from the perspective of its users. Most of the findings translate to collections in general; given that libraries increasingly contain and catalogue a variety of items and media, it ceases to make sense to hold up a strict discrimination between libraries on one hand and collections and archives on the other. Digitisation further blurs the boundaries, as Curall et al. point out: “the digital world in some senses equates to a library in that items enjoy an independence that is analogous to a book” (2005).
Lee finds that “as an entity, the library collection seemed to be extremely vague in the users’ minds” (Lee 2005, p.71). Some participants of the study equated it with certain physical items housed in a building (see Figure 2.11). Especially in the example of libraries and museums, the strong association between an institution’s collection and its physical building may strengthen this view – even though many museums and libraries store their collections in various of-site locations. And of course, the multiplicity of types of items in a collection – be they objects, files, references or concepts – may require various storage ‘locations’: physical, virtual, juridical, etc.
Despite users’ apparent difficulty to formulate what a collection is, most of them could easily describe what they expect from it. Key factors include selectivity – the fact that a collection is curated – but also flexibility – that a collection can be shaped to one’s needs. Finally, a collection is required to be “readily available”: if something were not readily available, it could not be considered part of the collection (Lee 2005, p.72) 
Currall et al. (2005) assembled a comprehensive review of institutional definitions of collections. For example, the description by JISC IE that states “a collection is any discrete aggregation of one or more items of content, but will often take the form of a database of one kind or another”. Slightly more useful is the definition in the Canadian Rules for Archival Description, despite its restriction on one specific type of collected item: An artificial accumulation of documents of any provenance brought together on the basis of some common characteristic, e.g. way of acquisition, subject, language, medium, type of document, name of collector, which may be treated for descriptive purposes as a unit under a common title.
The view of the authors is that collections can not be unambiguously defined as they are always a product of the people that maintain, produce and govern them: Our position is simply this: it is human beings, with their language and intentions, who determine the categories and, thus, the collections into which things are placed. (Currall et al. 2005, p.135) 
Curall et al. criticise that the people responsible for the collections are often oblivious of this: Although curators are aware that objects within their collection or collections have been selected for inclusion, it rarely occurs to them that the process of selection is both dynamic and constructed. (Currall et al. 2005, p.139) 
My own research however could not fully confirm this observation. Many curators and archivists I talked to were conscious of the subjective role they and their institution are playing in shaping a collection. However, often it was suspicious patterns in my visualisations – visual evidence of the influence of individuals on the collection – that steered our conversation to address the subjective biases they and their institution impose on a collection. These findings will be discussed later on.
Considerations of a curator’s influence on collections have not found wide adoption in specialised scholarly literature, ignoring the power that individuals may have in shaping a collection’s preservation criteria. Hedstrom observes that debates about appraisal occur along a continuum ranging from a Jenkinsonian [21] approach, which takes as its point of departure assumptions about the neutrality and impartiality of records and the objectivity of the archivist, to a more socio-technical approach. (2002, p.34) 
Many classical views on collections define it with regards to “tangibility”, “ownership” and its “user community” (Lee 2000). We can safely discard “tangibility” from a definition of a collection that is compatible with the digital age.22 “Ownership” does not hold up either, with institutions such as the MoMA “acquiring” the @-sign (Antonelli 2015); a symbolic entity that is part of the public realm and hence cannot be owned, but apparently nevertheless can be included in a museum collection. A more common example is items that are on loan and often enter a digital cataloguing system along with an institution’s own items. It is not unusual that these records remain in the digital collection even after a physical artefact has been returned.
What remains from these definitions is the “user community”. I argue that the user community includes both internal and external scholars, researchers and individuals and that they both exert power on what a collection is. Currently the main power still lies in the hands of the curators and the ones governing preservation criteria. With increased digital access to collections data however, the power structures are shifting. Since the 2013 redesign of the Rijksmuseum website, users can create their own collections from what is available in the digital catalogue (Figure 2.12). So far, more than 230,000 custom collections have been curated, according to taxonomies that often are far remote from scholarly art history: Bubbles, Breast Feeding, Pornography, etc.
In conclusion, a collection, it appears, is primarily defined through the people that use and maintain it. Recent definitions and discussions display an increased awareness of the influence of individuals on the shape of archives and collections, and depart from supposedly objective and neutral standpoints. 

Collections as Data 
Libraries, archives and museums have been among the early adopters of digital technology for cataloguing the contents of their collections (Chenhall 1975). GRIPHOS (Heller 2013), one of the earliest digital cataloguing systems was released in 1967 and some museums use it even today (Williams 2010). 
Catalogues were primarily drafted as a way of making inventory, a way of answering: what do we actually have? A non-trivial question, not only for holders of large collections such as the British Museum, whose catalogue currently contains more than two million items and is estimated to grow to more than six million by the time it will be completed. 
A catalogue functions like an index: an efficient way of searching for a specific item within a collection by imposing a certain structure. Digital catalogues have been adopted because they allow for searching through an entire archive almost instantly and without practical limits in its size. Notably, also without limits in the size of the catalogue itself. While physical index cards can only hold a restricted set of data, such as, for example, the name of an object and its location in a storage, their digital counterparts can store nearly unlimited amounts of (meta) data: the date it was made or acquired, the name of its creator or inventor, its material or colour – in short – anything which the authors of a catalogue consider meaningful to record about anything which might be in a collection. 
Thanks to this rich metadata, the digital catalogue becomes more than just a list of things, it becomes a resource in its own right. It turns into a digital collection, which is not a mere reproduction of the ‘original’ analogue collection. Neither is it imperatively, by any standard, better or inferior to a physical archive, but a resource that can be used both in conjunction as well as independent from it.
The digital catalogue not only makes working with a collection more efficient; it enables completely new ways of interacting with an archive. I suggest to look at digital collections primarily as ‘data’; digitally stored information which can be accessed, shared, manipulated, enriched, reinterpreted and – most importantly for my research – visualised. 
I define digital collections as digital versions of indexing catalogues and finding aids and not as digital substitutes of physical collections. This is on one hand to avoid confusion about the terminology around digital collections and the process of digitising a collection. Digitising can mean making digital copies of cultural artefacts, through photographic reproduction or 3D scanning. Often it simply refers to converting index cards into a machine-readable format. Looking at digital collections primarily as catalogues, that might or might not be enriched with digital reproductions, serves as a lowest common denominator to ensure that methods and findings can be applied to a wide range of digital collections. 
Europeana (Figure 2.13), the European aggregator of digital collections, is more strict in its definition: Europeana focuses on giving access to the digital version of physical objects held in institutions rather than just abstract digital information about these objects. Therefore such catalogue descriptions are not considered as digital objects in their own right within the context of Europeana. This definition includes digitised catalogue cards as well, as they function as finding aids and not as objects. (Europeana 2014) 
This, however, results in the platform itself exercising a bias on the represented cultural artefacts, excluding collections that do not comprise physical items or that do not lend themselves to digital reproduction. For example, many 20th century artefacts may not be photographically reproduced due to copyright restrictions, leaving data from that period underrepresented (Gomez & Keller 2015). 
The second reason for wanting to differentiate between a collection and the data about a collection is to avoid a competition between digital and non-digital collections, and the respective methods for studying them; many historians feared that traditional methods would waste away with the advent of Quantitative History. 
Using digital methods for historic research requires scholars to rethink archives as data. Data, however, is an ambiguous term (Machlup 1983). When it is understood in a realist sense as given facts, it is unfit for use in the humanities, argues Drucker: To begin, the concept of data as a given has to be rethought through a humanistic lens and characterized as capta, taken and constructed (2011b) 
Drucker argues that the concepts and tools – such as data and data visualisation – that have been borrowed from the natural and social sciences “carry with them assumptions of knowledge as observer-independent and certain” (ibid.). However, data is also in the ‘hard’ sciences not generally seen as a neutral piece of evidence (Buckland 1991; Scheiner 2004; Borgman 2009). Borgman writes: In our research on science and technology researchers in the environmental sciences, we found differing views of data on concepts as basic as temperature. (2009, sec.28)
A biologist, for example, regards temperature not as given, but as a piece of data that has been acquired by selected means, under specific circumstances in a certain environment. Scientists generate their own data, making them aware of its constructedness and the individual circumstances under which the data has been acquired. In contrast: The humanities and arts are the least likely of the disciplines to generate their own data […] Humanities scholars rely most heavily on records (Borgman 2009, sec.33) 
Scholars who use existing digital collections operate blindly – the conditions in which the data has been created are often not recorded: Archivists […] make little effort to leave clues about the basis for their appraisal decisions or the contexts in which they are made. (Hedstrom 2002, p.37) 
Hedstrom suggested that the digital turn in collections could be an opportunity to improve this situation: New interfaces could serve as gateways to structured information about appraisal and selection. To build such interfaces, however, archivists would have to share their insights […], and, most importantly, reveal their uncertainties about, and discomfort with, the choices that confront them. (2002, p.37) 
So far, however, the proposed changes in how archivists record data have not taken place: the reasons for selection, subjective decisions and beliefs, which are increasingly accepted as forming part of collections, are generally not made explicit.

Time - A Framework for Sense-Making
We have seen how time and the conceptual shift in its understanding as a quantity in the Newtonian sense has played an important role in the invention of data visualisation. Of course, time can be understood in a variety of ways and such numeric and apparently objective models of time have famously been contested. 
Bergson (1950) discusses time in relation to consciousness. He distances experienced (concrete duration) from mathematical time (abstract time), the latter seen by Bachelard (1963) as a sequence of discontinuous, countable instants. Bachelard, as a philosopher of science, favoured a quantified model of time, for only what can be expressed in numbers would, in his view, count as scientific. By contrast, Bergsonian duration is “a qualitative multiplicity, with no likeness to number” (Bergson 1950, p.226). His duration is unique and extends continuously from past to present. 
‘Scientific’ time is no longer the simple uniform progression from past, to present, to future that non-scientists sometimes like to suggest. Einstein introduced a kind of subjectivity with the theory of relativity, and time’s very existence is repeatedly questioned, including in the ‘hard sciences’ such as physics (Barbour 1999). For Gödel, too (Weinert 2013), time is unreal, a conclusion that has been reached by thinkers such as Spinoza, Kant, and Hegel (McTaggart 1993), and many others throughout history. 
In the field of information technology, a number of innovations are introducing interpretive and subjective (Drucker & Nowviskie 2003), complex and uncertain (Kräutli & Boyd Davis 2013; Meeks & Grossner 2014), and social (Martin 2010) models of time. 
Nevertheless, Newtonian time is still the prevalent underpinning model in computing; and, if we keep in mind that it is just one of many, it has considerable merits for analysing data through visualisation by providing a unified frame of reference that can be easily mapped on to the numerical space of a digital screen. 
Time-wise visualisations, I argue, can enable users to gain new knowledge from digital collections. Knowledge, according to the European Committee for Standardization is defined as “the combination of data and information, to which is added expert opinion, skills and experience […]” (CEN 2004) . Embedded in this statement is the DIKW pyramid. The letters stand for Data, Information, Knowledge and Wisdom. In a hierarchical order, one follows from the other, although not automatically. Knowledge and Wisdom form the transcendent top half of the pyramid, while Data and Information form the broad basis of all of knowledge. The DIKW pyramid is generally attributed to Ackoff (2010), but apparently has its origin in the writings of T.S. Eliot.
It is not always trivial to distinguish data from information and there are competing views of what discriminates the two. Rowley (2007) defines information as “organized or structured data”. A slightly problematic view when applied to digital data. Digital data is inherently structured; it must always be stored in a data structure. Is digital data therefore always information? Not if we accept that information is not universally defined, but dependent on a subject. This is the view that is taken here – a common view but by far not the only one generally held (Zins 2007). Digitally structured data may be information for a computer, but it needs to be restructured and represented in order to become information for a user. 
What should be the criterion by which data, specifically cultural data, may be organised and finally turned to knowledge? Wurman (1990) writes that there is only a limited number of criteria for organising information: location, alphabet, time, category and hierarchy.
I argue that only time can be universally applied to digital collections. Alphabet, category and hierarchy are dependent on individual decisions of naming and classification and the necessary data may often be absent. Location could be a universally informative criteria, but again, it is often absent. This leaves us with time.
As with location, the date an object has been created or a piece of text written may not always be known, but nevertheless temporal elements are hardly completely absent in a digital collection. Time is recorded not only explicitly as attributes of individual items or artefacts in a collection, but also in the form of time stamps: when it entered the archive, when it was recorded in the collection, when it has been accessed, moved, disposed, etc. Even when no explicit temporal information is recorded, time is implied in the sequence in which elements have been catalogued.
Arguably, time might simply be the most obvious way to order data. Time – as measured by the running of a clock – structures and coordinates most aspects of our lives, from daily routines, to appointments and yearly holidays. It is the mnemonic by which we remember pivotal events such as 9/11 or 1789 and it is the yardstick by which we slice the past into manageable portions, be it the 1960s or the Renaissance. Time has become so ubiquitous as an organising principle that we tend to take it for granted. 
Time has silently become one of the main modes of organising and viewing digital data. A study on email triage found that 89% of all users sort their emails by time (Neustaedter et al. 2005). Social networks sites suggest a chronological ordering, notably Facebook with changing the name of the “Facebook Wall” to “Timeline” in 2011 (Cellan-Jones 2011).Twitter’s attempts at deviating from displaying content in a strict chronology regularly caused an outrage among its user community.
What motivated this shift towards a time-centric mode of digital information structuring? Malone (1983) observed a general struggle of users dealing with complex folder structures already in the age of paper based documents. By adopting the file and folder metaphor in desktop computing, the problems of these organising principles have been inherited as well (Lansdale 1988). Moreover, the rise in the amount of documents that people have to deal with due to the almost zero cost involved in sharing them has led users to become increasingly unable to properly file them into folders (Boardman et al. 2003). 
Freeman et al. (1996) have similarly argued that hierarchical folder structures quickly become both too complex and obsolete. They instead propose a time based model: Lifestreams (Freeman & Fertig 1995; Freeman & Gelernter 1996, Figure 2.14) is a visual file retrieval system that arranges all personal files and documents in a growing visual timeline. It starts with a person’s birth certificate and extends into the future, including to-dos and documents a user will be needing at some later point in time. They chose time as the structuring element, because in their view time is a natural guide to experience; it is the attribute that comes closest to a universal skeleton-key for stored experience (Freeman & Gelernter 1996, p.2). 
Time has since successfully been used as ordering dimension in many digital information management and retrieval tasks, such as general desktop computing (Malone 1983; Freeman & Fertig 1995; Rekimoto 1999; Llorens et al. 2011), search tasks (Alonso et al. 2007; Alonso et al. 2010) and in applications targeting specific types of electronic files such as emails (Yiua et al. 1997; Kiritchenko et al. 2004; Ringel et al. 2003) or digital photographs (Platt et al. 2003; Huynh et al. 2005). Hierarchical ordering of data is increasingly abandoned in favour of time-based sorting as more and more personal files are stored on servers in the proverbial cloud. Names and folders – alphabet and hierarchy – as the obvious modes of organising files are replaced by time based sorting. Photos cease to be files and turn into streams when they are stored on the servers of companies like Apple and Flickr.
The novelty of cloud storage is not merely that files are stored on a server, but that data can be copied, edited and subsequently synchronised across a multitude of devices. Keeping track of the latest version of a piece of data is a non-trivial challenge. After all, a document might have been edited on a device without internet connection and only uploaded later, but the same document could have been changed on a different device in the meantime. Tracking changes over time is necessary in order to resolve potential conflicts and to only retain the most current version of a piece of data. 
It is unclear whether the shift towards time-centric structuring of information was informed by conscious design decisions, such as the ones proposed by Freeman et al. (1995; 1996), or if the focus on time from an engineering perspective has spilled over to the front-end. Time might arguably not be a “skeleton-key”, but it is an organising model that has proven to be very effective across a large number of knowledge domains. 

Time, History and Chronology 
One view of collections I left out in my earlier discussion is the dictionary definition, which equates archives to accumulations of historical documents and artefacts. This historical perspective makes studying them along a model of time an obvious choice, especially if ‘history’ itself is considered according to the dictionary as “the past considered as a whole” (OED Online 2015b). However, history cannot simply be equated with the past. According to Walter Benjamin (1940/1991), history is located in the present (“Jetztzeit”). History is constructed and subjective – a view shared by many historians and theorists, dating back at least to Hegel (1770-1831) who argues that even the ordinary, the “impartial” historiographer, who believes and professes that he maintains a simply receptive attitude; surrendering himself only to the data supplied him – is by no means passive as regards the exercise of his thinking powers. He brings his categories with him, and sees the phenomena presented to his mental vision, exclusively through these media. (2001, p.24) 
When we study collections over time we are employing chronology in order to derive meaning. John Locke (1632–1704) paired chronology, together with geography, as the essential prerequisites for history: Without geography and chronology […] history will be very ill retained, and very little useful. (1693) 
Locke emphasises the importance of geography and chronology for structuring events which otherwise would just be a “jumble of matters of fact” (1693). 
In its original greek meaning, ‘historia’ is concerned with retelling of what one has learned through investigation, not the least by chronology. In that sense, history is concerned with communicating knowledge, while the task of chronology is to turn the jumble of matters that is data into structured information, to be interpreted by a historian in order to derive knowledge.
Time, in the view of some authors of the 18th century, may serve as the unbiased framework by which events are presented “in a truer Light than regular Histories” (Pointer 1714). While the claim for a possible truth value of time has to be taken with a grain of salt, Pointer continues to argue that when events are presented in a chronological manner, it enables the individual on his own to make sense and draw new knowledge – to “make their own Inferences from simple Matters of Fact” (Pointer 1714). 
Where history is the – necessarily subjective – retelling of events, chronology provides rigour: a kind of ‘honesty’ in studying and representing events. Events are studied according to a schema that is traceable, communicable and transparent: the model of calendrical time. 
Pre-calendrical descriptions of events depended on correlations with temporal landmarks. Roman historians would chart events according to a list of past consuls, while Athenian used their own reigns (Feeney 2007, p.9f) – a cumbersome endeavour and converting between different cultures’ models of timekeeping meant identifying where they align and differ. The primary motivation for creating a unified calendrical model was, according to Feeney (2007, p.18), not practical or logistical considerations, but the writing of history, for which chronologies that were compatible across cultural differences in timekeeping were crucial. 
The Julian calendar provided a unified model according to which events can be ‘positioned’ – a model which allows their users to easily find out whether two events have happened before or after each other, or simultaneously. Graphical renderings of events, such as Priestley’s Chart of Biography that followed 1700 years later, made such comparisons even more accessible: You see at one glance, without the help of Arithmetic, or even of words, and in the most clear and perfect manner possible, the relation of these lives to one another in any period of the whole course of them. (Priestley 1764, p.10) 
The ease by which events can be located in chronologies can however introduce also a kind of dishonesty, when it leads to historic data being represented in a truer light than is possible. The date of past events can never be truly known, even if they are described according to a rigorous framework such as the calendrical model of time-keeping. A rigorous calendar is also a rigid model of time and no guarantee for ‘truth’. Calendrical dates do not rule out the presence of doubts, contradictions and inconsistencies.
History, in the historiographer’s definition, is therefore not a neutral representation of the past, but, as far as possible, an honest retelling of past events. Collections serve, to the researcher of history, as a source of evidence for past events. Chronology – structuring events through a model of time – equips a researcher with an ‘honest’ framework for making sense of collections: a transparent, rigorous, but not necessarily ‘true’ model for studying history. 
Chronology and a unified model of time equipped historians with methods for being rigorous and transparent – in short – honest about what they know and how they know it. Digital research methods need to follow similar ambitions, which in the case of timeline visualisation tools means being rigorous and transparent about the visual representation of sets of data. 

Curators’ Perspectives - Objects and Time in Digital Collections
Through my conversations and interviews with curators and other representatives of cultural institutions, and by examining their collections datasets, I was able to gain a better understanding of the prevalent views and issues around digital collections. Specifically, I will present insights on the handling of dates; how temporal data is stored in cultural datasets and the possible interpretations that digitally stored dates may entail. 
Most digital collections store dates as a pair of values denoting an earliest and latest possible date. Additionally, the date is generally stored as free text: it is this representation that the curators work with and is exposed on a website when the collection is accessible online. Numeric dates are, in day-to-day use, primarily relevant for searching records, as the textual dates are not machine readable. Data visualisation depends on them for the same reason: generating graphics digitally relies on the underlying data to be machine readable. 
The numeric date pairs typically bracket the date of production of an artefact. Other dates, if present, are usually only recorded as a single date. The date brackets therefore do not normally relate to a durational time period, but a possible time frame for a historic event. Collections data thus holds a measure of confidence in the numeric dates, which is derived from the written date descriptions. 
Often, there is a significant discrepancy between the free text that the curator enters manually and the numeric date pairs that lie ‘behind’ them and are sometimes generated automatically. The numeric values for the pairs of dates are typically stored as years, even in cases where more precise information would be available in the written date. In other cases, where the precision of the known date is less than a year, the numeric dates are set as a precisely defined range of years. In the Cooper Hewitt objects database, for example, “mid-20th century” becomes 1940-1958, “possibly ca. 1960” is stored as 1955-1965 and “1946 or later” is quantised to 1946-1989. Date-formatting and processing protocols add their own interpretations on the representation of the data, typically implying greater precision than was available to the person who originally entered the information.
Collections datasets exhibit a range of textual date descriptions. Table 2.1 on page 77 lists, in order of frequency of occurrence, the format of date descriptions in a representative sample of 200 records from the V&A dataset. A large number of them include expressions of uncertainties and doubts. There is, however, no indication of the source or reason of these uncertainties. A user who is unfamiliar with the history of an individual item will be oblivious if the uncertainties originate from a lack of information, conflicting records, unreadable or ambiguous sources – in short: the reasons for a lack of precision in the temporal information remains undisclosed in the dataset. It is important to remember that the same applies also to the dates without such qualifiers; one cannot inherently assume that these dates are certain. Certainty – as well as uncertainty – is merely a matter of sources and interpretation, none of which is captured in either of these digital date descriptions. 
We can identify the vocabulary used to express uncertainties, doubts and timespans: “ca.”, “probably”, “possibly”, “after”, “late”, etc. A fairly consistent set of terms, probably because the software used to catalogue the datasets tries to automatically convert these descriptions to numeric dates and displays an error, or requires manual user input, whenever it cannot recognise an expression. Due to them partly being controlled by the expectation of the software, this list of terms might reveal more about the inner workings of the recognition algorithm than about the curator's language for dating objects. BrittenPears Foundation’s thematic catalogue of works of Benjamin Britten contains textual date descriptions that have been manually converted to machine readable dates. Nevertheless, the descriptions follow similar patterns and expressions of confidence - “circa”, “pre”, “post” - which could mean that the terminology remains relatively fixed even when the manual conversion would allow more freedom. 
A curator I talked to about the dates I encountered in collections databases suggests that these date descriptions are influenced by conventions even when they are not mechanically enforced: 20 years as a curator, I was always forced to be certain about things I wasn't certain about. Think about how you express both uncertainty – not trueness – and which date you pick - however certain you are. Is it the start of construction, end of construction, sale, purchase, destruction, whatever. (C3) 
When an object is exhibited in a museum, it usually is described by just a single date, the year of production: There are two concealments that museums have practiced. One is, the concealment of uncertainties. The second is the concealment of the long lives of things. […] historians have only been interested in invention; the moment of genesis. […] we try to conceal everything since 1829 to the present by saying Stephenson’s Rocket is 1829. (C3) 
Conceptually one might think of dates in all different kind of ways – “There's a language that I use to express temporality, which is a fuzzy language and it’s a subjective language, as you made me realise.” (C3). Conventions of the field, however, led to a standardisation of the terminology of describing dates. Digital technology enforces its own standards on dates through the processes of quantification I described. These effects are added on top of the ones date descriptions have already undergone before they entered a digital system. 
The use of digital databases to represent knowledge is often associated with a loss of information resulting from the structural requirements posed by the digital system, a recurring critique of the computational turn in the humanities: In cutting up the world in this manner, information about the world necessarily has to be discarded in order to store a representation within the computer. (Berry 2011, p.2) 
At least in the realm of cultural collections, where structures and conventions have dictated how information is stored even before the advent of computers, digitisation also partly had the opposite effect. Cataloguing software abolishes the physical space restrictions of index cards and allows more freedom in the descriptions and choice of fields. These richer forms of data storage, however, introduce their own problems to collection holders, as one curator recalls: That was a quite difficult transition from when you did paper records to computer records. We used to have a glossary of terms, a thesaurus. You made your objects fit a prescribed framework of terminology. There was physically a book which gave you the thesaurus of terms. Now with more free flowing cataloguing, someone could call a bowl a ‘bowl’, or a ‘basin’. […] It was sort of easier to extract the information, because under ‘ewer’ it would say ‘see basin’. (C11) 
The challenges resulting from the relative freedom granted by digital cataloguing systems were echoed by a number of curators. As users are not forced to adhere to specific standards, datasets can easily become messy: […] we have a large number of different people cataloguing all the time. Because you can catalogue away in free text [...] it can cause you real issues. (C1)
Collections datasets often become complex and hard to interpret, because the system may allow a great amount of liberty in choosing how and where to store data – You’ll find some objects with description fields. Others without, but [descriptions] in another field. (C2)
– but also because the data structures have been changed and expanded as new items entered a collection that were not originally anticipated when a system was put in place: We have customised our collections management system very much. […] It has given us flexibility, but there’s a flip-side to that [...] it’s quite difficult to standardise it. (C2) 
Besides making it often challenging for curators to retrieve data, collection holders pay for increased customisation and flexibility when data from different collections has to be combined. A process which is quite common; except for a small minority of relatively recent catalogues, all datasets I have worked with contain items that have previously been maintained in (or constituted) separate collections, often as part of different departments within museums. In the old days we had a 2D collection and a 3D collection and they had quite different views about cataloguing […] We’ve been trying to bring the two together. (C2) 
It is during these processes of merging datasets that data has to be reinterpreted or may be discarded when old data finds no place within new databases – “We call it ‘squashing’. It’s not a technical term but it’s very, very difficult” (C5). Without background knowledge of a collection’s history, one may not always know how trustworthy certain pieces of information are. Especially with regards to data that may not be considered the most essential aspect of a collected item – often temporal information: They treated this whole batch [of posters] as if it was ‘an archive’ […] The individual posters within that [batch] – and of course all subsequent posters no matter what date they are – have just been given inventory numbers based on the date they were acquired, even if, of course, they could be much earlier. (C8)
Other factors, such as changes in the administrative structure of a collection also have a great influence on the accuracy and credibility of dates: We have a lot of objects, supposed to be acquired in 1876. They have been acquired before but that’s when we started a new inventory system. […] We know as curators that when you get [this date], you don’t believe it. (C3) 
Dates are particularly problematic to interpret in collections that occupy a large timeframe, both in terms of the items they contain as well as with regards to the period of their own existence. In younger and smaller collections that might only focus on the works of an individual artist, and therefore are able to apply more consistent dating strategies, knowledge about the origins of dates is more easily maintained and curators may know which dates they can trust… There’s a lot that could be done with the period of 1928-38 because he kept diaries then. He didn’t keep them before 1928, so any date that’s on there before 1928 will be because it’s written on it. (C6)
…or conversely which dates have to be treated with caution: [The artist] was really bad at dating. He just painted something and sold it, so stuff has gone into lots of different collections and come back to us at the Library, but we’ve got very limited information about dating. (C5)
These factors are, of course, embedded also in the data of larger collections, but it is less likely that knowledge about the origins of dates – and most other aspects of the dataset – has been acquired about the complete collection, passed on and maintained throughout changes in governance and staff. 
Archives and museum collections are seen as the neutral, material evidence of our cultural past. Lynch describes digital collections as “uninterpreted databases of raw cultural heritage material“ (2002). The UK’s National Museum Director’s Council states the purpose of museums in their manifesto as follows: We are a mirror to our own times and illuminate developments in our culture and society. (2004) 
What museums are generally not eager to admit in public, yet are aware internally, is that they are a distorting mirror, reflecting culture and society through various filters and biases. Beginning with the choice of material by which the past is represented…
In a museum, your core-thing is the object […] I suppose as curators we work on the premise that the object is what is fascinating. (C11) 
… and continuing with the various factors that determine which objects are preserved, which can be physical – Maybe people were very selective in the past sometimes […] when storage and conservation were big issues. (C11) 
– administrative – […] the shape of the collection is determined by the administrative structure and preservation criteria; what the museum deemed important enough […] (C8) 
– strategic – Sometimes you just have to take something and hope that with passage of time it will become significant (C1) 
– or environmental: The content of the database is a non-random selection of the painted pottery that survived from ancient Athens […] (C7) 
In my review of the literature I have already encountered a growing recognition that collections and collections data are not neutral, but subject to various influences. Through my conversations with curators and encounters with their datasets I have been able to get a better idea of the specific kinds of interpretations that are exerted by the individuals, institutions, conventions and the digital systems respectively. 
Digital databases and the people that use them add various layers of interpretation to a cultural collection. There can be no “uninterpreted” (Lynch 2002) databases as much as there can be no uninterpreted collections. Digital data structures add their own distortions to collections datasets. Computational representations of time, which, in the computer science tradition is treated as a numerical space, are particularly affected by this, as we have seen. 
Making sense of cultural data over time therefore entails making sense of the distortions that a collection has experienced throughout its history. The potential personal, institutional and organisational biases of collections, and consequently, collections data needs to be taken into account when visualising it on a timeline. 
Humanities researchers are used to having to be critical about their sources and the need for criticality applies to digital datasets as well. Several scholars I have talked to observe that digital sources are often not approached with a healthy level of suspicion, which could well be a symptom of digital interfaces not allowing or promoting critical enquiry. Ideally, visualisation tools can enable this criticality and help to expose the various layers of human and machine-made interpretations a dataset has undergone. It might be the most important difference when designing visualisations for scholarly, rather than for casual use; not to simplify, not to make a dataset appear more perfect than it is, but on the contrary, to respect and emphasise its imperfections and to steer the attention to inconsistencies and possible sources of knowledge.

Discussion
If we regard a collection as a dynamic entity that is shaped and reshaped by the people that govern and use it, digitisation has not fundamentally redefined the concept of a collection. Digitisation has, however, changed how collections may be used and studied, and added – to the traditional methods of humanities research – those methods that are universally applicable to digital data: data mining, visual analysis, automated processing, visualisation, etc. Digital tools and methods are, however, not easily transferable from the quantitative sciences, from which they originate, as is evident in the difficulties of curators to digitally model notions of time in databases as well as other kinds of humanities data. Digital Humanities methods require established paradigms for data analysis, including visualisation, to be reconsidered. Researchers need to develop an understanding of the kind of insights digital tools can enable. Collections data offers an ideal testbed for simultaneously exploring – by studying and developing appropriate visualisation methods – the requirements of humanities research tools as well as the knowledge currently hidden in digital collections. 

Data visualisation for the Humanities 
Data visualisation is one of the essential research methods for the Digital Humanities, especially when the research is – as it is most of the time – concerned with large datasets. However, established paradigms for visualisations in the sciences do not necessarily translate to humanities data. Lunenfeld et. al write: Currently, visualization in the humanities uses techniques drawn largely from the social sciences, business applications, and the natural sciences, all of which require self-conscious criticality in their adoption. Such visual displays, including graphs and charts, may present themselves as objective or even unmediated views of reality, rather than as rhetorical constructs. (2012, p.42) 
Jessop on the other hand argues that digital visualisation methods are not in any way “revolutionary” (2008) or “lacking in rigorous scholarly value” (ibid.). Rather they are a continuation of established academic practice. A similar line of argument is pursued by Unsworth (2000), who lists a range of “scholarly primitives”; common discrete activities that humanities scholars need to be able to perform when doing research, regardless whether these are carried out with digital or analogue tools.
Drucker argues that the effectiveness of visualisation has caused humanities researchers to lose the necessary criticism for rigorous scholarly research: The sheer power of the graphical display of “information visualization” […] seems to have produced a momentary blindness among practitioners who would never tolerate such literal assumptions in textual work. (2011b, sec.5) 
Drucker complements her article with suggestions of less reductionist graphical displays which try to convey some of the subjective, emotional and uncertain components of the presented data. These are toy examples based on artificial data and it is unclear how they would behave with and scale to real world datasets. They do however convey a sense of the necessity to scrutinise visual representations and to question the implied precision, honesty and trustworthiness of visual diagrams. 
The reason for an apparent lack of rigour in digital humanities research stems not only from inappropriate tools and visualisation methods, it might also lie in researcher’s unfamiliarity with visualisation tools and a lack of criticism towards them. The ability of graphs and diagrams to mislead – whether intentionally or out of lack of acuity – and the risk of compromising on the ‘truthfulness’ when representing data visually is a known problem in the scientific community, and even in popular literature (Huf 2010). 
On one hand, there is a clear need for visualisation tools that are able to fit the characteristics of humanities data and research – on the other hand it is also necessary that humanities researchers become aware of the mechanisms of digital data visualisation and how they in turn shape humanities knowledge production. My research aims to address both of these issues; by developing new tools, and by developing them in collaboration with curators and archivists. 
It is crucial that researchers gain an understanding of the epistemological consequences of knowledge production from digital sources by digital means and that we learn to understand what kind of insights we can expect to gain. Even if more appropriate tools were available to humanities researchers, without a better understanding of their working principles they remain “intellectual Trojan horse[s]” (J. Drucker 2011b).

Digital Collections as Objects of Research 
I argued that we should study digital collections independently from the collections they are based on; by regarding them primarily as catalogues and, thus, data. 
However, I am hesitant to refer to digital collections as ‘raw data’. The term is generally used to describe data that requires to be processed – for example through visualisation – in order to deliver useful insights. Clean data, on the other hand, is organised and pre-processed so that it can be read also in its ‘original’ form. I suggest that it is necessary and valuable to consider any kind of dataset, whether well organised or disorderly, as open to reinterpretation.
Differentiating ‘raw data’ from data in the context of digital collections is, I argue, neither useful nor possible. Lynch, who defends the view of collections being uninterpreted, questions at the same time how “interpretation-neutral” a collection can be (2002); because, for example, “interpretation creeps into the descriptive metadata” (Lynch 2002). In his view, interpretation-less digital collections would nevertheless be the ideal to strive for and he suggests that biases in collections could be neutralised by drawing from different sources. 
What I discovered through my research – and will describe later on – is that embedded “interpretations” in digital collections must not present an obstacle to making sense of it. They form part of any collection and hence should not be suppressed; doing so would mean consciously disregarding one of their fundamental properties. Furthermore, when the methods for accessing the datasets acknowledge the presence of embedded biases, they can enable valuable insights. 
Existing work in visualisation-based interfaces for cultural collections largely treats them as digital substitutes of physical archives and focusses on making their content more accessible to specialists and the public – with an emphasis on the latter. These include for example the SFMOMA ArtScope (2007, Figure 2.16), which allows users to explore more than 6,000 artworks in a tile-based zoomable visualisation or the map based interface of the Natural Science Museum of Barcelona.
Several interfaces for cultural collections have been developed by Whitelaw (2015), who advocates a “generous” approach of enabling access to digital collections: Generous interfaces offer rich, browsable views; provide evocative samples of primary content; and support an understanding of context and relationships. (Whitelaw 2012).
An example has been developed by Ennis Butler (2013) – Whitelaw’s PhD student – based on the Centre for Australian Arts Print collection (Figure 2.15).45 Through five different visual interfaces, online visitors can explore the collection based on the relationship between works, keywords, their associated individuals as well as two time-based views: a “decade summary” of the entire collection and a timeline view, which plots the works of an individual artist along a vertical timeline. Different access points and rich contextual cross-references allow users to immerse themselves in the collection. Users are permitted to get lost in a collection instead of – the normal task of curators and what interfaces are usually designed for – looking for something specific. 
Generous interfaces build on Bates’ (1989) berrypicking technique and Dörk’s (2012) concept of the information flâneur: models that see search and information seeking not only as a goal-directed task, but as an explorative and – not the least – enjoyable activity. 
The interfaces Whitelaw and his collaborators have built so far demonstrate the richness of digital collections, which is often hidden behind ‘ungenerous’ search forms. The interfaces are aimed at the general public and are not specifically intended for scholarly use, although “they may prompt such analyses both by scholars and (importantly) wider communities of interest.” (Whitelaw 2015, sec.38).
Whitelaw gives an example of what can be derived from the summative diagram in the decade view of Ennis Butler’s prototype: The resulting graph is informative in itself, showing the chronological shape of the collection and the relative distribution of different print types. The boom in stencil printing in the 1970s and 80s, for example, is clear. (2015, sec.26) 
A scholarly tool would need to support a deeper engagement with the occurrence of such patterns. Is it really representative of a general increase in the usage of this printing technique? Is the entire collection a representative sample of prints produced during that time or is the pattern telling of the taste of an individual curator? Are these all unique prints or maybe several reproductions of the same original stencil? Are the dates reliable or could there be errors or uncertainties? Could there be biases in the structure of the catalogue or the database that skew the digital data in this category? Visual analytic tools for cultural collections should have the ability to answer such questions and be able to convey the reliability of the conclusions that can be drawn from observations. 

Digital Historiography 
Traditionally, there has been a clear separation between a researcher and a collection; between the archivist – the maintainer of the collection – and the historian – the user of a collection. Collections provide the ‘neutral’ evidence for the historian, which the archivist has gathered and structured. Archives are organised by basic principles such as “respects des fonds” (Duchein 1983) which ensures that the original order of the artefacts and documents in an archive is maintained and suggests that they represent a neutral conservation of the past. The task of a historian is then to make sense of this material through tracing their historic narrative. 
We have seen, however, that collections are decreasingly conceived as neutral accumulations of evidence, but instead as dynamic entities that are defined and redefined by subjective individuals. This has consequences for historians and anyone doing research with archival materials. 
Historians separate their materials into ‘primary’ and ‘secondary’ sources: ‘original’ pieces of evidence as those contained by archives and other people’s interpretations of such evidence. If we accept, however, that historical evidence as contained in collections is already subjected to individual and institutional influences and appraisal, we consequently have to accept that a researcher working with a collection is in fact not working with primary sources in the strictest sense. 
It is not surprising that this is an unacceptable situation for some and one of the reasons why many scholars advocate the use of ‘traditional’ over digital methods; studying the ‘actual’ archival material over working with digitised artefacts. The competition emerges most visibly in digital collections that, in addition to cataloguing data contain high-resolution scans of historic documents. When high resolution photographs allow researchers to examine the quality of a brush stroke or the texture of a paper more closely than they would be allowed and able to with the ‘real’ physical artefact, the implied hierarchy between the digital and the physical object becomes hard to defend. 
However, this is not an argument for the digitised artefact to be regarded as equivalent to the original. It is an argument for the opposite. When the digital, an obviously remediated, interpreted and subjective ‘secondary’ source, is as useful for humanistic research as the ‘primary’, it becomes hard to deny that also the physical artefact in a collection is to a certain degree a secondary source. The digital, in the context of collections, not only requires new methods, but also a new understanding of historiography: of what we are able to derive from historic evidence and on what constitutes that evidence. This is a development that has been identified by Kramer: So what, then, does it mean within the digital domain to address historiography when it is understood to be the collection of secondary sources and ongoing debates about a historical topic? It would mean, perhaps, rethinking the relationship between primary and secondary sources in new ways, not just going to the supposedly pure sources, fetishized as they are in the field of history. (2014) 
Digital collections emphasise the need to be critical about archival sources – that primary sources in an archive carry a certain degree of secondary interpretation. Digital collections require historians to reconsider assumptions about primary sources in collections and researchers need to develop new methods that are honest about the degree of pre-interpretation of sources in curated collections. The way in which digital structures and representations emphasise the constructedness of a collection and, consequently, the data about the collection requires us to face the implications of researching history through remediated sources. 

Chapter 3 : Digital Timeline (Tools)

By embedding my research in the wider field of the Digital Humanities and studying its foundations with respect to collections data and time-wise visualisation I have identified a number of challenges for my research to address. I will now investigate the status quo of digital timelines in order to identify possible shortcomings in existing implementations. I will explore the abilities of digital timelines to qualify as analytical tools through a review of existing projects. My aim is to explore and make explicit what separates a naïve timeline from a timeline that can fulfil the needs of scholarly research and enable visual analysis of a wide range of digital datasets. In doing so I will identify shortcomings and opportunities of existing digital timelines for visual analysis of cultural collections. These will result in the formulation of focus issues – concerning the time-wise visualisation of large datasets, the development of timeline layouts and the incorporation of multiple temporal descriptions – that will guide my practical exploration of the research questions through a series of prototype visualisations. I will review a selection of timelines drawn from examples I have gathered throughout the duration of my studies, outline their characteristics and potential problems and how they translate to timeline visualisations more broadly. I will initiate a deeper discourse around this class of diagrams in the way that is already taking place with other formats such as network visualisations (Fruchterman & Reingold 1991; Golbeck & Mutton 2006; Martin et al. 2011; Krzywinski et al. 2012) and even pie charts (Brinton 1919; Eells 1926; Croxton & Stryker 1927; Cleveland & McGill 1984; Spence 2005). I begin by introducing a spectrum to systematise timeline implementations for scholarly analysis. The spectrum is presented as an alternative to DeFanti et al.’s (1989) discrimination between visualisations for either communication or discovery (analysis). While classifications are helpful for making comparisons through providing a framework for discussion, I found that this particular distinction is not very useful in the case of visual timelines. Priestley’s Chart of Biography (1764), for example, can be seen as both communicative and analytical and the same applies to most of the timelines I will introduce in this chapter. I therefore employ a spectrum that distinguishes timelines by progressing in four stages from static to open. It does so through a set of thresholds that describe interactive and technical features that signify an advancement in a timeline’s use as an analytical tool. Open timelines, the ultimate stage, contain interactive features to analyse, filter, select and compare data, and are open in the sense that they are able to work with different kinds of datasets and are themselves open to interpretation and critique. The tools I set out to develop, will consequentially be open timelines. My review of existing tools is led by a set of criteria. Based on an initial review of requirements I devised and refined these criteria over the course of my research and revised them according to new findings that resulted from my practical and theoretical investigations. The criteria help me to direct my attention to the specifics of how data is visually represented over time. Timelines are a familiar diagram format and consequently a lot of their visual rhetoric is often taken for granted. By examining timelines through a ‘lens’ of criteria, I am able to look beyond certain preconceptions and reconsider present assumptions and design decisions. These criteria are included in appendix A on page 251 and form the method by which I study the examples in order to ensure that my enquiry follows a transparent and rigorous process and covers all the aspects I set out to examine. The criteria therefore mainly serve the execution of the present investigation and are not intended to be used outside of this thesis – although they could be appropriated and improved by others.

Defining Analytical Timelines

At first I looked at timelines as either visualisations for “discovery” and “communication”. Communicative timelines may be illustrations to a narrative that has been constructed based on historical evidence: a way to communicate time-based information in a graphical manner in order to educate others. Most visual timelines typically found in museums are of this kind – engaging communicative devices, but often too simplified to serve as scholarly research tools and, some argue, even too simplified for communicating the complexity of historical narratives (Lubar 2013). The datasets that they represent are often limited and heavily curated, and the arrangement and visual representation of events follows aesthetic and practical constraints.
Such timelines may be of significant educational value, but one would not be inclined to draw any reliable conclusions from visualisations that are evidently not drafted for the purpose of scholarly research. For example, we would not expect Christopher Lloyds Wallbook of Big History (2011, Figure 3.1), a “comprehensive, visual voyage” through all of history, to – in fact – be comprehensive. Nor would we expect to be able to precisely read the period of time different species lived on our planet from the graphical space that they occupy on the time axis; it is not an arithmetic mapping of events for the purpose of analysis. The timeline is not intended to represent all of history, but to give an overview of important events in an accessible and engaging manner. The purpose of this timeline is not to discover new knowledge in the field of history, but to communicate insights from the field to a public. A timeline for the purpose of communication is the product of a transformer, a term coined by the designer and theorist of educational graphics Marie Neurath: It is the responsibility of the ‘transformer’ to understand the data, to get all necessary information from the expert, to decide what is worth transmitting to the public, how to make it understandable, how to link it with general knowledge or with information already given in other charts. In this sense, the transformer is the trustee of the public. (Neurath & Kinross 2009).
Communicative illustrative timelines may allow for novel insights, but their primary goal is not to process data, but to convey pre-processed information. 
We may not always be able to clearly distinguish communicative from analytical timelines, especially when it comes to their digital instantiations. When a graphical timeline is generated programmatically, the rendering of events has to be made explicit which results in digital timelines often, but not always, being more strict and therefore transparent in the visual mapping of events to (numerical) time. This side-effect of digital timelines facilitates their use as analytical devices, but it does not automatically follow merely from them being digital. 
A helpful classification I employed in the beginning of my research – when I collected different examples of digital timelines – was the distinction between timeline projects and timeline tools. A project represents a purpose-built timeline visualisation around a specific dataset, while a tool constitutes a dedicated software or library for visually representing arbitrary datasets in time. 
In many cases we can deduce that purpose built timeline projects are communicative visualisations as they are based on a single selected and curated dataset and often include elements of storytelling. Timeline tools, on the other hand, accept external datasets and may be used as analytical devices, whether or not this use was originally intended. However, there are a range of exceptions to this rule, such as dedicated timeline implementations that later have been adapted to accept different kinds of datasets, or timeline tools that are, in fact, authoring environments designed to produce simple narrative timelines. 
I therefore propose a four-step description for classifying digital timeline visualisations: static, dynamic, exploratory and open timelines (Table 3.1). We can look at it like a continuous spectrum, as a visualisation might develop from a static to a dynamic timeline, and further. As a progressive spectrum, each threshold presupposes the conditions of the previous classification(s).
Static timelines are digital timelines, which function equally well on screen as they could when printed on a paper. A user might be able to pan and zoom the display in order to look at aspects of the visualisation in detail, but static timelines do not offer any additional interactive features, by which I mean the ability to change the presented view or aspect of its rendering. 
Dynamic timelines offer basic functionality for a viewer to manipulate the display. They could be similar to slide shows or scroll based websites where interactivity is present, but mostly confined to a limited and pre-scripted storyboard – the author has anticipated most of the possible manipulations. Additional information about aspects of the visualisation may be provided, for example, by highlighting or selecting graphical elements. 
Exploratory timelines allow for a deeper level of interactivity and manipulation by, for example, not only offering different views on a display, but giving a user more freedom in affecting the rendering of individual events, or offering methods for filtering or searching a given display. The timeline affords ways for interrogation beyond visual inspection. 
Open timelines give a user not only more freedom in the way the data is represented, but also in the kind of datasets they visualise. This could be facilitated, in the case of dedicated software, through an appropriate user interface or, in the case of software libraries, through a well-designed API or sufficient documentation of the source code. For arriving at digital timelines that allow visual analysis and insights, I regard open timelines as the desirable format. This does not automatically mean that a static timeline is necessarily inferior in this regard – a well-designed static visualisation may be more insightful than a thoughtlessly designed one that is technically superior. However, open timelines allow for verifiable insights which may be reproduced and reused by others, which I – and others (Borgman 2009) – see as a main requirement of tools for scholarly analysis.

Evaluation Criteria for Timeline Visualisations
In order to be able to evaluate different kinds of digital timelines, despite their dissimilarities and the many possible implementations, purposes and styles, I have drafted a set of criteria which I have used to examine and compare the variety of digital timelines I have collected, of which I will present a selection. I selected the projects primarily based on their acceptance and diversity. My aim is to be comprehensive within my abilities – I can only safely evaluate a tool to which I was granted access. As is the nature of digital artefacts, some timelines I have studied may in the meantime have been updated or changed or – at worst – disappeared. I therefore captured screencasts of the discussed projects and included the URLs to the videos in appendix C on page 270. 
The criteria I propose and apply are not meant to be a means for assigning grades. There are no correct answers and a visualisation which can respond to several criteria is not automatically better than one which just answers a few. My approach relates to Twyman’s schema for the study of graphic language “as a device for directing our thinking and not as an end in itself” (1979, p.202). 
The criteria I employ are intended as a checklist to help me focus on issues that might get overlooked: All this is made necessary because our training and experience, whether primarily verbal, numerical, or visual, tends to predispose us towards particular approaches to graphic communication. (Twyman 1979, p.202) The criteria are organised thematically as a tree (Figure 3.2). Upper nodes represent wider themes that depend on several factors and might require individual judgment based on personal requirements. Therefore, they are further broken down such that the criteria at the leaf nodes may be assessed, as far as possible, without subjective appraisal. We move from larger questions such as the overall representation of records, to finer grained aspects such as the graphical vocabulary used to render individual items – what kind of shapes and colours are present and what do they signify? 
The complete tree contains 112 criteria, which I will not discuss in detail here. I will merely describe the five central topics which are below the root node: 
“Data acquisition and curation” looks at a visualisation based on the data level. What kind of datasets are allowed or included? What kind of expectations does a dataset need to meet?
“Representation of dataset” evaluates the visual rendering of the complete dataset. How is the layout assembled? What kind of temporal models are used? What factors influence the readability of the entire dataset? 
“Representation of records” focusses on the visual representation of individual items. What kind of graphics are used? How are temporal elements mapped onto visual aspects? What kind of temporal descriptions are supported, such as events, periods, uncertain or discontinued times, etc.? How consistent is the mapping of time to graphical space? Are there exceptions?
“Interaction” forms the largest branch and looks at aspects that facilitate exploration and sense-making in the visualisation. What modalities and techniques are used to navigate the visualisation? Can the visualisation be searched or filtered? What aspects of the display can be manipulated? 
“Technology/platform” is the most pragmatic branch to evaluate and looks at the technical implementation of the digital timeline. Is it a standalone tool or a web-based application? Does it rely on standard libraries or is it coded largely from scratch? 
I will comment on the specific insights that these criteria facilitated at the end of this chapter.

Static Timelines
Static timelines include all digital chronographics that ofer no additional level of interactivity beyond that provided by their medium. When a digital artefact is interactive, we expect it to change appropriately as a result of an input that a user executes through an input device, such as a mouse, a touch screen or a keyboard. We might implicitly understand the concept of interactivity, which nevertheless leaves a lot of room for interpretation and differences in definitions (Smuts 2009). Manovich argues that the term is meaningless in digital media because, as he states, “once an object is represented in a computer, it automatically becomes interactive” (2001). Here, I use the term simply to separate static timelines that offer no interactivity on their own – except, what Manovich refers to, through the browser or other software that is required to view them – from other digital timelines. 
The timeline I will focus on most here has in fact been published in print, in addition to being accessible as a digital image. I nevertheless treat it as an example of a digital timeline as it has been created with digital means and exhibits some of the problems that are typical for digitally generated timelines. It is a piece by Accurat, an Italian design studio specialised in data driven media design. Their portfolio includes a variety of timeline based works, of which I want to take a closer look at a particular visualisation that features a reoccurring topic throughout the history of visual timelines: the rise and fall of empires. Like Barbeau de la Bruyere’s Mappe-Monde (1750b), and other historic examples such as Friedrich Strass’s Strom der Zeiten (1804) or John Spark’s Histomap (1931), Accurat’s The empire strikes back (Beltramin et al. 2012, reproduced in Figure 3.3) plots the reigning period of a selection of the world’s greatest empires. I have chosen this particular visualisation as a representative example of a static digital timeline as it employs a prevalent – if not the de facto standard – timeline layout. 
Each empire is drawn as a rectangular bar, positioned horizontally on a linear time axis according to its year of rise and extending widthwise according to its duration. Typically in this timeline format, each bar would be of equal height, but in this particular example, the height encodes an additional dimension of the dataset. Each bar is scaled vertically in proportion to the maximum geographic expansion of the empire it represents. A yellow vertical line indicates the date of maximum expansion. The vertical order of the empires follow their date of fall, putting them in almost sequential order. A detailed legend on the left informs the viewer of the data that is represented graphically and gives an impression of the richness of the underlying dataset.
Before I look at the details of what this visualisation can tell us and what could be improved, I want to highlight an aspect in its layout that applies to a lot of similar timelines. 
This particular layout has its roots in Karol Adamiecki’s harmonogram (Marsh 1974), better known today as Gantt chart (Figure 3.4), after Henry Gantt (1919) who popularised the use of this chart in the early 1900s. Gantt charts are a common format for planning and visualising the scheduling of tasks using a tabular format. Columns typically represent units of time, such as days or weeks, while rows represent individual tasks, ordered vertically in sequence of their planned completion. Shaded cells indicate the time and duration of a particular task. In a Gantt chart time proceeds horizontally and the vertical axis contains categorical information – the name of each task or group of tasks. In Accurat’s timeline, the vertical ordering is not used to show an independent dimension of the dataset. Both the horizontal axis as well as the vertical ordering of the chart represent temporal information: calendrical date of rise on the horizontal and sequence of fall in relation to the other empires on the vertical. 
The strong correlation of these two temporal axes results in the apparent downwards sloping of the entire layout: a clear pattern, but one that is a result of the chosen layout and not a pattern that is present in the dataset. This effect is recognisable in many mechanically generated timelines. Automatically generating a timeline’s visual layout is not a trivial task; having each record occupy a separate row, like in a Gantt chart, is a possible solution that can be implemented relatively easily. 
Although the authors have clearly thought about their chosen layout – otherwise they would not have explained it in the legend – the decision to adopt a Gantt-like arrangement might have been more of a pragmatic than an optimal choice. While the height of the empires corresponds to aspects of the underlying dataset, their vertical positioning carries no meaning in this regard, but solely depends on the number of chosen empires that precedes them. When looking at the representation of the entire dataset, the overall shape the individual bars form does not reveal any insightful patterns.
A digital predecessor of Accurat’s visualisation can be identified in Edward Lee’s History’s Largest Empires (2011, Figure 3.5). This timeline bears a striking resemblance to Accurat’s visualisation and is very likely to have informed it. Lee’s timeline offers the ability to change the horizontal positioning of the bars, aligning them all by their beginnings or according to their date of maximum expansion. Here we are able, for example, to compare the relative duration of each empire, while still retaining their temporal order encoded in the vertical arrangement. 
In Accurat’s timeline, we can look at individual empires and in some cases, through an S-shaped dotted line, follow consecutive empires (Figure 3.6). Analysing overall patterns or judging the temporal distance of one empire to another, however, is not something the visualisation affords easily. The vertical arrangement of the empires could have profited from more deliberation. Using the vertical position for geographical categorisation might have been an obvious choice, making it easier to see how empires that occupied similar territories progressed through time rather than causing empires that are close in geographical space, but distant in time to be spread out across the chart. 
We can see how Barbeau de la Bruyère has identified, and indeed addressed this problem in his Mappe-Monde (1750b - Figure 2.7 on page 55). Bruyère is aware of the consequences of representing geographical space on a one-dimensional axis. He therefore selected neighbouring countries based on their shared borders as well as their relationship and shared history (Barbeau de la Bruyère 1750a, p.19) and made use of colour shading to indicate the coherence of empires that are graphically separated. 
Time is indicated as vertical axis on the left and right edge, with horizontal lines spanning across the chart. The time axis is non-uniform, using a condensed time scale for the distant past, which makes the horizontal separation slightly misleading – equal distances do not represent equal time periods across the chart. I will revisit the subject of uniform and non-uniform scalings of time axes later on. A double line marks the beginning of the Christian Era, the uniform reference point for counting time which Bruyère notes is “preferable to the method of counting from the Creation of the World” (Barbeau de la Bruyère 1750a, p.6). 
As Boyd Davis (2015a), points out we are essentially faced with a coordinate space: the vertical and horizontal position as well as the width and height of the plotted empires carry significance. In contrast to the two digital timelines discussed above, we can also see how the extent of individual empires changes over time and how the same geographical regions have been governed by different rulers. 
Every point in this chart therefore carries significance which, as Bruyère points out, logically follows from the fact that every represented country has been inhabited at all times. This is a level of consistency in the mapping of data to graphical space that we may not always find in timeline visualisations. Nevertheless, it is something we should strive for in digital timelines or at least – as Bruyère does as well – reflect on the implications and limitations of a chosen layout. Bruyère created his chart, of course, without the help of digital tools. Nevertheless its rectified, diagrammatic appearance in principle lends itself to be generated mechanically and difers from similar charts produced around the same time that made use of more rhetorical graphical devices – for example rivers to represent the history and convergence of diferent empires (Rosenberg & Grafton 2010). 
Accurat’s Empire timeline, as well as other examples from their portfolio which I will discuss later, are some of the most thoughtfully designed timelines that have been made recently – the great care for detail is evident in the richness of the represented data and the meticulous explanation of the visual parameters provided in the legend. The problems I have outlined are mainly a result of the algorithmic production of the timeline layout. Diagrams, whether constructed manually or mechanically, may never be able to escape the danger of patterns being misunderstood. However, if the representation can be manipulated, such as in Lee’s (2011) example, it might be possible to allow viewers to question a pattern and examine diferent ways of mapping a dataset along time.

Dynamic Timelines
Dynamic timelines can be characterised as static timelines with the addition of certain interactive features that, ideally, benefit their use as scholarly research devices. The online editions of the New York Times (NYT) and The Guardian feature a number of digital timelines that I consider to be dynamic based on the features that they offer to navigate the visualisation. Online journalism offers a rich source of dynamic timelines, although there has recently been a decline in favour of more slide-show based formats – possibly due to the unsuitability of most implementations for mobile devices. My selection here does not include any scholarly examples – these will follow soon – mostly because interactive timelines for research purposes tend to include more advanced interactive features. However, the argument here is that even evidently simple modes of interactivity – such as presenting detail information in a tooltip – can support the use of visual timelines as research tools. 
A variety of dynamic timelines have been developed by the team at the New York Times (Belopotosky et al. 2011; Delvisicio et al. 2013; Andrews & Parlapiano 2014; Clark & Bilefsky 2015 – Figures 3.7–3.9). They each seem to have been intended as reusable visualisations – their code is modular – nevertheless most of them only ever appear once and only a few of them have been used to visualise a variety of datasets. This diversity of timelines appears to be primarily a consequence of progressing web technology: more recent implementations make use of the latest technology available at their time as well as more image and video based data sources. The visual rhetoric of the different timelines as well as their technical capabilities on the other hand have not changed significantly. 
Events are represented as dots (Delvisicio et al. 2013; Andrews & Parlapiano 2014) or dashes (Belopotosky et al. 2011) and arranged from left to right on a horizontal time axis, forming a one-dimensional timeline visualisation. Buttons enable a step-by-step navigation, emphasising the chronological sequence of the events. This sequential navigation can also be helpful in more ‘busy’ periods, where events tend to overlap. In one of the earlier timelines (Belopotosky et al. 2011, Figure 3.8) it is possible to adjust the scaling of the time axis via zoom buttons which makes it easier to examine busy period – a feature which is not present anymore in later examples of NYT-timelines.
The user is able to interact with the event representations by using the mouse to hover over or click them. These limited, even seemingly trivial ways of interacting with the display ofer a significant advantage over static visualisations by allowing access to secondary information on demand and – more crucially for the use as analytical tools – the original source of the visually represented data. 
In one example, A History of the C.I.A.’s Secret Interrogation Program (Andrews & Parlapiano 2014, Figure 3.9), the NYT departs from the one-dimensional timeline format. The vertical dimension is used to denote the category of different events related to the uncovering of the contentious interrogation methods practiced by the CIA. This enables a viewer to gain a better impression of the complexity and the interrelatedness of events, something which a one-dimensional timeline and indeed an accompanying text or chronology tends to hide in favour of a sequential narrative.
Slightly odd appears the decision to use an individual time axis for every category despite all of them using the same time scale. The multiple timelines, each with its own axis, seems to suggest that either separate courses of events are visualised using different timescales, or that the timeline in fact flows continuously from one line to the next. 
Inspecting the generated code of the timeline reveals that each category is drawn independently on a separate HTML element. It is quite likely that the timeline was originally intended to depict a single one-dimensional and linear narrative, but was ‘misused’ by a creative editor in order to visualise a more complex story. 
The UK Guardian developed a dynamic timeline that supports mapping more complex courses of events. They have used it to visualise a variety of topics, such as the Middle East protests (Blight et al. 2012, Figure 3.10), the UK riots (Blight et al. 2011) or the Eurozone crisis (Mead & Blight 2014). Running on Adobe Flash, a technology not available on Apple mobile devices, its use declined with growing mobile access to the Guardian website. 
Events, corresponding to newspaper articles are assigned different categories and represented by colour coded icons. All icons are arranged on individual bands according to their geographic region. Unlike the columns in Bruyère’s Mappe-Monde, the bands are sorted not by geographical distance, but alphabetically – presumably a pragmatic decision to allow the arrangement to be more easily generated automatically. Together, the bands form a timeline which extends in a perspectival projection from the virtual viewpoint of the user into the screen, curving upwards as it proceeds into the future.
The perspectival curvature in the timeline is quite untypical, yet effective in several ways. First of all it allows a user to better see the distribution of events in the future, which would otherwise be hidden behind each other would the timeline simply continue straight. Secondly, a kind of subjectivity is introduced by the use of the first-person perspective, locating the viewer ‘within’ the course of events and, perhaps, communicating that one is not looking at a neutral representation of history, but at one particular viewpoint thereof – see also Boyd Davis (2009).
Such spatial representations, with time moving from the present into distant space can be traced back to Emma Willard’s Temple of Time published in 1846 (Figure 3.11). Kullberg and Mitchell (1995) as well as Korallo et al. (2012) have studied the effects of three-dimensional renderings of digital timelines and both argue for an increase in information recall as a result of the 3D rendering. In the wider discussion of best-practices in data visualisation however, the use of ‘unnecessary’ or faux 3D – extra dimensions that are not used to show additional data – is generally discouraged (Shneiderman 2003; Few 2007) and experimental studies found its effect on readability to be adverse (Zacks et al. 1998; Cockburn & McKenzie 2002; Hicks et al. 2003), or to be dependent on the implementation and task at hand on (Levy et al. 1996; Wiss et al. 1998; Risden et al. 2000; Smallman et al. 2001). 
In the Guardian timeline we are able to navigate through time by dragging a horizontal slider at the top of the visualisation or by manipulating a prominently placed handle which causes the visualisation to move forward or backward through time, like a train on tracks. Hovering over an icon highlights the corresponding band and presents a preview of the newspaper article, which can be accessed with a click of the mouse. 
With respect to the qualities as a tool for visual analysis there are a few things worth highlighting in the Guardian timelines. The upwards curving of the bands allows us to make out patterns in the dataset, albeit only over a few weeks into the future. The past moves out of view as we navigate the visualisation and an overview of the entire dataset is not available. 
In contrast to the NYT timelines, all records are representative of news articles, hence the provenance of the records is transparent and can be traced back to their source. However, we do not know whether the dataset is complete, if in fact all relevant articles are represented or if the dataset has been curated. We also need to trust the authors on the classification of the nature and geographic region of the events, which might be biased both subjectively as well as through the visualisation, which does not accommodate for events occupying several categories or locations. 
An important observation which is not unique to this implementation, is that we are not looking at a “timeline of Middle East protests”, but at a timeline of reports about the Middle East protests. What is represented are not the protests themselves, but data about the protests – a seemingly obvious distinction, but one that is often overlooked. Even Priestley, usually remarkably conscious of the relationship between data and display falls into this trap, making no distinction between lack of data and lack of events in one part of his interpretation: The thin and void places in the chart are, in fact, not less instructive than the most crowded, in giving us an idea of the great interruptions of science, and the intervals at which it has flourished. (Priestley 1764, p.24).
We have seen how already limited functionality can be helpful for analysing datasets through visualisation by providing detail on demand, maintaining provenance to the underlying data, and offering different views on a dataset by allowing users to manipulate the domain and scaling of the time axis. 
There are a few ways of manipulating the display that one might expect, but which are not supported by the Guardian timeline. It is not possible to select a geographic region and have all the corresponding events highlighted, nor is it possible to highlight or filter the data based on a category. Labels and legends act purely as output devices and do not, as Ahlberg and Shneiderman (1994) recommend, double as user interface elements. 
This lack of ways for manipulating the display make this visualisation fall short of a truly exploratory timeline, although one can easily imagine such functionality being added. Part of the purpose of discussing examples along this spectrum is precisely to identify how we can push timeline visualisations further.

Exploratory Timelines
Exploratory timelines allow for a greater level of engagement with a visualisation than dynamic timelines, by providing additional interfaces for manipulating the data and its visual representation. The term refers to Tukey’s (1977) proposition for exploratory data analysis (EDA). EDA outlines a working method with datasets which is not primarily aimed at confirming predefined hypotheses. Instead, datasets should be approached with an open mind and hypotheses formulated based on observations of the datasets, not prior knowledge. Tukey describes and introduces a number of graphical techniques, suggesting that visualisation may be an ideal method for EDA. Pousman et al. see exploratory analysis as an essential prerequisite for visual analysis: Analytic insights come from exploratory analysis, extrapolation, and consist in the large or small eureka moments where a body of data comes into focus for a user. (2007) 
While my selection of dynamic timelines originates from the field of journalism, we increasingly see explorative timelines appearing as part of, or even constituting scholarly publications.
Kindred Britain (Jenkins et al. 2013, Figure 3.12) has been developed by the Stanford University Libraries and visualises a detailed dataset of nearly “30,000 individuals – many of them iconic figures in British culture” (Jenkins et al. 2013). The timeline visualisation forms one of three visual layouts through which the dataset can be examined – the other two are based on a network visualisation and a geographic map. 
Time is plotted linearly from left to right and records are represented as dots, signifying individual events, and bands for visualising the period of individual’s lifetimes. Zooming out of the timeline hides the dots, leaving only the bars; an interaction paradigm known as ‘semantic zooming’ which adjusts the graphical representation based on the zoom level, in this case, by removing less relevant data.
The vertical arrangement follows largely the temporal sequence of events. Bars are moved to the top where gaps would otherwise appear, resulting in a more condensed layout, but also in unrelated events appearing on the same row. Similar layouts are often used in both analogue and digital timelines in order to arrive at a more spacesaving display than a Gantt-like timeline. Elijah Meeks later released the timeline component of Kindred Britain as a standalone D3 layout (Figure 3.13) and it quickly attracted the attention – and prompt rejection – of fellow developer Ethan Jewett, who works on the Palladio project. His critique was that the algorithm reacts with drastic changes in the layout even when the data only changes minimally, making him go back to “a sort of ‘step’ layout” – a Gantt-like chart.
Despite my reservations about the Gantt-layout, we see how a pragmatic space-saving layout may be even more problematic for scholarly analysis. In a Gantt-like layout the vertical position of an item is determined by the ones that precede it; a behaviour that is transparent and predictable. Space-saving algorithms are influenced by numerous factors, such as the temporal distribution of all events in the dataset, the graphical space available and the inner workings of the layout algorithm: factors that are unpredictable and opaque, not exactly the hallmarks of a scholarly research tool.
In the Kindred Britain visualisation, only 74 events are visible at any one time, allowing only a tiny fraction of the entire dataset to be examined on the timeline. It is very likely that a low number of records is visualised partly for performance reasons, partly because the focus of the visualisation is in the comparison of only a few individuals. Why we are presented exactly with this number of records and on which basis they are chosen remains undisclosed. 
If we do select one or two individuals for comparison, the timeline gains vertical bars that denote family relations between individuals through marriage or birth. We are in fact presented with a hybrid visualisation that represents both temporal and hierarchical network data. Unlike the network view that connects events through thin lines, the timeline uses bars of the same width as the events to indicate relationships. This graphical equivalence between events and connections is rather unusual when compared to similar examples that visualise hierarchical network data on a single time axis (Card et al. 2006; André et al. 2007; McClure 2014; Müller et al. 2015). 
The exploratory timeline allows for insights which were not all anticipated by the designer of the visualisation: Kindred Britain is also not about supplying definitive answers. Instead, on a broad foundation of historical fact, it deploys modern computational methods to suggest possibilities, metaphors, ideas about Britain, about its subjects and its culture. (Jenkins 2013). 
Exploratory features do not rule out the presence of narrative elements. Kindred Britain contains suggestions for comparisons, as well as a number of essays. Periscopic’s timeline visualisation U.S. Gun Deaths (Periscopic 2013, Figure 3.14), a different example of an exploratory timeline, begins with a text-based narration explaining how an individual person killed by a gun in the US is represented as an arc on the timeline, slowly building up the entire visualisation of all gun deaths in a particular year. Detailed filtering options then enable a viewer to dissect the dataset and make comparisons. This is in line with an observation made by Boonstra et al.: The difference between explorative visual data analysis and visual presentation is small, however. Similar tools can be used in both ways: if a special technique allows researchers to explore and interpret their data well, it will serve as a means to present their data efciently as well. (2004, p.73) 
At first sight, this visualisation uses a familiar timeline format, with events being plotted on a horizontal time axis running from left to right, except for the arcs that extend above it. Looking at the temporal description of individual records, we notice that each record is mapped using three temporal descriptions: the year of birth, the year of death, and the hypothetical year of death if the individual had died of natural causes. To make comparisons easier, the data is normalised and arranged by age. 
Unfortunately, the arc rendering of the events and the over-plotting caused by the relatively large number of records visualised (ca. 10,000) turns out to be uninformative. As an alternative view to the timeline display, the data may also be visualised as a set of two histograms representing the distribution of the actual and potential lifespans of the victims. In this quantitative view we can often spot patterns which the arc-layout tends to hide. For example, white southwestern victims account for 14% of the deaths, which corresponds to the graphical proportion of the histogram above the timeline. In the timeline view however, the top set of arcs only looks slightly smaller than the bottom one. We also fail to spot temporal patterns in the timeline visualisation that are apparent in the histogram, such as the extent and ages of peaks. Representing a large number of items individually on a timeline in a meaningful way is a challenge which we will see recur. 
Exploratory timelines that are built around specifically curated datasets allow for the inclusion of rich background information, stories and customised interactive features. Kindred Britain makes full use of this by turning to visualisation as a way to convey the complexity of the data. It does represent a humanities research output – the ‘traditional’ scholarly work has been done by Nicholas Jenkins, accumulating the genealogical data on the represented individuals. But instead of capturing the knowledge he gained in a paper or a book, he collaborated with developers Elijah Meeks, Karl Grossner and Scott Murray to create an interactive visualisation that allows others to make sense of the data. 
Both examples show how an exploratory timeline may enable different perspectives on a dataset and allow various narratives to unfold. They also show how a single dataset allows for various insights, merely by manipulating it using a custom interface. This is maybe one of the most powerful abilities of visualisation – to facilitate interpretation – but it also makes evident the need for transparency in the visualisation process.

Open Timelines
Open timelines should allow for custom datasets to be visualised and explored so that the visualisation can truly serve as a research tool. Such software is crucial for scholarly research in Digital Humanities as only when both the tools and the examined datasets are open, can we produce reliable and verifiable insights. As Borgman writes: Until analytical tools and services are more sophisticated, robust, transparent, and easy to use […], it will be difficult to attract a broad base of interest within the humanities community. (2009 §5). 
Open timelines, on the spectrum that I employ here, satisfy all prerequisites of static, dynamic and exploratory timelines, with the most important addition of added transparency and reusability.
Once again, my selection of projects here is not exhaustive; there are timeline tools I will not discuss that would qualify as open, notably vis.js or Timeline, both open source timelines that support various modes of browsing and searching, but are clearly designed for presenting, rather than analysing data. The timelines I do discuss here all have been designed for the purpose of doing research. 
Continuum (André, Wilson & schraefel 2007; André, Wilson, Russell, et al. 2007, Figure 3.15) is an exceptional timeline tool, not only with regards to the thinking and features it implements, but also in the context of the present selection of tools. Unlike the other examples I discuss, Continuum is not and has never been released. Strictly speaking, it therefore should not be included here, but it would be a gross omission not to discuss it and I will refer to this particular timeline tool later on when I present my own prototype implementations. 
Continuum was developed as a response to the lack of sophisticated and reusable timeline visualisations for data analysis and is conceived as a timeline “for hierarchies, relationships and scale” (André, Wilson, Russell, et al. 2007) – responding specifically to the challenge of visualising large datasets. This is facilitated through a diagram that includes summative histogram views of data within a conventional timeline format. Relationships between individual events can be identified through lines that connect matching entities. This is possible even over a large timeframe as the visualisation implements two separate views of a single timeline, omitting an arbitrary timeframe in between.
A comparative study between Continuum and the SIMILE timeline, which I discuss below, verified the claimed advantage as a visualisation tool to analyse large cultural datasets (André, Wilson & schraefel 2007) – a movie database containing 11,000 records. Despite plans of releasing the tool into the public domain, development of the tool appears to have ceased and it has never been made available. 
This makes TimeFlow (Viégas et al. 2010, Figure 3.16) one of the few publicly available visualisation tools which is dedicated purely to visual analysis of arbitrary data on a timeline. TimeFlow was developed as a “visualisation tool for analysing temporal data” aimed at data journalists. Other data visualisation suites and libraries put a stronger emphasis on non-temporal and quantitative data and most tools dedicated to temporal data tend towards a narrative, rather than analytic use.
The open source Java application accepts datasets in the tabular CSV format via an import screen that automatically assigns one of five types to each field (Number, Date/Time, Text, List or URL). After import, the data is visualised along a horizontal time axis using a “loose” layout where “the vertical location of data points is flexible” (FlowingMedia 2010b). Other supported layouts include a “diagonal” arrangement, which uses sequence of events to determine vertical positioning – starting back at the top when records would fall out of view at the bottom -  and “graph”, essentially an aggregated histogram view. It is possible to group events on horizontal bands and assign colours according to a chosen (text or date) field, as well as map a numeric value to the size of the dot used to represent individual events.
There is no forced limitation on the size of the datasets that may be visualised, but the authors state that a considerable decrease in performance is to be expected with datasets of more than 20,000 rows (FlowingMedia 2010a). While performance did suffer a bit, I had no trouble importing a dataset of almost 70,000 records. Nevertheless, the timeline layouts did no longer prove to be informative when more than a few hundred records were in view. As the display becomes cluttered it is very difficult to distinguish individual events and overall patterns that might be present in the dataset are no longer visible.
SIMILE Timeline (Huynh 2009, Figure 3.17) is arguably one of the timeline tools with the largest user base, partly also because of its integration in other scholarly projects, such as Neatline (Nowviskie et al. 2012; Nowviskie et al. 2013). SIMILE was a project that ran at the MIT from 2003 until 2011 and aimed to develop reusable interactive tools for the presentation and exploration of digital assets. The tools have since been released and are partly developed further as SIMILE Widgets, a collection of open source web based data visualisation tools. SIMILE Timeline’s basic layout is a horizontally scrolling timeline populated either by reading an XML file or by dynamically loading events in the JSON format. This architecture allows the timeline to be manually curated, as well as potentially being generated through an existing dataset. 
The designers have dedicated a remarkable level of consideration to the kind of temporal descriptions the timeline is able to visualise. In contrast to other timelines, which only support singular events and periods, it is possible to include elements of uncertainty by specifying a latest start or earliest end date to events. The appearance of individual events can be further customised and additional information about events can be revealed by clicking on them. In its later versions the tool also allows basic filtering and highlighting based on entered search terms.
Another unique feature is the ability to inflect the time axis by defining periods with a different temporal granularity than the rest of the visualisation. “Hotzones” (SIMILE 2009) are intended to locally zoom in on busy time periods, where events that closely follow each other can otherwise not be discriminated. These distortions have to be predefined and cannot be changed interactively by a user of the timeline. Like most timelines, SIMILE Timeline is primarily intended as a means for telling an authored story, rather than exploring unstructured and potentially large datasets. The last project I’d like to discuss within this section is Palladio (Figure 3.18) by Stanford’s Humanities+Design Lab (2014), an application dedicated to visual analysis of datasets for humanities researchers. Palladio’s origins lie in a research project on the Republic of Letters (Chang et al. 2009), which included an exploratory visualisation tool. The working principles and the insights gained through the development of this tool have been repurposed and made reusable. Palladio is not primarily a timeline visualisation tool – its focus is clearly on network and geographical visualisations. In fact, two dedicated timeline views (titled ‘Time’ and ‘Duration’ – see Figure 3.20) that appeared in a late beta version (Stanford Humanities + Design Lab 2015a) were removed at the release of the final version only a few months later (Stanford Humanities + Design Lab 2015b) – for undisclosed reasons. 
Temporal visualisations have remained in the tool not in the shape of dedicated views, but as interfaces for filtering datasets. The “Timeline” filter generates an aggregated histogram view, which can be grouped by any of the available fields. A conventional timeline visualisation with events represented individually as horizontal lines hides behind the “Timespan” filter. Clicking and dragging anywhere inside these filter views creates a brush, which allows the datasets to be filtered dynamically based on the chosen timeframe.
Both temporal filters employ timeline representations established by Priestley, but in earlier releases of the software we can see how the creators experimented with different ways of visualising temporal events. The timespan filter offers an alternative layout formed of two parallel time axes with events plotted as connections from their beginning dates at the top to their end dates on the bottom axis. This layout was, for a short time, also available as a dedicated view to analyse the dataset. 
A similar layout has been used, for example by Thudt et al. (2012) to explore patterns between the publishing dates of books and their fictional time periods. In Palladio, however, the upper and lower time axis are fixed and synchronised – the time axes can not be scaled or shifted – which makes comparisons across larger timeframes difficult. 
It might indicate a bias which originates from Palladio’s ancestor project that was built around a dataset concerned with individual’s lifespans over a common timeframe. Figure 3.19 is a screenshot of the TimeSpan filter in Palladio set up with one of the datasets I will visualise later on – the works of Benjamin Britten. The dataset contains works with their year of composition as well as associated writers and their birth year. Visualising both dates in Palladios TimeSpan filter scales the entire diagram to the larger timeframe of the writers, losing all detail in the smaller timeframe that the works occupy. 
This raises the question of how far a timeline visualisation can be truly reusable as it is impossible to anticipate every possible use and dataset. It is a question we may not be able to answer, as every implementation exposes new limitations. However, by opening up visualisation tools and making them generalisable, as the creators of Palladio have done, we can not only get closer to such tools, but also learn more about the biases we might unknowingly impose by expecting a certain kind of datasets and by asking certain questions.

Discussion
Before I summarise the main findings of this project review, I briefly summarise how the diferent branches of my criteria tree have mediated my appraisal of the discussed examples and reflect on the implications of my employed spectrum on the definition of a timeline as a visual analytics tool. 

Findings led by Criteria 
The “Data Acquisition and Curation” branch caused me to focus on the ‘expectations’ that a visualisation format may have towards the dataset it visualises. Visualisations that accept custom datasets often only support a very limited set of fields, while examples that are tied to a single dataset suggest that there are many more attributes that might be useful to visualise on a timeline – especially with regards to temporal descriptions as I will outline below. How might a timeline tool be able to make use of all temporal dimensions of a dataset? 
The criteria under “Representation of Dataset” and “Representation of Records” delivered the most useful observations, resulting in the focus issues described below. Distinguishing between how records are represented individually and how they form an overall representation of the dataset, revealed how many timeline visualisations exhibit problems with the latter. Even when great attention is given to the graphical rendering of individual records, as for example in SIMILE, patterns across several records are often unreadable. 
Looking at the examples in terms of “Interaction” has revealed issues that are more relevant for individual implementations than for the class of timelines as a whole. Most timelines are able to provide “details on demand” (Shneiderman 1996). Only few, however, offered the ability to operate on several records, indicating again a lack of focus on the totality of visualised events.
In terms of their “Technology and Platform”, most digital visualisation represented the prevalent state of the art at the time of their creation. Currently, web-based applications or libraries have replaced earlier Java-based standalone software. A development which is beneficial for scholarly research, when it leads to software that is based on open standards and/or open source practices. 

Findings led by spectrum 
I have already indicated that I do not mean to suggest that the fitness of a digital timeline tool for scholarly research and visual analysis automatically follows from the presence of certain interactive features. Still, I would like to highlight some of the technical aspects I have used to distinguish between static, dynamic, explorative and open visualisations on my spectrum which, after reviewing the examples, I think do make a difference. 
Static timelines may be created without any coding experience, but that does not make them necessarily an easier format, as it means having to include all data in one display and deciding on one way of representing a dataset. Dynamic timelines on the other hand may offer different views on a dataset, each highlighting certain aspects. Besides enabling different insights, alternative views may reveal and emphasise that some patterns that are visible in a visualisation may be a side-effect of a particular layout, scaling or graphical representation. 
Even limited interactive features may significantly improve the value of a timeline as a research tool by offering secondary information on demand and by providing links between the graphical representation of data and its original source. Ensuring that the underlying data remains accessible is a key issue in data visualisation (Kasik et al. 2009) as well as in the wider context of Digital Humanities (Flanders & Muñoz 2011). The timelines I have presented as dynamic support this kind of “details on demand” (Shneiderman 1996) and source linkage. 
Individual records may be interrogated as such, but what dynamic timelines fail to offer is a way of asking questions about the dataset in its entirety or about larger groups of records. In exploratory timelines these features include the option to colour records based on specified field values – as in Kindred Britain (Jenkins et al. 2013) – or the ability to select and compare data that fits certain criteria against the remaining dataset – as in U.S. Gun deaths (Periscopic 2013).
Open timelines offer in terms of interactive features not much more than exploratory. Arguably, they may often even be less sophisticated as they cannot take advantage of certain fields that may or may not be present in any particular dataset. They do however feature mechanisms and interface elements required for importing data and assigning fields to graphical dimensions of the visualisation. These make a crucial difference, especially with regards to temporal data. In an open timeline we have to tell the visualisation which field contains the data that governs the position of its graphical representation on the time axis. This leaves us with the option to use a different field than the authors of a tool might have anticipated; for example, to visualise objects by acquisition or cataloguing date, rather than production date. Palladio requires two dates to be selected, expecting that these will represent beginning and end dates of a single event, yet we can also choose dates with no apparent relationship and use the visualisation to examine if we can discover one. When a visualisation functions as a tool, it can not only be used, it may also be productively misused.

Focus Issues
This review of timeline visualisations has offered a snapshot of the diversity of implementations available and their various (interactive) features, which may support a use for visual analytics. It has also uncovered a range of embedded assumptions in the design of timelines and how events should be represented on them, along with the potentially counterproductive effects of adopting particular graphic layouts due to their ease of computational implementation or space-saving properties. 
The main challenge that emerged from my previous studies of the literature is the difficulty of accounting – within timeline visualisation tools – for the uncertainties, biases and subjectivities that are embedded within digital collections as a whole and in date descriptions specifically. Through my examination of implementations of digital timelines and visual analytic tools, I have further refined my analysis and identified practical challenges which will guide my prototype-led explorations. These issues concern the analysis of large scale datasets, the algorithmic generation of appropriate timeline layouts, and the modelling and representation of temporal descriptions in cultural datasets. 

Scale 
Perhaps the most far-reaching consequence of digital technology in the humanities context is an unprecedented increase in the size of collections that historians, archivists and archeologists are able to process: When digital technologies allow for the storage and analysis of millions of books, billions of tweets, and hundreds of billions of interactions, the ways in which we can query and comprehend the cultural record explodes. […] we will have to design and employ new tools to thoughtfully and meaningfully sift through, analyze, visualize, map, and evaluate the deluge of data and cultural material that the digital age has unleashed […] (Lunenfeld et al. 2012, p.38). 
Challenges around visualisations of large datasets are a recurring topic in the data visualisation literature (Lamping & Rao 1996; Fua et al. 1999; Keim 2001; Shneiderman 2008). None of these however focus on visualising large datasets on timelines. In the context of data visualisation time is often treated as “just another dimension” (Kosara et al. 2004), neglecting the differences between time and typical scalar quantities, but also missing out on the opportunities that time might offer for visualisation.
So far, the issue of large datasets in timelines has mainly been addressed in Continuum (André, Wilson, Russell, et al. 2007; André, Wilson & schraefel 2007), whose approach includes a histogram based overview timeline and limiting the number of events in view in the main timeline. Other timelines have implemented both strategies, albeit separately, and I will revisit and build on these approaches in my own prototypes. 
Large datasets are particularly challenging for timelines. In my own definition I have pointed out that timelines, in contrast to other visualisation formats, do not need to make quantitative summaries of data in order to visually represent it. Events can be studied individually and being able to examine the temporal position, succession and relationship of single events is one of the main benefits of graphical timelines. 
However maintaining individual representations of events creates problems when large numbers have to be visualised in a small amount of graphical space: a common problem of the timeline visualisations that I have reviewed here is their inability to handle large datasets elegantly, resulting in cluttered and unreadable displays. The challenge is therefore to either develop a suitable layout that maintains readability of individual events or to find a suitable way of summarising events on a timeline – which could be a histogram or a novel diagram format.

Layout
The issue of large datasets is intrinsically linked to the challenges around timeline layouts. In the digital realm, timelines are often understood literally as lines. Time is not only treated as a one-dimensional mathematical space but also represented as such graphically, as is visible in the timelines by the NYT as well as the work by Periscopic. This circumvents a problem I have hinted at in my discussion of Accurat’s Empires timeline: the significance of the orthogonal graphical dimension. 
Bruyère (1750a) underlines how every point in his chart carries significance due to the respective mapping of geographical and temporal dimensions to the horizontal and vertical axes of the graphical space. The Guardian timeline similarly uses the non-temporal axis to indicate the geographical region of an event. In these examples, the position of a record map on to a field value. This, however is not always the case in graphical timelines that visualise records on more than one graphical dimension – timeline layouts often are non-deterministic. 
A scatter plot is a deterministic visualisation layout – the position of every graphical representation of a record forms an arithmetic relationship with the data being visualised. In non-deterministic layouts, there can be many factors that influence the position of a mark, such as the content and structure of the dataset, the size of the visualisation, the chosen layout algorithms as well as randomness.
For network visualisations, a number of different and clearly defined deterministic and non-deterministic layouts exist and their effects and merits are widely discussed (Fruchterman & Reingold 1991; Golbeck & Mutton 2006; Martin et al. 2011; Krzywinski et al. 2012). As Krzywinski et al. write: Network layouts are difficult to predict and interpret because their creation is in part, driven by an aesthetic heuristic that can influence how specific structures are rendered. (2012, p.2). 
In addition, the same layout can produce significantly different visualisations even when the dataset has only been changed slightly: Most algorithms are sensitive to small changes in the network and create perceptually nonuniform layouts, where differences vary out of proportion to changes in the network. (Krzywinski et al. 2012, p.2).
Although timeline visualisations face very similar challenges, these are generally not discussed and the issue of timeline layouts are not addressed outside very specific implementations. 
The mechanisms used to generate the visual layout of a timeline affect not only the position of individual records, but the overall visual appearance and our likelihood of spotting patterns and connections among items that appear close together. When the arrangement of items on the non-temporal axis is arbitrary or undisclosed, the relevance of the position and distance between items on that axis becomes meaningless and overall patterns may be misinterpreted.
Priestley exploited this flexibility in arrangements that the timeline affords by “placing those persons the nearest together who had the most connections, and whom I thought it would be most amusing to compare together” (Priestley 1764, p.19). He could rely on his individual judgement to do so, which digital timelines that are generated through software are unable to do. We therefore need to develop timeline layouts that can be generated automatically and are readable, comprehensible, and robust against changes in the dataset or display size.

Temporal Descriptions
At first sight it appears as if we are mainly faced with two kinds of temporal descriptions in digital timelines: single events and time periods. Single events are defined by a unique date and tend to be graphically represented as dots (Huynh 2009; Viégas et al. 2010; Delvisicio et al. 2013; Jenkins et al. 2013; Andrews & Parlapiano 2014), dashes (Belopotosky et al. 2011), or icons (Blight et al. 2012). Periods on the other hand consist of two dates, beginning and end dates and are rendered as bands (Huynh 2009; Lee 2011; Beltramin et al. 2012; Jenkins et al. 2013; Stanford Humanities + Design Lab 2014). 
Only a few examples make use of different event formats. US Gun Deaths (Periscopic 2013) maps three dates per event – birth, actual death and hypothetical death. Accurat’s (Beltramin et al. 2012) and Lee’s (2011) timeline visualise empires as periods with beginnings and ends, as well as an additional third date representing the date of maximum expansion. SIMILE timeline even supports four dates per event (period), equivalent to the quadruple proposed by Kauppinen et al. (2010) for describing imprecise temporal information in cultural heritage data: earliest start, latest start, earliest end and latest end. SIMILE however only uses these description for the graphical rendering; they remain inaccessible when interacting with the visualisation. In Lee’s interactive timeline we are, to a certain extent, able to pick the date that determines the spatial arrangement, allowing for comparisons in sequence, total duration and durations before and after peak date. 
The presented examples employ multiple date descriptions either to express uncertainty or to provide secondary information. I am interested in exploring both types of date multiplicities. Digital timelines predominantly treat events as singular occurrences in time, ignoring the uncertainties and multiplicities in dating that might be associated with real events. Born-digital data reinforces this practice by carrying a unique timestamp marking its creation. Historically, temporal diagrams have not only been used to analyse and understand the ‘actual’ chronology of events, but also to examine and compare the variety of possible accounts of chronology – for example Lenglet du Fresnoy’s Tables Chronologiques discussed in Boyd Davis (2015b).
Cultural data such as digital collections, and any other authored datasets, may have a multitude of known and unknown relevant dates which would lend themselves to be explored through visualisation. The question is, how can a timeline make use of different temporal descriptions? What kind of insights could be enabled by timeline visualisations that do so?

Chapter 4 : Prototypes

Building on the theoretical and methodological groundwork established in the previous chapters, I here present how I respond to the specified focus issues through making and evaluating prototype visualisations. They lead me to refine the challenges and finally derive a set of principles for the design of timeline visualisation tools for visual analysis of digital collections. 
The prototypes were evaluated primarily through critical reflection and discussion with expert users. In cases where I published initial results online, comments from other scholars in the form of peer critique further helped me in evaluating my prototypes. 
Prototype 6 (P6) is evaluated through a controlled user study – see page 155. Initially I expected this to be the preferred method to ultimately evaluate my research output. However I found that this method did not perform as expected in answering my research questions. The discussion of P6 includes a summary of the user testing procedure and my reasons for refraining from further controlled user studies. The practical work I discuss here developed alongside the theoretical enquiries that I presented earlier. Making, in the form of sketches on paper as well as with code, studies of different forms of visuals, interaction paradigms and algorithms up to the design of fully fledged visualisation tools took place throughout the course of my research. 
In retrospect, I can identify three stages in my process. My very first experiments were driven by a ‘scientific’ enquiry into specified research questions through prototypes that modelled and addressed isolated problems. From there I soon progressed to a more data-driven approach, working closely with existing cultural collections. Finally, collaborating with experts in museums, archives and libraries, enabled me to gain a better understanding of how timeline visualisations are able to address the experts’ specific research questions along with how they translate to knowledge production in the context of digital collections more broadly. 
Here I will discuss eight prototype iterations that each address some or all of the focus issues by implementing candidate solutions and build on each other by following leads that arose in previous prototype iterations. Each presentation of a prototype is followed by a discussion of the insights that it enabled and an appraisal of the successful elements that are developed further, as well as their drawbacks and failures that are to be tackled or avoided.

Prototype 1 - Metaballs

Process
My awareness of the challenges posed by timeline visualisations for large datasets initially led me to focus on clustering algorithms. Clustering techniques are used in data analysis to identify groups of records that share a similarity based on set parameters. When applied to visualisation, clustering may be used to summarise several records with one graphical representation in order to minimise the number of elements drawn on the screen, hence reducing complexity and improving readability in visualisations of large datasets. Clustering algorithms have been developed for timelines of photo collections (Huynh et al. 2005) and documents more broadly (Alonso et al. 2009). Some scholars (Goldstein & Roth 1994; Chuah 1998; Fredrikson et al. 1999; Tang & Shneiderman 2001) prefer to speak of ‘aggregation’ in order to discriminate between the visual efect of records accidentally clustering together due to their proximity in a visualisation and the computational method of intentionally summarising groups of data into a single representation. The term aggregation however is similarly ambiguous in the data visualisation context due to its relation to data retrieval, but I will use both terms to refer to the deliberate visual summarising of data representations. 
I developed a time-based clustering method built around the principle of two-dimensional Metaballs (Blinn 1982). Metaballs are a mathematical technique for producing circular shapes with dropletlike behaviour; entities that are in close proximity of each other merge into a larger shapes, which makes it a useful concept for visual clustering and has already been applied to a variety of datasets (Rilling & Mudur 2002; Müller et al. 2007). Admittedly, my decision of adopting this principle was not a purely rational choice. Rather it was heavily influenced by an example script I used to get acquainted with the JavaScript drawing framework Paper.js (Lehni & Puckey 2011); such accidental influences are perhaps typical of a research project that follows an applied, rather than an idealised model. After a few iterations of tryout visualisations (Figure 4.1), the concept resulted in a prototype application which allowed users to explore the collection of the Gefrye Museum based on given search terms (Figure 4.2). Two clustering methods are at play in this prototype. The Metaball clustering summarises records that are close in time by production date on a horizontal time axis according to a threshold, which the user may adjust via a slider. A second clustering method organises the presented records according to their dominant categories and arranges them by category vertically, starting with the category that contains the most items. 
I abandoned the Metaball concept after this prototype because the resulting visualisation did not have the desired effect when applied to this particular cultural collection. In my model tryouts I used randomly generated data with a relatively even distribution throughout time. The Gefrye collection – and most other collections I have worked with so far – display an uneven temporal distribution. Gefrye’s dataset causes my prototype to overly exaggerate the data in more recent time periods, while earlier items are hardly visible. 
The same would probably happen with any dataset of historic events and it is the consequence of adhering to a strictly linear time scale. The left-most part of Barbeau-Dubourg’s 16.5 metre long chronography are almost empty, with the right end of it crammed full of data (Boyd Davis 2016b).

Insights

Dynamic Aggregations
The metaphor of drops of liquid combining and separating made the process of clustering transparent and comprehensible, besides producing a pleasing visual efect – according to casual user trials. In addition, the process worked seamlessly, allowing me to move between representing records individually and as parts of progressively larger clusters. Shneiderman (2008) calls these two ways of looking at a dataset ‘atomic’ views and ‘aggregations’. He specifically recommends including both as separate views in visualisation tools for large datasets in order to be able to examine datasets as a whole in the aggregated view and smaller selections in atomic views. TimeFlow (Viégas et al. 2010) applies this technique in a timeline by using a histogram in the overview timeline when datasets exceed a certain size (Figure 4.3). Continuum (André, Wilson, Russell, et al. 2007) follows a similar approach, while the widely used SIMILE Timeline (Huynh 2009) does implement two separate views for overview and detail, but uses atomic representations for both. 
What I found intriguing in my prototype is the ability to use the same visual paradigm for both atomic and aggregated views, in a single display, including the ability to seamlessly transition between the two. The ‘liquid’ metaphor could aid in understanding how the aggregated view is constructed. Histograms on the other hand may be less readable for unaccustomed users. Such a proposition would however have to be verified.

Automated Curating 
My prototype automatically assigns a category for every record. In this specific case, it is chosen from the website keywords curators have assigned to individual records. A single record may have several keywords, which is why the prototype implementation gives preference to the one that is most frequently present in all the records currently displayed. Searching for ‘wood’ results in most records being assigned the ‘seating’ category, causing it to occupy the top row in the visualisation, followed by the remaining categories in decreasing order of frequency. This enables a user to get an impression of the thematic distribution of a selection along with the possibility to spot patterns. We can see how ‘seating’ is present across the entire timespan of the collection, while ‘electric lighting’ evidently only comes into place towards the end of the 19th century. This, or a similar form of ‘automated curation’ could potentially be very useful. 
On the other hand, it could also put a damaging emphasis on dominant themes, causing records in less popular categories to disappear from sight. The ‘long tail’ of a collection may inadvertently get suppressed. One also needs to scrutinise the basis of automated curation. Website keywords, as I have used here, may not be the most unbiased of all possible criteria. A curator may have a lot of time and dedication drafting keywords for one item, while others may be neglected. 
Presenting a pre-conditioned display may or may not be desirable for the user. It could appear patronising; users may not be interested in seating at all, for example, yet it gets imposed on them. On the other hand, such a display could equally be engaging, ofering a more accessible entry point for users less familiar with the collection. There are arguments (Whitelaw 2012) as well as evidence (Gorgels 2013; Brenner 2015) in favour of the latter view. These authors however look primarily at engaging external visitors of online collections and not at scholarly uses, which require a more ‘neutral’ display.

Continuing 
How can a timeline visualise heterogenous data without over-emphasising dominant patterns? 
What visual paradigms allow a fluid transition between atomic and aggregate views within a single display?

Prototype 2 - Temporal Projections

Process
Looking for alternative temporal models and descriptions that a timeline could represent I was prompted by Zerubavel (2004), whose writings on sociocultural concepts of time range from illustrated enumerations of temporal visions and narratives that would lend themselves to visualisation – cyclical, tree-shaped, staccato, legato, etc. – to accounts of historical discontinuities introduced through discrepancies between perceived, narrated and historical time, and time as measured by a calendar. A digital timeline could be used to explore such conflicts and counterintuitive correlations. There exists a body of work directed at visualising patient histories (Plaisant et al. 1996; Park & Choi 2012) or for criminal investigations (Plaisant et al. 1996), which includes the development of alternative visual and computational models of time to account for the complexities and ambiguities of narrated events. 
My initial prototypes follow the footsteps of these examples in conceiving novel temporal models to computationally represent diverse accounts of historical time. By considering alternative concepts – non-Newtonian, subjective, relational, branching etc. – my aim was to develop new models that allow timeline tools to exploit and exhibit the complications of time, and, as a result, be more rigorous and honest about the temporal data they represent. I produced a number of diagrams which explored different visual and computational representations of time as well as ways for navigating and manipulating such temporal spaces. 
These include a timeline that could be coiled up, in order to examine cyclical patterns within a linear timeline (Figure 4.4), or one that can be folded (Figure 4.5). I experimented with the possibility of a two dimensional model of time (Figure 4.6) as well as branching time (Figure 4.7). Mapping ambiguous events is enabled by a diagram format where years are projected downwards, creating a singularity at the bottom edge where the time of events is unknown (Figure 4.8).

Insights 
I initially distanced myself consciously from specific datasets in order to explore the topic more freely. However my endeavours towards unconventional and possibly more human notions of time translated poorly to the application in real digital collections. Existing datasets are incompatible with my proposed alternative temporal approaches. Relations, explicit levels of confidence, source identifications, alternatives – information that might have been available to a curator at the time of dating a cultural artefact and necessary qualifiers for supporting richer models of time – are all conflated into numeric date specifications. 
It was crucial therefore, to move my prototyping closer to existing cultural collections and to look at the opportunities for alternative temporal representations that are commonly supported by digital collections. An obvious step, perhaps, but also one that is easier said than done. Technically there were no obstacles in getting access to cultural datasets through my collaboration with System Simulation. Getting permission to use those datasets required the consent of their rights holders, which first had to be negotiated. 

Continuing 
What possibilities for alternative models of time are cultural datasets able to afford?

Prototype 3 - Drawing Uncertainties

Process
After my previous prototypes I moved my endeavours out of the ‘lab’ and closer to the datasets at hand. With regards to my ambitions to allow timelines to use different temporal descriptions, I decided to take a closer look at what we might be able to achieve with the date pairs that are used in digital collections for specifying imprecise temporal information.
Digitally stored descriptions of time imply a certain level of precision through the need to specify discrete times or time frames and by having to match the granularity expected by the database. Date brackets suggest that an event has happened precisely within these boundaries, with equal probability. However unlikely this scenario is, when digital timelines map date boundaries onto precise bars and rectangles, this is what the graphics imply. To represent such data more honestly, their purpose in defining a possible timeframe for an event needs to be taken seriously. A date bracket could signify an event that has happened at some unknown precise date within the date bracket, it could represent an event that is inherently imprecise or it could express a curator’s confidence in a date description. 
Based on these observations I devised a method to computationally model confidence levels from the date descriptions that are available in cultural collections. I have discussed their rationale and working method elsewhere (Kräutli & Boyd Davis 2013) and will only briefly summarise them here, focussing instead on why I later departed from this approach. The idea is based on translating date brackets to probability density functions. These functions are able to calculate a varying level of confidence for any period of time within and outside a specified date bracket, allowing visualisations to render more sophisticated event representations than uniform blocks. The confidence is calculated by the integral of the function over the given period, which means we always need to look at a period of time rather than a point in time. The probability of an event having taken place at a single point in time is always zero, which reflects our intuition of what we are at all able to know about the date of historic events.

Insights 
I developed prototype implementations of my proposed approach, first based on model data (Figure 4.9) and later using the Gefrye dataset (Figure 4.10). I experimented with different visual renderings of the probabilistic events, but did not arrive at a fully convincing solution. I indicated confidence levels by changing the way events are graphically represented; adding elements such as lines to mark confidence intervals, or using shading or opacity to indicate that events are uncertain. This graphical rhetoric has already been proposed by Priestley (1764) and reiterated by Drucker: Edges might be permeable, lines dotted and broken, dots and points vary in size and scale or degree of ambiguity of placement, and so on. (2011b, sec.20) 
On the level of an individual event, these strategies worked well and could be interpreted as an indication of uncertainty. In the timeline visualisation as a whole, they however tended to introduce a bias towards events that have a wider date bracket which, as a result, also occupy a larger area on the time axis. 
What is visible as well are quantisation effects of the dating strategies. Date brackets in the Gefrye dataset are not of arbitrary width, but are defined in regular intervals of often 10 or 25 years – a pattern which could be informative about dating strategies in an institution. 
Perhaps the most crucial observation from attempting to model and render uncertainties in this manner is the danger of implying precision in the imprecision; suggesting that we can derive from the available data exactly how uncertain a specific event is. This might be possible with sensor data, where the imprecision of a reading can be measured; where the unknowns are known. Dates in cultural collections are not meter readings but human crafted inputs whose basis are, as far as the digital data is concerned, unknown: You can talk about time duration with error bars […] or the number of decimal places of significant figures. That’s the standard uncertainty expression for figures. But epochs, dates, are not durations. That’s why we have the problem we have, there’s no way to express it. (C3) 
The problem of temporal uncertainty, and how it is represented in a visualisation, will need further consideration.

Continuing 
How to represent temporal uncertainty in an entire dataset? 
How to represent uncertainty, without implied certainty?

Prototype 4 - First Encounters with Tate

Process
An opportunity to delve into the challenge of visualising large datasets on a timeline presented itself through the Tate and its digital catalogue, which contains data on almost 70,000 items. In an effort towards increasing the accessibility and use of their digital collection, Tate published an export of the metadata of their entire collection of works of art and an additional dataset with tombstone information of 3,500 associated artists on GitHub, a platform normally used by programmers as a collaborative code repository. Tate followed the footsteps of Cooper Hewitt in choosing this fairly unusual publishing method as the “most time- and cost-effective method of releasing data to [the] public for now”.
Being able to download this dataset influenced my perception of a digital collection. Even though I had access to exact copies of archival databases, they still made it difficult to consider a dataset as a single entity, as a whole. In a database, information is scattered across a number of tables and in order to retrieve it, one has to formulate a precise query. Many cultural institutions mirror this paradigm of interacting with a collection online by providing search forms and APIs that return only a limited number of records. On GitHub, it is possible to download an entire digital collection as a single CSV file. 
In principle, one could create a single file export from any database, but this is not something the database paradigm affords – in the Gibsonian (1977) sense. Databases afford partial access, while downloading a file entails that all data is contained within that file. A study conducted by Harper et al. (2013) highlights how users see files as something they can own and manipulate, giving them a sense of control and completeness – both qualities that are useful also for analysing data.
Tate’s degree of popularity quickly gave rise to a range of projects. Researchers built visualisations to look at the different sizes of artworks (Davenport 2013), or the distribution and correlations of assigned topics (Drass 2013), or to map the gender gap in Tate’s art purchases over time (Szpak 2013). 
My own interest lied in getting a sense of the scope and temporal distribution of the collection as a whole, following my endeavours in representing large datasets on a timeline. The prototypes and sketches, which I documented online (Kräutli 2013), were some of the very first anyone ever did with the dataset – a few weeks after Tate published it – therefore one of my visualisations (Figure 4.11) quickly became a poster child for illustrating the potential of visualising the Tate, and collections data more broadly. It has been included in a number of articles on this topic (Simon 2013; Bailey & Pregill 2014; Rodley 2014; Winesmith & Carey 2014). The only problem is, the diagram is misleading. 
Bailey and Pregill describe it as an example […] in which the collection data of the Tate Museum was used to parse the distribution of artworks by the birthdate of artists, with the size of each bubble representing the number of works by that artist in the collection (the vertical position is for visual clarity and has no statistical meaning). (2014) 
What they and many other authors who wrote about the visualisation do not point out is that the visualised collection actually misses its most prominent artist: J.M.W. Turner. For their omission I have but myself to blame as I did not sufficiently indicate Turner’s absence in the visualisation’s caption – a reader needed to follow the reasoning in my writing in order to be aware of it. 
My decision to remove Turner from the diagram was partly for the sake of its visual appearance. When I envisaged the diagram that I hoped would result from mapping the data to bubbles in the described manner, I imagined it as pictured above. Instead, what I was presented with was a much more monotonous representation: a single large blob embedded in a plane of similarly-sized dots (Figure 4.12).
The large circle, positioned around 1800, testifies to the overshadowing dominance of Turner in Tate’s collection, accounting for about 40,000 works, or more than half of the entire art collection. This observation by itself was a surprising insight the visualisation provided and which I later studied more thoroughly. Tate’s second most prominent artist in the collection, George Jones, is present with ‘only’ 1,046 works, or 0.015% of the collection.
As my visualisation uses a linear scale to map number of works to circle size, the unequal distribution of artists makes it impossible to spot any patterns among the non-Turners; all their dots are only a few pixels in size. Removing the singular extreme case of Turner allows for a more diferentiated scaling and gives the diagram more depth, enabling me to see what I wanted to see; the scope and temporal distribution, although no longer of the complete collection. “In a sense he was blocking your view”, a curator later commented, “By taking away the Tate’s chief glory, you got a better idea of their collection” (C11). 

Insights 
My own experience with working with the Tate dataset and the responses that the work received confirm my hypothesis, that timeline visualisations can be an insightful tool for visualising and analysing collections data. Bailey and Pregill comment on my diagram: This simple visualization would be impossible through interpretation of individual collection records themselves, but open data combined with an interested researcher has allowed for the building of a visualization that concisely provides a high level of detail about characteristics of the museum’s collection that would be impossible without the encapsulating power of this chart. (2014) 
They conclude that Visualizing information from the perspective of collection analysis allows curators and collection managers to gain novel insights into the nature of their holdings – insights that facilitate and enhance supporting research uses and imagining new methods of exhibition. (2014)
Simon (2013) takes a more critical stance in discussing Davenport’s (2013) and my own visual interpretation of the Tate dataset. While Simon is excited to see “what surprising things can be visualized and learned from the collections data”, she also points out that “the data is sufciently flawed and idiosyncratic to yield conclusions of questionable value” (Simon 2013). In particular, she proposes to use collections data to explore more “compelling” (ibid.) questions than Davenport’s size comparisons: issues of gender or race of artists, or which works of art may have been loaned out to whom. 
Information on loans constitutes data that most institutions are unwilling or unable to make available to the public, leaving one to speculate what might be hiding in this kind of data. By my own experience of negotiating the use of collections datasets, the main reasons for not sharing (parts of) a dataset are concerns regarding copyright and the security of the physical collection. Loans data, for example, might equip a malicious individual with detailed knowledge about the financial value and physical location of an object. Another reason is the more obscure feeling of insecurity about what one might give away by sharing such data, not knowing what exactly it contains and what it could tell a researcher equipped with the right tools. An unfortunate and vicious cycle, when releasing data to researchers could dismantle such insecurities. 
The other kind of questions Simon proposes may however be answered by the level of detail present in the Tate dataset and in most other available digital collections, given suitable tools that allow all available fields to be used. I would be cautious however to favour – in a visualisation tool – one type of question over seemingly less compelling ones, as even the most benign starting point may lead to surprising insights. 
Simon rightly observes that “the data you have is not always the data you want, but you often don’t know that until you start monkeying with it” (Simon 2013) and when one does so, questions might get answered one did not previously think. Ed Rodley, Associate Director of Integrated Media at Peabody Essex Museum, observes: By giving people access to the collection, you give them the ability to ask questions of the museums’ work that we inside these museums might never think to ask. Florian Kräutli’s visualization of Tate’s collecting history was not only a new way to look at Tate, but also uncovered flaws in how Tate’s collection data were organized […] that a collections manager or information architect could overlook or rationalize. Putting it out in public both surfaced the issue and provided impetus for addressing it. (2014)
In conclusion, producing these visualisations of the Tate dataset at this stage in my research resulted in a number of insights relevant for the progression of my research questions. 

Accounting for Inconsistencies in Collections 
Erasing Turner’s works from the visualisation, as drastic as this intervention might seem from an art historical perspective, was essential for being able to study the distribution of artists in the collection without this extreme case. Filtering is often a necessary, if not indispensable step in exploratory data analysis; progressively excavating new patterns and relationships in a dataset by intentional omission or separation. Visualisation tools need to support such filtering options. 
However, my reasons for omitting Turner were not purely for analytical purposes. I removed his works also in order for my diagram to be visually more lively. I tackled the ‘problem’ by cleaning up the diagram, a ‘satisficing’ (Simon 1997) solution for this individual case, but none that would satisfy my research goals. 
Instead, I have to reflect on how the diagram could be redesigned in order to be able to accommodate such inconsistencies likely to be found in other cultural datasets as well – and likely to produce valuable insights when visualised. Of course, it is not harmful when such diagrams take on a visually pleasing appearance and it is impossible for subjective design choices – in terms of selecting colours, fonts and shapes – to be completely absent in a design-led research process. However, visual appearances should not be the main driver. 

Communicating Completeness 
The version of the visualisation that was publicised is a partial view of Tate’s collection, but one is led to believe – when it is presented detached from its history – that one is actually looking at a representation of the complete collection. This observation is insightful in two respects. First, it is important to be instructive about what a visualisation displays, both in terms of the data as well as the mapping of the data. 
Second, viewers’ expectation that a diagram is a complete representation needs to be taken into account when designing a visualisation. The challenge for my research here is not only to accommodate for large datasets in my timeline visualisations, but to account for a sense of knowing the presence of the complete collection; designing not only for scale, but completeness. This issue was later also evoked by a user study and even for the early chronographers, being able to represent the “complete” history was a recurring ambition (Boyd Davis 2015a).

Continuing 
How can a large dataset be visualised on a timeline as a ‘complete entity’? 
How can biases and inconsistencies not only be revealed, but explored in detail?

Prototype 5 - ChronoZoom
ChronoZoom Hierarchical TimeTree (Figure 4.13) was my winning contribution to the Visualizing Time challenge (Pappas 2014), organised by Visualizing.org and Microsoft Research. The contest invited participants to “use the ChronoZoom APIs and create novel solutions to visualize the entire ChronoZoom dataset” (visualizing.org 2013). ChronoZoom is an interactive visual timeline that enables users to explore Big History, the history from the Big Bang up to our present time. 
Strictly speaking, the ChronoZoom dataset does not exactly qualify as a digital collection. When I began the ChronoZoom project I saw it as an aside to my ‘actual’ research endeavours. I mainly chose to participate in the contest because the description stated unsolved problems in timeline visualisations very similar to the ones I identified as well: challenges that are only rarely discussed and addressed in visualisation research and practice.
The original ChronoZoom is both a timeline interface and a dataset that contains all the events and histories that make up the timeline – the dataset can also be accessed separately from the visual interface. As the dataset grew in size, it became difficult to explore using the current interface. How to design a novel timeline interface that enables large datasets to be visualised is a challenge the developers of ChronoZoom faced as well, as they outline in their contest description: There are currently about 7,000 content items in the default Big History dataset and we anticipate many more. It is crucial for users to be able to get a clear overview as they begin to browse this data. […] [Contest] entries should aim to make timelines and related content more clear at a high level. (visualizing.org 2013).
Their brief specifically asks for clarity at “high level” in alignment with my own observations that visual timelines often fall short on providing an overview of a complete dataset. 
ChronoZoom’s content items are defined as a set of nested timelines all contained by the root, the Cosmos timeline. Within the Cosmos timeline we can find the history of the Earth & Solar System and in there the history of Life down to finer grained histories even of the Microsoft Corporation. In the original ChronoZoom interface, these nested timelines are drawn, not as bars, but as rectangles, within rectangles, within rectangles – forcing each graphical timeline to be tall enough to accommodate all of its children. This produced the difficulties the ChronoZoom developers faced as the dataset grew larger: When viewing “humanity” for example, it should be easy to see quickly the names of a reasonable number of visible timeline titles. When viewing the “Industrial Revolution”, the timeline is unnaturally very tall due to the large number of parallel items. (visualizing.org 2013) 
To solve this problem I developed a timeline layout that is a hybrid between a common Gantt-like timeline, with events represented as horizontal bars, and a collapsible folder tree: timelines are drawn, not within, but below each other with dependencies indicated through connected lines and additionally through colour coding (Figure 4.14). I have elsewhere provided a more thorough description of the project (Kräutli 2014b) and its technical details (Kräutli 2014a).

Insights
Abstraction 
My immediate insight from this project was on the relationship between the structure of the dataset and its visual representation. Manovich (2011, p.13) argues for the benefits of “direct visualisation”: the reorganisation of data “into a new visual representation that preserves its original form” (Manovich 2011, p.13). I am highly critical of this view, first of all because digital data does not have any inherent visual appearance or “form” to begin with – any data visualisation is necessarily an act of interpretation. Secondly, for the reason that my prototype offers a better overview of the dataset than the original ChronoZoom: precisely by not graphically mimicking the data structure of nested timelines and instead adopting an abstracted visual representation of implied hierarchy. An increased level of abstraction, even when it means moving away from ‘reality’, can allow for better sense-making and understanding; a simplified topographic map may be a more useful orientation device than a detailed aerial photograph. 

Reusability 
The second insight concerns the reusability of (parts of) visualisations. I was writing a section of a paper on the history of visual timelines and the pioneering contributions by Jacques Barbeau-Dubourg (1709–1779), Joseph Priestley (1733–1804), William Playfair (1759–1823) and Adam Ferguson (1723–1816) when I wondered how their lifespans may have overlapped and whether or not they have been aware of each others’ work. As Priestley (1764, p.10) argued in defence of his chart, such relationships are hard to calculate mentally, but obvious when inspected on a visual diagram. I had no suitable diagram at hand, so I began to draft one in MS Excel when it dawned on me that, provided with a suitable dataset of the lifespans of these individuals, my ChronoZoom visualisation would be able to give me the answer quickly – and make me aware of just how far Playfair, who is often regarded as the father of modern charts, was predated by other proponents of arithmetic data visualisations (Figure 4.15).

The architecture of my ChronoZoom visualisation allowed individual components to be decoupled and repurposed. I defined and reviewed open timeline visualisations that accept different types of datasets and (in the case of SIMILE) can be embedded as plugins into larger projects. Based on my experience with ChronoZoom I started considering visualisations not as self-contained tools, but as a set of interlinked components. I directed my focus on the reusability of my proposed visualisation tools, both complete as well as in parts, in order to not only make the tools more adaptable, but most importantly more transparent. University of Virginia’s Neatline (Nowviskie et al. 2012) has similarly diverted its focus. Described at the time of launch as “a tool for the creation of interlinked timelines and maps” (UoV Library Scholars’ Lab 2009) it is since its second version (McClure 2013) presented as “a lightweight, extensible framework for creating interactive editions of visual materials” (UoV Library Scholars’ Lab n.d.). The SIMILE timeline, originally a central element, is now just one of several optional plugins that can be included. This shift does not follow a change in the technical architecture – Neatline has been designed as a plugin on top of the Omeka CMS since the beginning – rather it is a change in the perception of a digital visualisation suite as a reusable scholarly tool. 

Continuing 
Is a modular visualisation tool more appropriate for scholarly research than standalone software?

Prototype 6 - Tate Artists
I repurposed the timeline view and bars layout of my ChronoZoom prototype and turned it into a modular timeline tool. I tested the visualisation with data from the Tate, the Britten-Pears Foundation and the London Transport Museum, and developed an extended prototype based on the Tate artists data that includes additional interface elements to filter the dataset (Figure 4.16). 
In order to represent up to 70,000 records in a Gantt-like timeline, I implemented a type of semantic zooming based on a sampling approach. Semantic zooming is an established concept, for example, in digital maps, where it is used to draw only the essential features of a landscape at high zoom levels and reveal more details dynamically as the user zooms in. Perlin and Fox (1993) invented both the term and its first application. Semantic zooming has been used in timeline visualisations for quantitative data (Brodbeck & Girardin 2003; Aigner et al. 2012; Hofmann et al. 2012) as well as for navigating photographic data on a graphical timeline (Huynh et al. 2005). In a digital map, the hierarchy of geographic features controls what is visible at which zoom level: country, district, city or street-level information. In less structured datasets, such as cultural collections, a suitable mechanism needs to be established first. My prototype requires a measure of ‘importance’ to determine the rendering of individual items at different zoom levels; only the most ‘important’ records are represented at higher zoom levels, with less ‘important’ ones either drawn as a thin line or hidden completely. The importance of artists in the Tate datasets is measured by their number of works in the collection, but any other measure could work equally. The design of this prototype is more thoroughly discussed elsewhere (Boyd Davis & Kräutli 2014).

User Testing
I conducted a controlled user testing on this prototype, following best practice UX evaluation methods after Nielsen (1994). Subsequently I abandoned this route and instead followed the evaluation method outlined in my methodology. Here I want to give a brief account of the initial testing procedure and discuss the reasons for my departure from evaluating through controlled user studies. 
Candidates were recruited from the student body of the Royal College of Art via the college’s online notice board, ensuring that the participants had at least basic knowledge of information technology. The call informed interested students that they would be interacting with a software interface based on the Tate collection and that some interest in art and art history was desirable. Seven candidates were initially scheduled but due to unfortunate circumstances only five were able to attend on the day. 
The participants were led to a quiet room where they were asked to sit in front of a laptop computer running the visualisation and received four sheets of paper with instructions and small exercises to familiarise themselves with how to interact with the prototype. I then verbally read out the test procedure which consisted of them executing a set of twelve tasks using the timeline visualisation and filling in a short questionnaire after completing (or giving up on) a task. Participants were also asked to describe to me, while they were working on the task, what they were doing and why, following Lewis’ “thinkingaloud” protocol (Lewis 1982; Nielsen 1994; Lewis 2006). At the end of the session I captured their general impression of the prototype in non-structured interviews. During the testing I took notes and all sessions were video recorded and transcribed. 

Results 
In general, participants reacted positively to the interface and were eager and motivated to delve into the visualisation and follow their own leads beyond my predefined tasks for exploring the dataset using the timeline tool. Being presented with a lot of data at once made people curious. They quickly started to, for example, explore art movements and find corresponding artists for movements they were not aware existed, or test their own knowledge about the artists present in the dataset. 
While the experience of testing and the feedback I received were encouraging and confirmed the ability of digital timeline visualisation tools to assist in knowledge discovery in digital collections, most of the insights and problems the sessions revealed could not be translated beyond this specific prototype. 
The strength of this and similar studies lies in exposing flaws in the specific implementation of a visual interface; usability problems related to interface elements, insecurities about the signification of certain labels or the use of filters and selectors. My goal is however not to evaluate the effectiveness of a particular implementation of a visualisation in achieving a certain tasks, but to gain a broader understanding of the benefits and challenges of timeline visualisation tools in enabling and assisting in knowledge discovery in cultural collections. I encountered a contradiction when trying to evaluate the ability of a tool to facilitate an essentially creative act through predefined tasks and a controlled testing scenario; or in the words of Shneiderman et al. (2006), “[…] specifying tasks is somehow at odds with the goals of supporting innovation or discovery” (Shneiderman & Plaisant 2006). 
By interacting with the visualisation, the participants were able to make discoveries that were novel to them and formulate research questions that they then tried to answer using the tool. This observation is however insufficient evidence for drawing an informed conclusion on the ability of my visualisation tools to enable sense-making, as the users’ discoveries were lacking a baseline. A widespread method for establishing a baseline is to use a comparative testing scenario, with a control group exploring the same dataset through a standard interface and comparing the kind of insights they were able to make with the ones that were facilitated by the tool to be evaluated. Such A/B testing is a common practice for evaluating visual search interfaces. However, van Hoek et al. (2014) question the reliability of these tests and identify the need for a common reference system, while Shneiderman et al. (2006) express a general doubt on the effectiveness of these, and similar, evaluation methods: “Controlled experiments of specific features seem too narrow as do gross comparisons of one tool versus another” (Shneiderman & Plaisant 2006). The baseline I use instead for evaluating the heuristic quality of my visualisation prototypes is the knowledge that experts have acquired during years of their professional and academic career. If this knowledge can be augmented through a visualisation tool – even ever so slightly – this will equip me with more reliable evidence than testing within a narrow framework. 
In sum, what I was missing from this controlled user study – and what made me choose a different mode of evaluation – was a lack of transferable insights beyond specific usability problems, a difficulty of verifying discoveries that the visualisation facilitated and the impossibility of discriminating them from superficial or pre-existing knowledge because of the lack of a suitable baseline to ‘measure’ the ability of my visualisations to provoke new insights. 

Insights 
Confirmed Issues with Gantt-like Timelines
In several respects the Gantt-like layout proved to be unsuitable for visualising cultural data. Bars encode durations and, with the exception of the artist lifespans, the temporal data in the cultural datasets refers not typically to time-periods but, as I showed earlier, to estimates of a possible timeframe for an event to have taken place. Collections data is thus largely event-based, although not exclusively. Britten-Pears’ collection sometimes includes works that have a known period of composition – when a work comprises several pieces and each has been individually dated or when Britten referred to having spent time on a composition over several days in his diary. Solely based on the numeric dates in the database however, we are unable to decide whether the dates refer to a (documented) period of composition or to an estimated timeframe (Figure 4.17).
Mapping timeframes to lengths of bars produces a bias towards events with wider confidence in dates; larger timeframes visually stand out in the diagram. I have already observed this in P3 and the user study confirmed the effect. Indeed many users were drawn to identifying the oldest artist in the Tate collection, or to find out why certain artists seemingly reached an unrealistically high age – those ‘artists’ typically turned out to be umbrella categories for works of art whose creator was, in fact, unknown. However, in most datasets the signification of a duration is not as evident as in the case of a person’s lifespan, therefore a layout that emphasises this aspect may not be the ideal choice for visualising cultural data. 
Earlier, when discussing the Empires timeline of Accurat (Beltramin et al. 2012) and Lee (2011), I pointed out the pattern that results from the correlation of the horizontal time axis and the vertical sequential ordering in Gantt-like timeline layouts. This effect occurs in my own prototype as well and I was able to observe the consequences for the viewer through my user study. 
Users did not realise that the vertical ordering of the events corresponded to the birth-dates of the artists, even when they were consciously reflecting on it. Instead, users began to speculate on the significance of the vertical axis and sought to make sense of the overall pattern, giving up quickly as they could not come to a satisfying conclusion. This demonstrated not only the problem inherent in the layout which I criticised, but also that users try to interpret the visualisation both in respect to its totality as well as individual items, supporting the need for timelines to be effective on the level of individual events as well as in totality. 

Biases Through Sampling-Based Semantic Zoom 
Due to the sampling that was required by my semantic zooming mechanism, any conclusion one could derive from this overall pattern would not only be distorted by the layout algorithm, but also by the applied selection criteria of the semantic zooming algorithm. The S-shaped pattern that emerges in the overall representation of the records could signify an uneven temporal distribution of artists in the Tate collection, with a cluster of artists born around 1800 and a second one around 1950, or, it could show an uneven distribution of significant artists – according to a quantitative measure of significance. Due to the constraints of the chosen semantic zooming method, which only ever shows a fraction of the data, one is not able to draw any reliable insights about the entire dataset. However, users often did assume they were presented with the complete dataset when interacting with the tool. The layout did not sufficiently communicate the extent of the dataset and whether or not all that is available is, in fact, in view. Some users stated that they expected the visualisation to be complete whenever it did not entirely fill the available space. 
A prevalent assumption that a visualisation displays a complete picture of a dataset appeared already when the lack of Turner in my earlier Tate diagram (P4, Figure 4.11 on page 146) went unnoticed. Through this user testing I was once more made aware of the importance of not only making an entire dataset available, but also of the challenge of finding an appropriate representation that indicates the boundaries of a collection. In the physical world the constraints of an information source are often obvious through the medium. A physical archive is terminated by the spaces it is contained in. The thickness and weight of a book lets us estimate the size of its content; as we flip through pages, we get a sense of our ‘location’ within it. In the digital realm we need to design visualisations so that users get a similar sense of orientation.14 It is not sufcient to use external indicators. My prototype did state the number of items currently visible along with the total in writing, yet this information was ignored, with no exception, by all users. 

Continuing 
How can we design a semantic zoom that retains completeness? 
What layout is more suitable to represent event-based data than a Gantt-like chart?

Prototype 7 - Britten Force

Process
“Britten Force” is motivated by my enquiries into representing uncertainties in dating events and is based on the digital archive of the Britten-Pears foundation, a dataset that offered, from all the collections available to me, the most diverse  source for different levels of (un)certainties in the temporal descriptions of the catalogued works. Reflecting on how I could even attempt to do justice to the variety of different temporal granularities and to the richness of the descriptions, I asked myself what would happen if I disregard most of the classifications, cataloguing and categorisation and instead just consider this significant cultural collection as, quite literally, a bunch of stuff. 
In this visualisation every work of Benjamin Britten is graphically represented as a dot. Each dot’s position is determined by a simulated force; it is drawn by a gravitational pull to its destined location on a horizontal time axis. The more certain a dot’s temporal description, the stronger the force which is exerted on it. As individual dots are also repelled from each other, the layout arranges itself and ultimately settles in a flock-like composition – uncertain events will have settled with a position somewhere in the vicinity of their respective dates, while more narrowly dated events will stick tightly to their ‘proper’ temporal location (Figure 4.19). The technique is borrowed from a force-directed graph visualisation method (Fruchterman & Reingold 1991) that is also responsible for the fluid motion in which the dots align themselves – a visual effect that curators found very appealing. 
Users can dissect the dataset by clicking and dragging one of the words that appear at the right of the flock in a tag cloud. They are based on word occurrences in the works’ subtitles, ordered and sized by frequency of appearance. I used the subtitles as they effectively described a work’s instrumentation and contained values for all the pieces. Additionally, this method of machine-interpreting free text is robust and reusable for other cultural datasets . 
Dragging one of the words splits the group of records in two based on whether they match the chosen criteria. For example, “piano” appears as the dominant category in the Britten dataset and dragging the term downwards creates two new collections, one with and one without piano pieces. To the curators’ surprise the piano works comprised a large subset of the collection: He is not known at all as being a piano composer, and there it is. (C6) 
What the visualisation revealed was not so much representative of Britten’s oeuvre, as of the decision to classify most of his many childhood works as piano pieces. 
We can continue dragging selections based on instruments out of the flocks (Figure 4.18). “Viola” now appears as a term besides the piano pieces and separating it reveals a cluster of pieces around 1935 and a single piece, an outlier, composed around 1950. 

Insights 
The prototype was well received by the curators of the Britten-Pears archive who described it as “very expressive” (C6) and immediately began to suggest queries and how it could be enriched by using it to explore different aspects of their dataset. The tactile metaphor of starting with a heap of things and then being able to sift through it, while getting visual feedback of the query result, proved to be very effective. Due to the layout algorithm and the coarse granularity of the time axis the visualisation could only give an approximate indication of when certain works were composed. However, the curators raised no concerns on the factual imprecision of the events’ date representation. They used the visualisation to examine overall temporal patterns rather than looking at precise date of composition of individual works. The time-aware force-directed layout successfully addresses a number of challenges that arose in my research. Through the arrangement one can clearly see the extent of the collection and comprehend it as a single entity. Patterns that occur through variations in the overall shape are representative of temporal patterns in the dataset and not merely side-effects of the layout algorithm. I have previously questioned the effectiveness of communicating uncertainties in visualisations by additional graphical elements. In the design of this timeline layout, uncertainty is treated not as an additional and therefore optional qualifier, but as a fundamental property of temporal data. Uncertainty is taken into account as a basis of the layout – a radical departure from Gantt-like layouts that expect the timing of events to be known and introduce an additional graphical vocabulary for the exceptional case of uncertain dates. In collections data, however, uncertain dates are the rule, not the exception. Conceptually, this is an important insight, technically however the implementation of the layout did not scale well to datasets larger than a few hundred items due to the complexity of the physics simulation. By optimising the algorithm and changing the architecture a performance improvement would be conceivable, however the layout suffered from more than just technical difficulties. Unsurprisingly, the curators found it difficult to interrogate records that were moving around constantly. I realised that I had to find a way to retain accessibility to individual records, even in collections that span hundreds of thousands of them.

Continuing
How can this type of layout scale to larger datasets? 
How to use uncertainty as the basis of a visualisation and not merely as an optional qualifier?

Prototype 8 - Temporal Jittering / Parallel Timelines

Process
The starting point is the previously discussed implementation of a time-aware force-directed layout based on the Britten-Pears archive dataset (P7). The premise of temporal descriptions as inherently uncertain, the tactile metaphor of the heap of ‘stuff’ and the atomic representation of individual records proved to be effective. These are characteristics that should be retained. Major downsides in the previous prototype turned out to be the fact that the approach scales badly to larger datasets and that the final layout is non-deterministic; the position of any single item depends on the attributes of all other items. I have already pointed out the adverse effects on readability of non-deterministic layouts in the context of the space-saving layout implemented in Kindred Britain (see page 113). 
To counteract these properties, I developed an algorithm that arranges the dots in a reproducible, deterministic manner, making use of the uncertainties embedded in the temporal descriptions. The Temporal Jittering (TJ) layout represents each record as a same-sized dot, positioned horizontally according to its allowed timeframe – as defined by the date brackets – and stacked vertically in order of accession. This produces a compact and aggregated overview of an entire collection. Essentially, it exploits the width of the timeframe allowed by the date brackets to accommodate a more densely packed display than would otherwise be possible. 
I produced two initial prototype implementations using the layout: an application that combines the layout with a vertical list based timeline and filters to explore and dissect the dataset (Figure 4.20), and a parallel timeline that looks at the relationship between the composition date of works and their date of first performance (Figure 4.21). Following my focus issue on temporal descriptions I looked at what kind of dates are available in the Britten-Pears archive and what this visualisation format might be able to reveal about them. The parallel timeline visualises Britten’s works twice: the layout in the top half is generated according to their date of composition, the bottom half according to the date of first performance. I use a symmetrical version of the layout here – for reasons I will outline later. As the layout allows each work to be represented individually, it is possible to connect matching works by a thin line.

Insights
We can spot a number of lines that are going the ‘wrong way’. Apparently these works have been performed before they were written – as it turns out, a result of textual dates misinterpreted by the cataloguing software. A vertical pattern of lines indicates that most of the works have been performed shortly after having been composed. Oblique lines heading from the performances into the past appear shortly before, and long after Britten stopped composing – and indeed living. These are first performances of juvenilia taking place. By the point in time at which they appear, we can study how people must have begun to understand Britten as a whole and started being interested in his very early works. This can speak about the telling of biography. You revealed in this diagram that propensity for looking for the origins. (C3) 
This prototype is not the first one where I experiment with using other temporal descriptions than the date of creation to visualise the dataset. However, it is the first one that does so successfully. Primarily because the layout allows not only an entire collection to be represented in a compact form, but also several ‘versions’ of a collection according to different temporal attributes. The collection itself – reorganised according to different temporalities – provides its own context. 
When discussing this visualisation with the curators at Britten-Pears they were immediately able to spot the outliers: How were some performed before they were written? (C6) The also began to question and interpret the diagram: I’m curious about this thick bunch of lines here. What’s that telling us? (C6) 
Going back to the Temporal Jittering layout – this proved to be successful in tackling the issues that my research brought up. The strict rule-based positioning of the dots eliminates randomness; the diagram is built up gradually, placing each dot at the lowest available vertical position, while minimising the horizontal distance to the midpoint of the allowed time period. This relates to issues observed earlier about the meaning of the non-temporal axis; the vertical order matters as it is a consequence of the sequence in which records have been accessioned – a feature whose benefits become more apparent when I apply it to larger datasets later on. 
In contrast to Gantt-like layouts that produce a sloping pattern in the overall representation of the records as a side-effect of the correlation between the two axes, the patterns produced by this layout are informative about the dataset and – specifically – the temporal uncertainties Both the layout algorithm and the implementation proved to be very effective in addressing the focus issues as well as by raising positive reactions and evoking insights and questions among my collaborators. 

Continuing 
How can the layout and the insights gained from the implementations be generalised? 
What kind of insights are enabled by incorporating temporal multiplicities?

Emerging Design Principles
A development is taking place with regards to the focus issues. While I initially looked at them as separate problems, they have started to converge. Tackling issues of scale and layout is, in the last prototypes, done effectively by incorporating uncertainty as a fundamental principle in the timeline visualisation. The compactness of the layout in turn is achieved by making use of the uncertain temporal descriptions embedded in a dataset. 
Based on the initial focus issues and the insights that emerged from the development and evaluation of the prototypes I propose three design principles that address specific challenges related to the time-wise visualisation of digital collections. These include approaches to examining large datasets through timelines that support distant reading, and new approaches to model and represent historic time by taking advantage of embedded uncertainties and temporal multiplicities. 

Timelines for Distant Reading 
Existing timelines and timeline layouts can be magnificent tools for locating an event in time or tracing the history of a course of events. Current timelines excel at close reading of histories, but they often fall short when trying to make sense of an entire dataset. 
I showed how timeline tools collapse when faced with large datasets. It is not necessarily the scale of a dataset, but its temporal distribution that causes a lot of records to occupy a small timeframe, or even identical times. Unlike regular time series, digital collections and many other ‘manually’ produced datasets usually exhibit uneven temporal distributions. 
By tackling the issues of layouts for visualising large datasets on timelines, I have paved the way for timelines that support a distant reading of digital collections. The Temporal Jittering layout results in overall patterns that are informative about the visualised dataset and readable in both dense and sparse temporal regions. 
The difficulty of visualising large datasets over time is to achieve this not by imposing severe biases on how the data is represented. Combining events that are close in time and organising them by category (P1), or controlling a semantic zoom by hiding ‘unimportant’ records (P4) emphasises the dominant themes in a dataset and suppresses its long tail of records that do not match the specified measure of importance – an undesirable outcome. Preventing clutter by reducing the number of displayed items means exerting a bias on the represented dataset and violating the basic principle of distant reading: being able to study ‘everything’ without discarding data unquestioned. 
Semantic zooming could be a viable solution for cluttered timelines and indeed has been applied in the past, but it needs to be able to function without reducing the number of represented records. Kindred Britain’s timeline adjusts the detail of drawn events when zooming out – but the maximum of records visible is capped at 74 records, while the dataset is said to contain 30,000 records. Other examples of digital timelines with semantic zooming all work by reducing the number of events represented. Having to sample a dataset in order for it to be represented however compromises on the honesty of the visualisation and can mean that observed overall patterns are meaningless because not all records in a dataset contribute to it. 
In my discussion of P1 I have pointed out how existing timeline visualisations approach the issue of distant reading by implementing two separate views – an atomic representation of events and an aggregate view of the entire dataset in a histogram. In a histogram we however lose the quality of being able to work with individual events. Ideally, I concluded, aggregate and atomic views could both be implemented using the same layout and representation. The Temporal Jittering layout I developed in P8 does have the potential to manage this because its overall shape is determined, can therefore be drawn like a histogram and is equally informative, while its composition consists of individual units that can also be drawn separately. The result is a timeline that supports distant reading by implementing an aggregate view that retains the completeness of a dataset, communicates its extent and exposes large-scale patterns that are informative, rather than side-effects of an algorithmic layout. 

Embedding Uncertainties 
Closing in on the issue of making use of temporal descriptions I focused on the uncertainty embedded in numeric date brackets, to see how temporal uncertainty could be represented on a timeline (P3, P7, P8). Graphically indicating uncertainty as error bars – a standard approach in statistical diagrams – works well on the level of individual events. SIMILE implements a variation of this by indicating uncertain parts of events through a lighter shading. However, we are still left with the issue of clutter, to which graphical error bars might even contribute. 
Other concerns emerged on the danger of suggesting – through a precise graphical rendering – certainty within the uncertainty. On the other hand, it is insightful that curators raised no concerns about the imprecision of the temporal positioning in the Britten Force layout (P7). In this particular case it might be because this is a comparatively small collection. Curators typically know when most of the works were composed. In a larger dataset this might be more problematic. However, this example also shows how a timeline of cultural data can bring new knowledge to experts who are very familiar with every single piece in a collection. What the visualisation was able to tell them was something about overall patterns or connections and ask questions about a larger number of records. 
Is it possible to enable a distant reading of a dataset, along with its temporal uncertainties? In P7 and P8 I have deviated from the standard practice of including uncertainties at the end of a visualisation ‘pipeline’ – by adding graphical elements or changing the representation of an event – to the very beginning of it – by making it the driving force of a timeline layout. Temporal uncertainty is then a fundamental component of the timeline visualisation, as much as it is a fundamental part of dating historic events. Timelines that incorporate temporal uncertainty at their very basis are able to respond to and be transparent about inconsistencies in temporal data that are typical for digital collections. 

Multiple Temporalities 
In P1–P7 I retained the established convention of museums to date cultural artefacts by their “moment of genesis” (C3). In P8 I deviated from this by arranging Britten’s works also by their dates of first performances. This allowed me and curators to study the history of the public popularity of Britten’s works in addition to their own history of composition. New insights in digital collections could be facilitated by making use of alternative temporal attributes as a structuring principle and subsequently also looking at a collection from different perspectives: rather than seeing the Britten-Pears collection as an archive of compositions, it could be an archive of first performances or – as I show later – an archive of poets. 
The issue of multiple temporalities in cultural collections is possibly an under-explored one because in archiving practices the central unit is the object and its ‘date of birth’ is the dominant temporal point. 
Chronology, the study of the proper temporal location of events and the foundation of modern timelines has enabled structured and comparative sense-making along a uniform model of mathematical time, but also reinforced a singular model of time, which treats events as occupying a single position in time. As I have shown, in digital collections, it is not unusual to record several temporal attributes of an item, such as date of acquisition or relocation, and an item may have related events – exhibitions, persons, other items – which each have their own associated dates. Digital visualisations of entire datasets have so far made little use of including multiple temporal perspectives for individual events and established formats for visual timelines are unable to represent rich relationships through multiple granularities of time. Visualising for multiple temporalities – in the way I have demonstrated in P8 and will develop further – means decreasing the authority of a single date associated with an event and instead rendering multiple temporal perspectives of individual events, which as a result draws a richer representation of the temporal relationships within an entire dataset.

